Params:[-referenceAssistant, /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts, /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/RawTextsNoTranscripts, /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full, /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/configs/FULL.xml]
Usage: either
	$java ReferenceAssistant -trainSvmModelsOnly <pathToConfigFile>
or
	$java ReferenceAssistant -buildTrainingDataAndTrain <pathToProblems> <pathToRawTexts> <pathToConfigFile>
or
	$java ReferenceAssistant -annotateData <inputPath> <outputPath> <generateFeatureDumps>  <pathToConfigFile> 
or
	$java ReferenceAssistant -referenceAssistant <pathToProblemFileOrFolder> <pathToRawTextFilesFolder> <pathToExplanations>  <pathToConfigFile> 
Creating wordnet dictionary from data/WordNet/...
Dictionary opened.
----------------->Bypassing the curator!
Loading the most recent redirect pages from Wikipedia to normalize the output links to the latest version
loading the latest redirects; linecount=1
Consructing wikipedia summary from a proto buffer
loading the latest redirects; linecount=100001
Done - consructing wikipedia summary from a proto buffer
Opening the index for the complete index interface
Prefetching the basic information about the wikipedia articles
loading the latest redirects; linecount=200001
0 titles processed out of 2478573
loading the latest redirects; linecount=300001
loading the latest redirects; linecount=400001
loading the latest redirects; linecount=500001
50000 titles processed out of 2478573
loading the latest redirects; linecount=600001
loading the latest redirects; linecount=700001
100000 titles processed out of 2478573
loading the latest redirects; linecount=800001
loading the latest redirects; linecount=900001
loading the latest redirects; linecount=1000001
150000 titles processed out of 2478573
loading the latest redirects; linecount=1100001
loading the latest redirects; linecount=1200001
200000 titles processed out of 2478573
loading the latest redirects; linecount=1300001
loading the latest redirects; linecount=1400001
loading the latest redirects; linecount=1500001
250000 titles processed out of 2478573
300000 titles processed out of 2478573
loading the latest redirects; linecount=1600001
loading the latest redirects; linecount=1700001
loading the latest redirects; linecount=1800001
350000 titles processed out of 2478573
loading the latest redirects; linecount=1900001
loading the latest redirects; linecount=2000001
loading the latest redirects; linecount=2100001
400000 titles processed out of 2478573
loading the latest redirects; linecount=2200001
loading the latest redirects; linecount=2300001
loading the latest redirects; linecount=2400001
loading the latest redirects; linecount=2500001
450000 titles processed out of 2478573
loading the latest redirects; linecount=2600001
loading the latest redirects; linecount=2700001
500000 titles processed out of 2478573
loading the latest redirects; linecount=2800001
loading the latest redirects; linecount=2900001
550000 titles processed out of 2478573
loading the latest redirects; linecount=3000001
loading the latest redirects; linecount=3100001
600000 titles processed out of 2478573
650000 titles processed out of 2478573
700000 titles processed out of 2478573
750000 titles processed out of 2478573
loading the latest redirects; linecount=3200001
800000 titles processed out of 2478573
loading the latest redirects; linecount=3300001
loading the latest redirects; linecount=3400001
loading the latest redirects; linecount=3500001
loading the latest redirects; linecount=3600001
850000 titles processed out of 2478573
loading the latest redirects; linecount=3700001
loading the latest redirects; linecount=3800001
900000 titles processed out of 2478573
loading the latest redirects; linecount=3900001
loading the latest redirects; linecount=4000001
loading the latest redirects; linecount=4100001
loading the latest redirects; linecount=4200001
950000 titles processed out of 2478573
loading the latest redirects; linecount=4300001
loading the latest redirects; linecount=4400001
1000000 titles processed out of 2478573
loading the latest redirects; linecount=4500001
loading the latest redirects; linecount=4600001
loading the latest redirects; linecount=4700001
1050000 titles processed out of 2478573
loading the latest redirects; linecount=4800001
loading the latest redirects; linecount=4900001
loading the latest redirects; linecount=5000001
1100000 titles processed out of 2478573
loading the latest redirects; linecount=5100001
loading the latest redirects; linecount=5200001
1150000 titles processed out of 2478573
loading the latest redirects; linecount=5300001
loading the latest redirects; linecount=5400001
1200000 titles processed out of 2478573
loading the latest redirects; linecount=5500001
loading the latest redirects; linecount=5600001
1250000 titles processed out of 2478573
loading the latest redirects; linecount=5700001
loading the latest redirects; linecount=5800001
Done  - Loading the most recent redirect pages from Wikipedia to normalize the output links to the latest version
1300000 titles processed out of 2478573
1350000 titles processed out of 2478573
1400000 titles processed out of 2478573
1450000 titles processed out of 2478573
1500000 titles processed out of 2478573
1550000 titles processed out of 2478573
1600000 titles processed out of 2478573
1650000 titles processed out of 2478573
1700000 titles processed out of 2478573
1750000 titles processed out of 2478573
1800000 titles processed out of 2478573
1850000 titles processed out of 2478573
1900000 titles processed out of 2478573
1950000 titles processed out of 2478573
2000000 titles processed out of 2478573
2050000 titles processed out of 2478573
2100000 titles processed out of 2478573
2150000 titles processed out of 2478573
2200000 titles processed out of 2478573
2250000 titles processed out of 2478573
2300000 titles processed out of 2478573
2350000 titles processed out of 2478573
2400000 titles processed out of 2478573
2450000 titles processed out of 2478573
Actual capacities:
TitleEssentialData:6584983
Loaded 2478573 nonNormalizedTitles
Done prefetching the basic data about 2478573 Wikipedia articles
Loading information about surface form to title id mappings
1 surface forms is linkable out of 0. There are 4045674  surface forms total; last surface form read: Lord of Coucy
100001 surface forms is linkable out of 100000. There are 4045674  surface forms total; last surface form read: Casino, New South Wales
200001 surface forms is linkable out of 200000. There are 4045674  surface forms total; last surface form read: St. Dominic’s Church
300001 surface forms is linkable out of 300000. There are 4045674  surface forms total; last surface form read: GATT
400001 surface forms is linkable out of 400000. There are 4045674  surface forms total; last surface form read: Beotia
500001 surface forms is linkable out of 500000. There are 4045674  surface forms total; last surface form read: Heartbreaker
600001 surface forms is linkable out of 600000. There are 4045674  surface forms total; last surface form read: The White Dove
700001 surface forms is linkable out of 700000. There are 4045674  surface forms total; last surface form read: Polish league's
800001 surface forms is linkable out of 800000. There are 4045674  surface forms total; last surface form read: G.Beck
900001 surface forms is linkable out of 900000. There are 4045674  surface forms total; last surface form read: Pacific Air Transport
1000001 surface forms is linkable out of 1000000. There are 4045674  surface forms total; last surface form read: Guo Zhendong
1100001 surface forms is linkable out of 1100000. There are 4045674  surface forms total; last surface form read: N-630
1200001 surface forms is linkable out of 1200000. There are 4045674  surface forms total; last surface form read: Arbor Lodge State Park
1300001 surface forms is linkable out of 1300000. There are 4045674  surface forms total; last surface form read: 1996's Hurricane Fausto
1400001 surface forms is linkable out of 1400000. There are 4045674  surface forms total; last surface form read: The Story of Doctor Dolittle
1500001 surface forms is linkable out of 1500000. There are 4045674  surface forms total; last surface form read: WBZB
1600001 surface forms is linkable out of 1600000. There are 4045674  surface forms total; last surface form read: State Highway 50A
1700001 surface forms is linkable out of 1700000. There are 4045674  surface forms total; last surface form read: Antoniadi scale
1800001 surface forms is linkable out of 1800000. There are 4045674  surface forms total; last surface form read: Mulroy
1900001 surface forms is linkable out of 1900000. There are 4045674  surface forms total; last surface form read: Yellow birch
2000001 surface forms is linkable out of 2000000. There are 4045674  surface forms total; last surface form read: Aleksandr Grigorievich Stoletov
2100001 surface forms is linkable out of 2100000. There are 4045674  surface forms total; last surface form read: Rob Valentine
2200001 surface forms is linkable out of 2200000. There are 4045674  surface forms total; last surface form read: Christ 777
2300001 surface forms is linkable out of 2300000. There are 4045674  surface forms total; last surface form read: “Alice” shorts
2400001 surface forms is linkable out of 2400000. There are 4045674  surface forms total; last surface form read: Knights of Da Gama
2500001 surface forms is linkable out of 2500000. There are 4045674  surface forms total; last surface form read: Anastasiopolis
2600001 surface forms is linkable out of 2600000. There are 4045674  surface forms total; last surface form read: Hearing protection
2700001 surface forms is linkable out of 2700000. There are 4045674  surface forms total; last surface form read: Orhuwhorun
2800001 surface forms is linkable out of 2800000. There are 4045674  surface forms total; last surface form read: Warren Ellis'
2900001 surface forms is linkable out of 2900000. There are 4045674  surface forms total; last surface form read: rag-time
3000001 surface forms is linkable out of 3000000. There are 4045674  surface forms total; last surface form read: urnebes
3100001 surface forms is linkable out of 3100000. There are 4045674  surface forms total; last surface form read: As Rapture Comes
3200001 surface forms is linkable out of 3200000. There are 4045674  surface forms total; last surface form read: marrow
3300001 surface forms is linkable out of 3300000. There are 4045674  surface forms total; last surface form read: Object-based
3400001 surface forms is linkable out of 3400000. There are 4045674  surface forms total; last surface form read: Siege of Dapur
3500001 surface forms is linkable out of 3500000. There are 4045674  surface forms total; last surface form read: National Unity Cabinet
3600001 surface forms is linkable out of 3600000. There are 4045674  surface forms total; last surface form read: 43 countries recognise
3700001 surface forms is linkable out of 3700000. There are 4045674  surface forms total; last surface form read: maneštra
3800001 surface forms is linkable out of 3800000. There are 4045674  surface forms total; last surface form read: Digital Datcom
3900001 surface forms is linkable out of 3900000. There are 4045674  surface forms total; last surface form read: Louisville Courier
4000001 surface forms is linkable out of 4000000. There are 4045674  surface forms total; last surface form read: Risset
There are 0 unlinkable surface forms
Actual capacities:
SurfaceFormData:4961459
Done loading information about surface form to title id mappings
WordNet config file: configs/jwnl_properties.xml
[INFO][net.didion.jwnl.dictionary.Dictionary] - Installing dictionary net.didion.jwnl.dictionary.FileBackedDictionary@36d585c
Done initializing the system: 171605 milliseconds elapsed
Memory usage : 3406 MB


********************************************

Solving problems with user-specified entities.
	 pathToProblems=/scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts
	 rawFilesPath=/scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/RawTextsNoTranscripts
	 outPath=/scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full

********************************************


Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/NYT20001106.1705.0187
character encoding = UTF8
Adding feature: Forms
Adding feature: Capitalization
Adding feature: WordTypeInformation
Adding feature: Affixes
Adding feature: PreviousTag1
Adding feature: PreviousTag2
Adding feature: GazetteersFeatures
Adding feature: BrownClusterPaths
Adding feature: prevTagsForContext
Adding feature: PredictionsLevel1
Working parameters are:
inferenceMethod=GREEDY
beamSize=5
thresholdPrediction=false
predictionConfidenceThreshold=-1.0
labelTypes
	PER	ORG	LOC	MISC
logging=false
debuggingLogPath=../../DebugLog//finalSystemBILOUdebugLog.txt
forceNewSentenceOnLineBreaks=true
keepOriginalFileTokenizationAndSentenceSplitting=false
taggingScheme=BILOU
tokenizationScheme=DualTokenizationScheme
pathToModelFile=data/NER_Data/Models/Demo/CoNLL//finalSystemBILOU.model
Brown clusters resource: 
	-Path: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt
	-WordThres=5
	-IsLowercased=false
Brown clusters resource: 
	-Path: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters
	-WordThres=5
	-IsLowercased=false
Brown clusters resource: 
	-Path: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt
	-WordThres=5
	-IsLowercased=false
Reading the Brown clusters resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt
1288301 words added
Reading the Brown clusters resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters
95262 words added
Reading the Brown clusters resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt
85963 words added
loading dazzetteers....
	loading gazzetteer:....data/NER_Data//KnownLists/WikiArtWorkRedirects.lst
	loading gazzetteer:....data/NER_Data//KnownLists/known_jobs.lst
	loading gazzetteer:....data/NER_Data//KnownLists/known_corporations.lst
	loading gazzetteer:....data/NER_Data//KnownLists/known_place.lst
	loading gazzetteer:....data/NER_Data//KnownLists/WikiPeople.lst
	loading gazzetteer:....data/NER_Data//KnownLists/known_names.big.lst
	loading gazzetteer:....data/NER_Data//KnownLists/WikiCompetitionsBattlesEventsRedirects.lst
	loading gazzetteer:....data/NER_Data//KnownLists/WikiManMadeObjectNamesRedirects.lst
	loading gazzetteer:....data/NER_Data//KnownLists/WikiFilms.lst
	loading gazzetteer:....data/NER_Data//KnownLists/WikiArtWork.lst
	loading gazzetteer:....data/NER_Data//KnownLists/WikiOrganizations.lst
	loading gazzetteer:....data/NER_Data//KnownLists/temporal_words.txt
	loading gazzetteer:....data/NER_Data//KnownLists/WikiCompetitionsBattlesEvents.lst
	loading gazzetteer:....data/NER_Data//KnownLists/WikiSongsRedirects.lst
	loading gazzetteer:....data/NER_Data//KnownLists/WikiSongs.lst
	loading gazzetteer:....data/NER_Data//KnownLists/known_country.lst
	loading gazzetteer:....data/NER_Data//KnownLists/WikiPeopleRedirects.lst
	loading gazzetteer:....data/NER_Data//KnownLists/measurments.txt
	loading gazzetteer:....data/NER_Data//KnownLists/known_nationalities.lst
	loading gazzetteer:....data/NER_Data//KnownLists/WikiFilmsRedirects.lst
	loading gazzetteer:....data/NER_Data//KnownLists/cardinalNumber.txt
	loading gazzetteer:....data/NER_Data//KnownLists/Occupations.txt
	loading gazzetteer:....data/NER_Data//KnownLists/WikiManMadeObjectNames.lst
	loading gazzetteer:....data/NER_Data//KnownLists/ordinalNumber.txt
	loading gazzetteer:....data/NER_Data//KnownLists/known_title.lst
	loading gazzetteer:....data/NER_Data//KnownLists/known_state.lst
	loading gazzetteer:....data/NER_Data//KnownLists/KnownNationalities.txt
	loading gazzetteer:....data/NER_Data//KnownLists/known_name.lst
	loading gazzetteer:....data/NER_Data//KnownLists/WikiLocations.lst
	loading gazzetteer:....data/NER_Data//KnownLists/VincentNgPeopleTitles.txt
	loading gazzetteer:....data/NER_Data//KnownLists/WikiOrganizationsRedirects.lst
	loading gazzetteer:....data/NER_Data//KnownLists/WikiLocationsRedirects.lst
	loading gazzetteer:....data/NER_Data//KnownLists/currencyFinal.txt
found 33 gazetteers
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =810
		- Total unique tokens  =387
		- Total unique tokens ignore case =367
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =54
		- OOV tokens, no repetitions, Case Sensitive =23
		- Total OOV tokens even after lowercasing  =54
		- OOV tokens even after lowercasing, no repetition  =22
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =59
		- OOV tokens, no repetitions, Case Sensitive =28
		- Total OOV tokens even after lowercasing  =59
		- OOV tokens even after lowercasing, no repetition  =27
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =38
		- OOV tokens, no repetitions, Case Sensitive =32
		- Total OOV tokens even after lowercasing  =35
		- OOV tokens even after lowercasing, no repetition  =28
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 3104 milliseconds
Constructing a problem for the following text: 
 (EDS: This early version will be updated from Davenport, Iowa.) &QL; (ART ADV: Photos NYT11 and 25 are being sent to NYT photo clients. Nonsubscribers can purchase one-time rights by calling 888-6...
13 milliseconds elapsed on constructing the TF-IDF representation of the input text...NYT20001106.1705.0187
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Adding NER candidates for NYT20001106.1705.0187
Creating coreferencer by thread 24
Adding SHALLOW_PARSE and subChunk candidates for NYT20001106.1705.0187
Loading clusters...
Loading wordnet database...
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Matched regex entity Davenport, Iowa[47-62]{10-12}
Matched regex entity CHATTANOOGA, Tenn[317-334]{77-80}
Matched regex entity Vice President Al Gore and President Clinton[925-969]{194-201}
Matched regex entity Gore and President Clinton[943-969]{197-201}
Matched regex entity Tennessee and Arkansas[2137-2159]{433-436}
Matched regex entity Wisconsin and Iowa[2196-2214]{443-446}
Matched regex entity Michigan and Pennsylvania[2365-2390]{476-479}
Matched regex entity Monday, Bush[2506-2518]{500-503}
Matched regex entity Election Day, Bush[2794-2812]{548-552}
Matched regex entity Green Bay, Wis[3041-3055]{598-602}
Matched regex entity In Chattanooga, Bush[3507-3527]{700-704}
Matched regex entity Chattanooga, Bush[3510-3527]{701-704}
Matched regex entity Washington, D.C.[3939-3955]{785-788}
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Annotating mention view..
[pool-2-thread-1] INFO edu.illinois.cs.cogcomp.edison.annotators.GazetteerViewGenerator - Loading all gazetteers from resources/gazetteers/gazetteers
Done constructing the Wikifiable entities
     ----  almost there....
1119 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...NYT20001106.1705.0187
Inference on the document  -- NYT20001106.1705.0187
7 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
38 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
20483 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
18 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
1179 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
7 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: CHATTANOOGA to : http://en.wikipedia.org/wiki/Chattanooga,_Tennessee
Level:FeatureExtractorCoherenceCorrect Wikification of: Tenn. to : http://en.wikipedia.org/wiki/Tennessee
Level:FeatureExtractorCoherenceCorrect Wikification of: Arkansas to : http://en.wikipedia.org/wiki/Arkansas
Level:FeatureExtractorCoherenceCorrect Wikification of: White House to : http://en.wikipedia.org/wiki/White_House
Level:FeatureExtractorCoherenceCorrect Wikification of: Wisconsin to : http://en.wikipedia.org/wiki/Wisconsin
Level:FeatureExtractorCoherenceCorrect Wikification of: Iowa to : http://en.wikipedia.org/wiki/Iowa
Level:FeatureExtractorCoherenceCorrect Wikification of: Michigan to : http://en.wikipedia.org/wiki/Michigan
Level:FeatureExtractorCoherenceCorrect Wikification of: Pennsylvania to : http://en.wikipedia.org/wiki/Pennsylvania
Level:FeatureExtractorCoherenceCorrect Wikification of: Green Bay to : http://en.wikipedia.org/wiki/Green_Bay,_Wisconsin
Level:FeatureExtractorCoherenceCorrect Wikification of: D.C. to : http://en.wikipedia.org/wiki/Washington,_D.C.
Level:FeatureExtractorCoherenceCorrect Wikification of: CHATTANOOGA to : http://en.wikipedia.org/wiki/Chattanooga,_Tennessee
Level:FeatureExtractorCoherenceCorrect Wikification of: Tenn. to : http://en.wikipedia.org/wiki/Tennessee
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Washington; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Washington,_D.C.;
  The confusions set is : Washington,_D.C.(ranker score=3.326916467149039) Vs: Washington(ranker score=4.32794467470943);
  The context is: ; ------- ;  17 months after he first issued his call for a ``fresh start after a season of cynicism,'' Gov. George W. Bush ended his quest for the presidency Monday on a nearly identical note, pledging to purge Washington of what he cast as a crippling discord.   The course that Bush charted over his final hours on the campaign trail, plotted with as much concern for symbolism as for raw electoral arithmetic
Level:FeatureExtractorCoherenceCorrect Wikification of: Arkansas to : http://en.wikipedia.org/wiki/Arkansas
Level:FeatureExtractorCoherenceCorrect Wikification of: White House to : http://en.wikipedia.org/wiki/White_House
Level:FeatureExtractorCoherenceCorrect Wikification of: Wisconsin to : http://en.wikipedia.org/wiki/Wisconsin
Level:FeatureExtractorCoherenceCorrect Wikification of: Iowa to : http://en.wikipedia.org/wiki/Iowa
Level:FeatureExtractorCoherenceCorrect Wikification of: Michigan to : http://en.wikipedia.org/wiki/Michigan
Level:FeatureExtractorCoherenceCorrect Wikification of: Pennsylvania to : http://en.wikipedia.org/wiki/Pennsylvania
Level:FeatureExtractorCoherenceCorrect Wikification of: Green Bay to : http://en.wikipedia.org/wiki/Green_Bay,_Wisconsin
Level:FeatureExtractorCoherenceCorrect Wikification of: D.C. to : http://en.wikipedia.org/wiki/Washington,_D.C.
Could not find WikiMatchData for title Identical_note
Could not find WikiMatchData for title Folks
Could not find WikiMatchData for title Americans
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Chattanooga,_Tennessee, pred=isPartOf, arg2=Tennessee, score=9.417873573303224, normalizedScore=100.0]For surfaces CHATTANOOGA and Tenn.
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Governor, pred=WIKI_LINK_RELATION, arg2=George_W._Bush, score=3.990677833557129, normalizedScore=100.0]For surfaces Gov. and George W. Bush
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Al_Gore, pred=president, arg2=Bill_Clinton, score=11.490239191055297, normalizedScore=100.0]For surfaces Gore and President Clinton
[pool-2-thread-1] INFO edu.illinois.cs.cogcomp.edison.annotators.GazetteerViewGenerator - Finished loading  79 gazetteers from resources/gazetteers/gazetteers
InitGazetteers
Finish InitGazetteers
start loading gender file
finish loading gender file
READFILE
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Al_Gore due to a longer mention than Gore that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Al_Gore due to a longer mention than Gore that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Al_Gore due to a longer mention than Gore that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Al_Gore due to a longer mention than Gore that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bill_Clinton due to a longer mention than Clinton that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bush_family due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bush_family due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bush_family due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bush_family due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bush_family due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush_military_service_controversy due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush_presidential_campaign,_2000 due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bush_family due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Presidency_of_George_W._Bush due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bush_family due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bush_family due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bush_family due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bush_family due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bush_family due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bush_family due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush due to a longer mention than Bush that referred to the same thing
Relational inference took 31ms
CoherenceRelation 441 [arg1=[surface=Gov., solution=Governor], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=100.0] is captured by ILP inference.
CoherenceRelation 925 [arg1=[surface=Al Gore, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 925 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 3939 [arg1=[surface=Washington, solution=Washington,_D.C.], arg2=[surface=Washington, D.C., solution=Washington,_D.C.], weight=10.0] is captured by ILP inference.
CoherenceRelation 925 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 925 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 952 [arg1=[surface=President, solution=Bill_Clinton], arg2=[surface=President Clinton, solution=Bill_Clinton], weight=10.0] is captured by ILP inference.
CoherenceRelation 441 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 925 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 952 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=President Clinton, solution=Bill_Clinton], weight=50.0] is captured by ILP inference.
CoherenceRelation 441 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 925 [arg1=[surface=Vice, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 952 [arg1=[surface=Clinton, solution=Bill_Clinton], arg2=[surface=President Clinton, solution=Bill_Clinton], weight=10.0] is captured by ILP inference.
CoherenceRelation 441 [arg1=[surface=W. Bush, solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 330 [arg1=[surface=CHATTANOOGA, solution=Chattanooga,_Tennessee], arg2=[surface=Tenn., solution=Tennessee], weight=1.0] is captured by ILP inference.
CoherenceRelation 441 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 441 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 4062 [arg1=[surface=He, solution=*null*], arg2=[surface=He, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 441 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 441 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 925 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 441 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 441 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 441 [arg1=[surface=George W., solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 441 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 441 [arg1=[surface=W., solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 925 [arg1=[surface=Vice President, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 441 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 441 [arg1=[surface=George, solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 441 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 925 [arg1=[surface=President, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 441 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
Discarded 98 hypothesis
Level: Relational Coherence Correct Wikification of: CHATTANOOGA to : http://en.wikipedia.org/wiki/Chattanooga,_Tennessee
Level: Relational Coherence Correct Wikification of: Tenn. to : http://en.wikipedia.org/wiki/Tennessee
Level: Relational Coherence : Still Incorrect Wikification of: Washington; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Washington,_D.C.;
  The confusions set is : Washington,_D.C.(ranker score=0.21996975132713564) Vs: Washington(ranker score=0.598554900225994);
  The context is: ; ------- ;  17 months after he first issued his call for a ``fresh start after a season of cynicism,'' Gov. George W. Bush ended his quest for the presidency Monday on a nearly identical note, pledging to purge Washington of what he cast as a crippling discord.   The course that Bush charted over his final hours on the campaign trail, plotted with as much concern for symbolism as for raw electoral arithmetic
Level: Relational Coherence Correct Wikification of: Arkansas to : http://en.wikipedia.org/wiki/Arkansas
Level: Relational Coherence Correct Wikification of: White House to : http://en.wikipedia.org/wiki/White_House
Level: Relational Coherence Correct Wikification of: Wisconsin to : http://en.wikipedia.org/wiki/Wisconsin
Level: Relational Coherence Correct Wikification of: Iowa to : http://en.wikipedia.org/wiki/Iowa
Level: Relational Coherence Correct Wikification of: Michigan to : http://en.wikipedia.org/wiki/Michigan
Level: Relational Coherence Correct Wikification of: Pennsylvania to : http://en.wikipedia.org/wiki/Pennsylvania
Level: Relational Coherence Correct Wikification of: Green Bay to : http://en.wikipedia.org/wiki/Green_Bay,_Wisconsin
Level: Relational Coherence Correct Wikification of: D.C. to : http://en.wikipedia.org/wiki/Washington,_D.C.
Annotation at test time--98462 milliseconds elapsed to annotate the document NYT20001106.1705.0187
Final System Output:Correct Wikification of: CHATTANOOGA to : http://en.wikipedia.org/wiki/Chattanooga,_Tennessee
Candidates Entropy: 0.7653443376333094
Final System Output:Correct Wikification of: Tenn. to : http://en.wikipedia.org/wiki/Tennessee
Candidates Entropy: 0.0
Final System Output:: Still Incorrect Wikification of: Washington; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Washington,_D.C.;
  The confusions set is : Washington,_D.C.(ranker score=0.21996975132713564) Vs: Washington(ranker score=0.598554900225994);
  The context is: ; ------- ;  17 months after he first issued his call for a ``fresh start after a season of cynicism,'' Gov. George W. Bush ended his quest for the presidency Monday on a nearly identical note, pledging to purge Washington of what he cast as a crippling discord.   The course that Bush charted over his final hours on the campaign trail, plotted with as much concern for symbolism as for raw electoral arithmetic
Candidates Entropy: 1.4344235693433236
Final System Output:Correct Wikification of: Arkansas to : http://en.wikipedia.org/wiki/Arkansas
Candidates Entropy: 0.0862972589057692
Final System Output:Correct Wikification of: White House to : http://en.wikipedia.org/wiki/White_House
Candidates Entropy: 0.33431155684380115
Final System Output:Correct Wikification of: Wisconsin to : http://en.wikipedia.org/wiki/Wisconsin
Candidates Entropy: 0.3021065852788236
Final System Output:Correct Wikification of: Iowa to : http://en.wikipedia.org/wiki/Iowa
Candidates Entropy: 0.2002779746745715
Final System Output:Correct Wikification of: Michigan to : http://en.wikipedia.org/wiki/Michigan
Candidates Entropy: 0.35543495214606885
Final System Output:Correct Wikification of: Pennsylvania to : http://en.wikipedia.org/wiki/Pennsylvania
Candidates Entropy: 0.3466758195935914
Final System Output:Correct Wikification of: Green Bay to : http://en.wikipedia.org/wiki/Green_Bay,_Wisconsin
Candidates Entropy: 0.831260649619348
Final System Output:Correct Wikification of: D.C. to : http://en.wikipedia.org/wiki/Washington,_D.C.
Candidates Entropy: 1.5075330589752782
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/NYT20001106.1705.0187.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/20001115_AFP_ARB.0217.eng
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =224
		- Total unique tokens  =124
		- Total unique tokens ignore case =120
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =7
		- OOV tokens, no repetitions, Case Sensitive =5
		- Total OOV tokens even after lowercasing  =7
		- OOV tokens even after lowercasing, no repetition  =5
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =12
		- OOV tokens, no repetitions, Case Sensitive =9
		- Total OOV tokens even after lowercasing  =12
		- OOV tokens even after lowercasing, no repetition  =9
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =7
		- OOV tokens, no repetitions, Case Sensitive =6
		- Total OOV tokens even after lowercasing  =7
		- OOV tokens even after lowercasing, no repetition  =6
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 252 milliseconds
Constructing a problem for the following text: 
  Bandar Seri Begawan 11-15 (AFP) -  A Japanese official announced today Wednesday that Japan and Russia are to hold a summit before the end of the current year in an attempt to find a solution to ...
Annotating mention view..
1 milliseconds elapsed on constructing the TF-IDF representation of the input text...20001115_AFP_ARB.0217.eng
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Adding NER candidates for 20001115_AFP_ARB.0217.eng
Adding SHALLOW_PARSE and subChunk candidates for 20001115_AFP_ARB.0217.eng
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Matched regex entity Japan and Russia[88-104]{15-18}
Matched regex entity Russian President Vladimir Putin and Japanese Prime Minister Yoshiro Mori[412-485]{78-88}
Matched regex entity Russian President Boris Yeltsin and Japanese Prime Minister Riotaro Hashimoto[698-775]{128-138}
Matched regex entity Russia and Japan[888-904]{159-162}
Matched regex entity Russia and Japan[1037-1053]{184-187}
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Done constructing the Wikifiable entities
     ----  almost there....
379 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...20001115_AFP_ARB.0217.eng
Inference on the document  -- 20001115_AFP_ARB.0217.eng
19 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
4 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
412 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
9 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
198 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
5 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: Bandar Seri Begawan to : http://en.wikipedia.org/wiki/Bandar_Seri_Begawan
Level:FeatureExtractorCoherenceCorrect Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level:FeatureExtractorCoherenceCorrect Wikification of: Russia to : http://en.wikipedia.org/wiki/Russia
Level:FeatureExtractorCoherenceCorrect Wikification of: Coral Islands to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Brunei to : http://en.wikipedia.org/wiki/Brunei
Level:FeatureExtractorCoherenceCorrect Wikification of: Bandar Seri Begawan to : http://en.wikipedia.org/wiki/Bandar_Seri_Begawan
Level:FeatureExtractorCoherenceCorrect Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level:FeatureExtractorCoherenceCorrect Wikification of: Russia to : http://en.wikipedia.org/wiki/Russia
Level:FeatureExtractorCoherenceCorrect Wikification of: Coral Islands to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Brunei to : http://en.wikipedia.org/wiki/Brunei
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Irkotsik; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Irkutsk;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; ir Putin and Japanese Prime Minister Yoshiro Mori on the periphery of the Asia-Pacific Economic Cooperation forum in Brunei.   The Japanese official said that those responsible had "agreed to meet at Irkotsik (east Russia) before the end of the year.   In 1997, Russian President Boris Yeltsin and Japanese Prime Minister Riotaro Hashimoto agreed to sign the peace treaty before the end of 2000, but 
Could not find WikiMatchData for title This_year
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=President_of_Russia, pred=title, arg2=Vladimir_Putin, score=30.81285209655762, normalizedScore=100.0]For surfaces Russian President and Vladimir Putin
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Prime_Minister_of_Japan, pred=WIKI_LINK_RELATION, arg2=Yoshiro_Mori, score=6.957352542877198, normalizedScore=100.0]For surfaces Japanese Prime Minister and Yoshiro Mori
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=President_of_Russia, pred=inaugural, arg2=Boris_Yeltsin, score=22.04886999130249, normalizedScore=100.0]For surfaces Russian President and Boris Yeltsin
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Vladimir_Putin due to a longer mention than Putin that referred to the same thing
Relational inference took 5ms
CoherenceRelation 706 [arg1=[surface=Boris Yeltsin, solution=Boris_Yeltsin], arg2=[surface=President Boris Yeltsin, solution=Boris_Yeltsin], weight=10.0] is captured by ILP inference.
CoherenceRelation 473 [arg1=[surface=Japanese Prime Minister, solution=Prime_Minister_of_Japan], arg2=[surface=Yoshiro Mori, solution=Yoshirō_Mori], weight=100.0] is captured by ILP inference.
CoherenceRelation 473 [arg1=[surface=Mori, solution=Yoshirō_Mori], arg2=[surface=Yoshiro Mori, solution=Yoshirō_Mori], weight=10.0] is captured by ILP inference.
CoherenceRelation 430 [arg1=[surface=Russian President, solution=President_of_Russia], arg2=[surface=Vladimir Putin, solution=Vladimir_Putin], weight=50.0] is captured by ILP inference.
CoherenceRelation 716 [arg1=[surface=Yeltsin, solution=Boris_Yeltsin], arg2=[surface=Boris Yeltsin, solution=Boris_Yeltsin], weight=10.0] is captured by ILP inference.
CoherenceRelation 716 [arg1=[surface=Russian President, solution=President_of_Russia], arg2=[surface=Boris Yeltsin, solution=Boris_Yeltsin], weight=50.0] is captured by ILP inference.
CoherenceRelation 430 [arg1=[surface=Vladimir, solution=Vladimir_Putin], arg2=[surface=Vladimir Putin, solution=Vladimir_Putin], weight=10.0] is captured by ILP inference.
CoherenceRelation 420 [arg1=[surface=Vladimir Putin, solution=Vladimir_Putin], arg2=[surface=President Vladimir Putin, solution=Vladimir_Putin], weight=10.0] is captured by ILP inference.
CoherenceRelation 716 [arg1=[surface=Boris, solution=Boris_Yeltsin], arg2=[surface=Boris Yeltsin, solution=Boris_Yeltsin], weight=10.0] is captured by ILP inference.
CoherenceRelation 430 [arg1=[surface=Putin, solution=Vladimir_Putin], arg2=[surface=Vladimir Putin, solution=Vladimir_Putin], weight=10.0] is captured by ILP inference.
CoherenceRelation 430 [arg1=[surface=Putin, solution=Vladimir_Putin], arg2=[surface=Vladimir Putin, solution=Vladimir_Putin], weight=10.0] is captured by ILP inference.
CoherenceRelation 473 [arg1=[surface=Yoshiro, solution=Yoshirō_Mori], arg2=[surface=Yoshiro Mori, solution=Yoshirō_Mori], weight=10.0] is captured by ILP inference.
CoherenceRelation 758 [arg1=[surface=Hashimoto, solution=*null*], arg2=[surface=Riotaro Hashimoto, solution=*null*], weight=10.0] is captured by ILP inference.
Discarded 0 hypothesis
Level: Relational Coherence Correct Wikification of: Bandar Seri Begawan to : http://en.wikipedia.org/wiki/Bandar_Seri_Begawan
Level: Relational Coherence Correct Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level: Relational Coherence Correct Wikification of: Russia to : http://en.wikipedia.org/wiki/Russia
Level: Relational Coherence Correct Wikification of: Coral Islands to : http://en.wikipedia.org/wiki/*null*
Level: Relational Coherence Correct Wikification of: Brunei to : http://en.wikipedia.org/wiki/Brunei
Level: Relational Coherence : Still Incorrect Wikification of: Irkotsik; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Irkutsk;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; ir Putin and Japanese Prime Minister Yoshiro Mori on the periphery of the Asia-Pacific Economic Cooperation forum in Brunei.   The Japanese official said that those responsible had "agreed to meet at Irkotsik (east Russia) before the end of the year.   In 1997, Russian President Boris Yeltsin and Japanese Prime Minister Riotaro Hashimoto agreed to sign the peace treaty before the end of 2000, but 
Annotation at test time--918 milliseconds elapsed to annotate the document 20001115_AFP_ARB.0217.eng
Final System Output:Correct Wikification of: Bandar Seri Begawan to : http://en.wikipedia.org/wiki/Bandar_Seri_Begawan
Candidates Entropy: 0.14160549288266006
Final System Output:Correct Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Candidates Entropy: 1.7169297807752752
Final System Output:Correct Wikification of: Russia to : http://en.wikipedia.org/wiki/Russia
Candidates Entropy: 0.1059881196593798
Final System Output:Correct Wikification of: Coral Islands to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Brunei to : http://en.wikipedia.org/wiki/Brunei
Candidates Entropy: 0.5368232601935602
Final System Output:: Still Incorrect Wikification of: Irkotsik; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Irkutsk;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; ir Putin and Japanese Prime Minister Yoshiro Mori on the periphery of the Asia-Pacific Economic Cooperation forum in Brunei.   The Japanese official said that those responsible had "agreed to meet at Irkotsik (east Russia) before the end of the year.   In 1997, Russian President Boris Yeltsin and Japanese Prime Minister Riotaro Hashimoto agreed to sign the peace treaty before the end of 2000, but 
Candidates Entropy: 0.0
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/20001115_AFP_ARB.0217.eng.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/APW20001218.2221.0727
Empty problem - no reference instances!!!
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/NYT20001129.2040.0383
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =947
		- Total unique tokens  =367
		- Total unique tokens ignore case =347
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =42
		- OOV tokens, no repetitions, Case Sensitive =18
		- Total OOV tokens even after lowercasing  =41
		- OOV tokens even after lowercasing, no repetition  =17
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =47
		- OOV tokens, no repetitions, Case Sensitive =22
		- Total OOV tokens even after lowercasing  =46
		- OOV tokens even after lowercasing, no repetition  =21
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =33
		- OOV tokens, no repetitions, Case Sensitive =24
		- Total OOV tokens even after lowercasing  =31
		- OOV tokens even after lowercasing, no repetition  =22
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 1114 milliseconds
Constructing a problem for the following text: 
 QUICKLY &LR; &QL; (Repeating; this is now a New York Times front-page story) &QL; (ART ADV: Graphic is being sent to NYT graphic clients. Nonsubscribers can purchase one-time rights by calling 888...
Annotating mention view..
1 milliseconds elapsed on constructing the TF-IDF representation of the input text...NYT20001129.2040.0383
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Adding NER candidates for NYT20001129.2040.0383
Adding SHALLOW_PARSE and subChunk candidates for NYT20001129.2040.0383
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Matched regex entity TALLAHASSEE, Fla[323-339]{81-84}
Matched regex entity Lawyers for Vice President Al Gore[343-377]{85-91}
Matched regex entity District Court of Appeal[679-703]{145-149}
Matched regex entity Thursday, Gore's[787-803]{164-168}
Matched regex entity Miami-Dade and Palm Beach[1266-1291]{255-259}
Matched regex entity Dade and Palm Beach[1272-1291]{255-259}
Matched regex entity Tallahassee at the Gore[1479-1502]{293-297}
Matched regex entity Barry Richard, Bush's[1591-1612]{317-322}
Matched regex entity David Boies, Gore's[2321-2340]{470-475}
Matched regex entity Nonetheless, Gore's[2373-2392]{482-486}
Matched regex entity Electoral College, Gore[2896-2919]{578-582}
Matched regex entity Court of Appeal[3722-3737]{744-747}
Matched regex entity Florida Supreme Court, and Gore's[4157-4190]{829-836}
Matched regex entity If the Supreme Court[4605-4625]{921-925}
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Done constructing the Wikifiable entities
     ----  almost there....
841 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...NYT20001129.2040.0383
Inference on the document  -- NYT20001129.2040.0383
4 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
7 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
109 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
14 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
908 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
7 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: TALLAHASSEE to : http://en.wikipedia.org/wiki/Tallahassee,_Florida
Level:FeatureExtractorCoherenceCorrect Wikification of: Fla. to : http://en.wikipedia.org/wiki/Florida
Level:FeatureExtractorCoherenceCorrect Wikification of: Supreme Court to : http://en.wikipedia.org/wiki/Supreme_Court_of_Florida
Level:FeatureExtractorCoherenceCorrect Wikification of: Barry Richard to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Electoral College to : http://en.wikipedia.org/wiki/Electoral_College_(United_States)
Level:FeatureExtractorCoherenceCorrect Wikification of: Kendall Coffey to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: TALLAHASSEE to : http://en.wikipedia.org/wiki/Tallahassee,_Florida
Level:FeatureExtractorCoherenceCorrect Wikification of: Fla. to : http://en.wikipedia.org/wiki/Florida
Level:FeatureExtractorCoherenceCorrect Wikification of: Supreme Court to : http://en.wikipedia.org/wiki/Supreme_Court_of_Florida
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: District Court of Appeal; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Florida_District_Courts_of_Appeal;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; d if they have to wait until Saturday to begin counting disputed ballots, and they began an appeal to the Florida Supreme Court to do the counting itself, immediately.   The appeal was filed with the District Court of Appeal late Wednesday afternoon, and will be submitted to the state's highest court early Thursday, Gore's lawyers said. It essentially asks the Supreme Court to take over Gore's con
Level:FeatureExtractorCoherenceCorrect Wikification of: Barry Richard to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Electoral College to : http://en.wikipedia.org/wiki/Electoral_College_(United_States)
Level:FeatureExtractorCoherenceCorrect Wikification of: Kendall Coffey to : http://en.wikipedia.org/wiki/*null*
Could not find WikiMatchData for title Enormous_(band)
Could not find WikiMatchData for title Huntington's_Disease_Outreach_Project_for_Education_at_Stanford
Could not find WikiMatchData for title Perilous
Could not find WikiMatchData for title Allow
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Tallahassee,_Florida, pred=capital, arg2=Florida, score=13.760082864761351, normalizedScore=100.0]For surfaces TALLAHASSEE and Fla.
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=District_Court_of_South_Australia, pred=WIKI_LINK_RELATION, arg2=Appeal, score=2.258237600326538, normalizedScore=0.21247745517146127]For surfaces District Court and Appeal
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=District_court, pred=WIKI_LINK_RELATION, arg2=Court_of_Criminal_Appeal, score=1.9108270406723022, normalizedScore=0.25299022722700387]For surfaces District Court and Appeal
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Electoral_College_(United_States), pred=WIKI_LINK_RELATION, arg2=Al_Gore, score=3.1498504638671876, normalizedScore=100.0]For surfaces Electoral College and Gore
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Barry Richard[1591-1604]{317-319} === Bush 's chief trial lawyer here
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:David Boies[2321-2332]{470-472} === Gore 's chief trial lawyer
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Gore[2915-2919]{581-582} === electors for the Electoral College
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Kendall Coffey[2978-2992]{597-599} === one of Gore 's election lawyers
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Al_Gore due to a longer mention than Gore that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Al_Gore due to a longer mention than Gore that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Al_Gore due to a longer mention than Gore that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Al_Gore due to a longer mention than Gore that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Al_Gore due to a longer mention than Gore that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Al_Gore due to a longer mention than Gore that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bush_family due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush_military_service_controversy due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush_presidential_campaign,_2000 due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bush_family due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Presidency_of_George_W._Bush due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush due to a longer mention than Bush that referred to the same thing
Relational inference took 15ms
CoherenceRelation 2321 [arg1=[surface=Boies, solution=David_Boies], arg2=[surface=David Boies, solution=David_Boies], weight=10.0] is captured by ILP inference.
CoherenceRelation 355 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 3722 [arg1=[surface=Court, solution=*null*], arg2=[surface=Court of Appeal, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 1591 [arg1=[surface=Richard, solution=*null*], arg2=[surface=Barry Richard, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 355 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 355 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 1591 [arg1=[surface=Barry, solution=*null*], arg2=[surface=Barry Richard, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 585 [arg1=[surface=Supreme Court, solution=Supreme_Court_of_Florida], arg2=[surface=Florida Supreme Court, solution=Supreme_Court_of_Florida], weight=10.0] is captured by ILP inference.
CoherenceRelation 4157 [arg1=[surface=Supreme Court, solution=Supreme_Court_of_Florida], arg2=[surface=Florida Supreme Court, solution=Supreme_Court_of_Florida], weight=10.0] is captured by ILP inference.
CoherenceRelation 355 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 355 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 2321 [arg1=[surface=David, solution=David_Boies], arg2=[surface=David Boies, solution=David_Boies], weight=10.0] is captured by ILP inference.
CoherenceRelation 1199 [arg1=[surface=Sanders, solution=*null*], arg2=[surface=N. Sanders Sauls, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 355 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 355 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 2915 [arg1=[surface=Electoral College, solution=Electoral_College_(United_States)], arg2=[surface=Gore, solution=Al_Gore], weight=100.0] is captured by ILP inference.
CoherenceRelation 355 [arg1=[surface=Vice President, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 4157 [arg1=[surface=Supreme Court, solution=Supreme_Court_of_Florida], arg2=[surface=Florida Supreme Court, solution=Supreme_Court_of_Florida], weight=10.0] is captured by ILP inference.
CoherenceRelation 2978 [arg1=[surface=Kendall, solution=*null*], arg2=[surface=Kendall Coffey, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 1044 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 4157 [arg1=[surface=Florida Supreme Court, solution=Supreme_Court_of_Florida], arg2=[surface=Florida Supreme Court, solution=Supreme_Court_of_Florida], weight=10.0] is captured by ILP inference.
CoherenceRelation 2653 [arg1=[surface=Supreme Court, solution=Supreme_Court_of_Florida], arg2=[surface=Florida Supreme Court, solution=Supreme_Court_of_Florida], weight=10.0] is captured by ILP inference.
CoherenceRelation 355 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 355 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 355 [arg1=[surface=President, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 1044 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 1044 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 1044 [arg1=[surface=W., solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 355 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 2978 [arg1=[surface=Coffey, solution=*null*], arg2=[surface=Kendall Coffey, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 1591 [arg1=[surface=Richard, solution=*null*], arg2=[surface=Barry Richard, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 1044 [arg1=[surface=George, solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 1199 [arg1=[surface=Sanders, solution=*null*], arg2=[surface=N. Sanders Sauls, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 355 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 355 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 1044 [arg1=[surface=W. Bush, solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 1199 [arg1=[surface=N., solution=*null*], arg2=[surface=N. Sanders Sauls, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 355 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 355 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 355 [arg1=[surface=Al Gore, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 1199 [arg1=[surface=Sauls, solution=*null*], arg2=[surface=N. Sanders Sauls, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 336 [arg1=[surface=TALLAHASSEE, solution=Tallahassee,_Florida], arg2=[surface=Fla., solution=Florida], weight=1.0] is captured by ILP inference.
CoherenceRelation 4157 [arg1=[surface=Florida Supreme Court, solution=Supreme_Court_of_Florida], arg2=[surface=Florida Supreme Court, solution=Supreme_Court_of_Florida], weight=10.0] is captured by ILP inference.
CoherenceRelation 355 [arg1=[surface=Vice, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 679 [arg1=[surface=Court of Appeal, solution=*null*], arg2=[surface=District Court of Appeal, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 1044 [arg1=[surface=George W., solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 1199 [arg1=[surface=Sanders Sauls, solution=*null*], arg2=[surface=N. Sanders Sauls, solution=*null*], weight=10.0] is captured by ILP inference.
Discarded 30 hypothesis
Level: Relational Coherence Correct Wikification of: TALLAHASSEE to : http://en.wikipedia.org/wiki/Tallahassee,_Florida
Level: Relational Coherence Correct Wikification of: Fla. to : http://en.wikipedia.org/wiki/Florida
Level: Relational Coherence Correct Wikification of: Supreme Court to : http://en.wikipedia.org/wiki/Supreme_Court_of_Florida
Level: Relational Coherence : Still Incorrect Wikification of: District Court of Appeal; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Florida_District_Courts_of_Appeal;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; d if they have to wait until Saturday to begin counting disputed ballots, and they began an appeal to the Florida Supreme Court to do the counting itself, immediately.   The appeal was filed with the District Court of Appeal late Wednesday afternoon, and will be submitted to the state's highest court early Thursday, Gore's lawyers said. It essentially asks the Supreme Court to take over Gore's con
Level: Relational Coherence Correct Wikification of: Barry Richard to : http://en.wikipedia.org/wiki/*null*
Level: Relational Coherence Correct Wikification of: Electoral College to : http://en.wikipedia.org/wiki/Electoral_College_(United_States)
Level: Relational Coherence Correct Wikification of: Kendall Coffey to : http://en.wikipedia.org/wiki/*null*
Annotation at test time--1590 milliseconds elapsed to annotate the document NYT20001129.2040.0383
Final System Output:Correct Wikification of: TALLAHASSEE to : http://en.wikipedia.org/wiki/Tallahassee,_Florida
Candidates Entropy: 0.5846456632656545
Final System Output:Correct Wikification of: Fla. to : http://en.wikipedia.org/wiki/Florida
Candidates Entropy: 0.06488451231299479
Final System Output:Correct Wikification of: Supreme Court to : http://en.wikipedia.org/wiki/Supreme_Court_of_Florida
Candidates Entropy: 0.0
Final System Output:: Still Incorrect Wikification of: District Court of Appeal; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Florida_District_Courts_of_Appeal;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; d if they have to wait until Saturday to begin counting disputed ballots, and they began an appeal to the Florida Supreme Court to do the counting itself, immediately.   The appeal was filed with the District Court of Appeal late Wednesday afternoon, and will be submitted to the state's highest court early Thursday, Gore's lawyers said. It essentially asks the Supreme Court to take over Gore's con
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Barry Richard to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Electoral College to : http://en.wikipedia.org/wiki/Electoral_College_(United_States)
Candidates Entropy: 0.7078511296751397
Final System Output:Correct Wikification of: Kendall Coffey to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/NYT20001129.2040.0383.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/APW20001120.1450.0376
Empty problem - no reference instances!!!
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/VOA20001208.2000.1275
Empty problem - no reference instances!!!
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/NYT20001125.1558.0117
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =736
		- Total unique tokens  =318
		- Total unique tokens ignore case =304
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =30
		- OOV tokens, no repetitions, Case Sensitive =12
		- Total OOV tokens even after lowercasing  =28
		- OOV tokens even after lowercasing, no repetition  =10
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =37
		- OOV tokens, no repetitions, Case Sensitive =17
		- Total OOV tokens even after lowercasing  =37
		- OOV tokens even after lowercasing, no repetition  =16
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =28
		- OOV tokens, no repetitions, Case Sensitive =21
		- Total OOV tokens even after lowercasing  =26
		- OOV tokens even after lowercasing, no repetition  =19
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 618 milliseconds
Constructing a problem for the following text: 
 &UR; c.2000 N.Y. Times News Service &LR; &QC; &QL;    GROSSE POINTE PARK, Mich. _ It is deer hunting season in Michigan, and hunters who climb trees with loaded shotguns have state officials redou...
Annotating mention view..
1 milliseconds elapsed on constructing the TF-IDF representation of the input text...NYT20001125.1558.0117
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Adding NER candidates for NYT20001125.1558.0117
Adding SHALLOW_PARSE and subChunk candidates for NYT20001125.1558.0117
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Matched regex entity GROSSE POINTE PARK, Mich[55-79]{17-22}
Matched regex entity New York and Pennsylvania[640-665]{122-126}
Matched regex entity York and Pennsylvania[644-665]{123-126}
Matched regex entity Michigan Department of Natural Resources[895-935]{169-174}
Matched regex entity Department of Natural Resources[904-935]{170-174}
Matched regex entity For Williams, Rule No[2492-2513]{473-478}
Matched regex entity Williams, Rule No[2496-2513]{474-478}
Matched regex entity Others, Koppelo[3418-3433]{668-671}
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Done constructing the Wikifiable entities
     ----  almost there....
332 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...NYT20001125.1558.0117
Inference on the document  -- NYT20001125.1558.0117
5 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
7 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
219 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
13 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
162 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
9 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: GROSSE POINTE PARK to : http://en.wikipedia.org/wiki/Grosse_Pointe_Park,_Michigan
Level:FeatureExtractorCoherenceCorrect Wikification of: Mich. to : http://en.wikipedia.org/wiki/Michigan
Level:FeatureExtractorCoherenceCorrect Wikification of: New York to : http://en.wikipedia.org/wiki/New_York
Level:FeatureExtractorCoherenceCorrect Wikification of: Pennsylvania to : http://en.wikipedia.org/wiki/Pennsylvania
Level:FeatureExtractorCoherenceCorrect Wikification of: Detroit to : http://en.wikipedia.org/wiki/Detroit
Level:FeatureExtractorCoherenceCorrect Wikification of: GROSSE POINTE PARK to : http://en.wikipedia.org/wiki/Grosse_Pointe_Park,_Michigan
Level:FeatureExtractorCoherenceCorrect Wikification of: Mich. to : http://en.wikipedia.org/wiki/Michigan
Level:FeatureExtractorCoherenceCorrect Wikification of: New York to : http://en.wikipedia.org/wiki/New_York
Level:FeatureExtractorCoherenceCorrect Wikification of: Pennsylvania to : http://en.wikipedia.org/wiki/Pennsylvania
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Department of Natural Resources; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Georgia_Department_of_Natural_Resources ; the gold is: http://en.wikipedia.org/wiki/Michigan_Department_of_Natural_Resources;
  The confusions set is : List_of_environmental_agencies_in_the_United_States(ranker score=2.5583855784009866) Vs: Georgia_Department_of_Natural_Resources(ranker score=2.783648567687252);
  The context is: ; ------- ;  season in Michigan, and officials say it appears that hunters still have a lot to learn about safety. Lt. Suzanne Koppelo, hunter safety administrator of the law enforcement division of the Michigan Department of Natural Resources &UR; , &LR; said that since firearm platform hunting began in Michigan there had been seven shooting accidents linked to the practice. Three were fatal. Two hunters sho
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Rob Williams; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Robert_Williams ; the gold is: http://en.wikipedia.org/wiki/*null*;
  The confusions set is : Rob_Williams_(basketball)(ranker score=1.1187487143660853) Vs: Robert_Williams(ranker score=3.371011310952933);
  The context is: ; ------- ;  ground, rather than whistling through the woods and striking other people.   The problems primarily arise when hunters get in and out of position.   ``It's kind of hard climbing a tree with a gun,'' Rob Williams said, as he and a hunting partner, Art Bush, waited on a recent morning in a conventional earthbound hunting blind about 20 miles west of Detroit.   For Williams, Rule No. 1 is not to cli
Level:FeatureExtractorCoherenceCorrect Wikification of: Detroit to : http://en.wikipedia.org/wiki/Detroit
Level:FeatureExtractorCoherenceCorrect Wikification of: Peter Thompson to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherencethis fixes the Wikification (!!!)Peter Thompson; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/*null*;
  The confusions set is : Peter_Thompson_(English_footballer)(ranker score=1.536052737588871) Vs: Peter_Thompson(ranker score=2.3867397689144525);
  The context is: ; ------- ; that though anecdotal reports show Michigan's large hunting population to be taking slowly to firearm deer hunting from platforms, most expect the practice to catch on as it has in other states.   As Peter Thompson, a 16-year-old hunter, said, ``Usually the deer don't look up.''  
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Grosse_Pointe_Park,_Michigan, pred=isPartOf, arg2=Michigan, score=12.951324462890625, normalizedScore=100.0]For surfaces GROSSE POINTE PARK and Mich.
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Suzanne Koppelo[811-826]{156-158} === hunter safety administrator of the law enforcement division of the Michigan Department of Natural Resources
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Sgt. Larry D. Sargent[1941-1962]{370-374} === the hunter killed from the platform
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Sgt. Larry D. Sargent[1941-1962]{370-374} === hunter education field coordinator for the law enforcement division
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Art Bush[2378-2386]{452-454} === a hunting partner
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Peter Thompson[3719-3733]{726-728} === a 16-year-old hunter
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - Force linking Peter Thompson[3719-3733]{726-728} to null
Relational inference took 13ms
CoherenceRelation 3719 [arg1=[surface=Peter, solution=*null*], arg2=[surface=Peter Thompson, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 811 [arg1=[surface=Koppelo, solution=*null*], arg2=[surface=Suzanne Koppelo, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 2378 [arg1=[surface=Bush, solution=*null*], arg2=[surface=Art Bush, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 1941 [arg1=[surface=Larry, solution=*null*], arg2=[surface=Sgt. Larry D. Sargent, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 1941 [arg1=[surface=Sargent, solution=*null*], arg2=[surface=Sgt. Larry D. Sargent, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 1941 [arg1=[surface=Sgt., solution=*null*], arg2=[surface=Sgt. Larry D. Sargent, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 1941 [arg1=[surface=Sargent, solution=*null*], arg2=[surface=Sgt. Larry D. Sargent, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 1941 [arg1=[surface=Larry D. Sargent, solution=*null*], arg2=[surface=Sgt. Larry D. Sargent, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 2330 [arg1=[surface=Williams, solution=Robert_Williams], arg2=[surface=Rob Williams, solution=Robert_Williams], weight=10.0] is captured by ILP inference.
CoherenceRelation 895 [arg1=[surface=Department of Natural Resources, solution=Michigan_Department_of_Natural_Resources], arg2=[surface=Michigan Department of Natural Resources, solution=Michigan_Department_of_Natural_Resources], weight=10.0] is captured by ILP inference.
CoherenceRelation 1941 [arg1=[surface=D., solution=*null*], arg2=[surface=Sgt. Larry D. Sargent, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 2378 [arg1=[surface=Art, solution=*null*], arg2=[surface=Art Bush, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 75 [arg1=[surface=GROSSE POINTE PARK, solution=Grosse_Pointe_Park,_Michigan], arg2=[surface=Mich., solution=Michigan], weight=1.0] is captured by ILP inference.
CoherenceRelation 3719 [arg1=[surface=Thompson, solution=*null*], arg2=[surface=Peter Thompson, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 811 [arg1=[surface=Koppelo, solution=*null*], arg2=[surface=Suzanne Koppelo, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 811 [arg1=[surface=Suzanne, solution=*null*], arg2=[surface=Suzanne Koppelo, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 811 [arg1=[surface=Koppelo, solution=*null*], arg2=[surface=Suzanne Koppelo, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 811 [arg1=[surface=Koppelo, solution=*null*], arg2=[surface=Suzanne Koppelo, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 1941 [arg1=[surface=Sargent, solution=*null*], arg2=[surface=Sgt. Larry D. Sargent, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 2330 [arg1=[surface=Rob, solution=Robert_Williams], arg2=[surface=Rob Williams, solution=Robert_Williams], weight=10.0] is captured by ILP inference.
CoherenceRelation 2330 [arg1=[surface=Williams, solution=Robert_Williams], arg2=[surface=Rob Williams, solution=Robert_Williams], weight=10.0] is captured by ILP inference.
CoherenceRelation 811 [arg1=[surface=Koppelo, solution=*null*], arg2=[surface=Suzanne Koppelo, solution=*null*], weight=10.0] is captured by ILP inference.
Discarded 11 hypothesis
Level: Relational Coherence Correct Wikification of: GROSSE POINTE PARK to : http://en.wikipedia.org/wiki/Grosse_Pointe_Park,_Michigan
Level: Relational Coherence Correct Wikification of: Mich. to : http://en.wikipedia.org/wiki/Michigan
Level: Relational Coherence Correct Wikification of: New York to : http://en.wikipedia.org/wiki/New_York
Level: Relational Coherence Correct Wikification of: Pennsylvania to : http://en.wikipedia.org/wiki/Pennsylvania
Level: Relational Coherence Correct Wikification of: Department of Natural Resources to : http://en.wikipedia.org/wiki/Michigan_Department_of_Natural_Resources
Level: Relational Coherence this fixes the Wikification (!!!)Department of Natural Resources; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Michigan_Department_of_Natural_Resources ; the gold is: http://en.wikipedia.org/wiki/Michigan_Department_of_Natural_Resources;
  The surface form has a single disambiguation candidate : Michigan_Department_of_Natural_Resources(ranker score=1.0) ;
  The context is: ; ------- ;  season in Michigan, and officials say it appears that hunters still have a lot to learn about safety. Lt. Suzanne Koppelo, hunter safety administrator of the law enforcement division of the Michigan Department of Natural Resources &UR; , &LR; said that since firearm platform hunting began in Michigan there had been seven shooting accidents linked to the practice. Three were fatal. Two hunters sho
Level: Relational Coherence : Still Incorrect Wikification of: Rob Williams; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Robert_Williams ; the gold is: http://en.wikipedia.org/wiki/*null*;
  The confusions set is : Rob_Williams_(basketball)(ranker score=0.09515447657529864) Vs: Robert_Williams(ranker score=0.9048455234247013);
  The context is: ; ------- ;  ground, rather than whistling through the woods and striking other people.   The problems primarily arise when hunters get in and out of position.   ``It's kind of hard climbing a tree with a gun,'' Rob Williams said, as he and a hunting partner, Art Bush, waited on a recent morning in a conventional earthbound hunting blind about 20 miles west of Detroit.   For Williams, Rule No. 1 is not to cli
Level: Relational Coherence Correct Wikification of: Detroit to : http://en.wikipedia.org/wiki/Detroit
Level: Relational Coherence Correct Wikification of: Peter Thompson to : http://en.wikipedia.org/wiki/*null*
Annotation at test time--674 milliseconds elapsed to annotate the document NYT20001125.1558.0117
Final System Output:Correct Wikification of: GROSSE POINTE PARK to : http://en.wikipedia.org/wiki/Grosse_Pointe_Park,_Michigan
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Mich. to : http://en.wikipedia.org/wiki/Michigan
Candidates Entropy: 0.15352473048484988
Final System Output:Correct Wikification of: New York to : http://en.wikipedia.org/wiki/New_York
Candidates Entropy: 0.7869989106600758
Final System Output:Correct Wikification of: Pennsylvania to : http://en.wikipedia.org/wiki/Pennsylvania
Candidates Entropy: 0.48783272690234897
Final System Output:Correct Wikification of: Department of Natural Resources to : http://en.wikipedia.org/wiki/Michigan_Department_of_Natural_Resources
Candidates Entropy: 0.0
Final System Output:: Still Incorrect Wikification of: NIL [NER, PER]Entity:Rob Williams; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Robert_Williams ; the gold is: http://en.wikipedia.org/wiki/*null*;
  The confusions set is : Rob_Williams_(basketball)(ranker score=0.09515447657529864) Vs: Robert_Williams(ranker score=0.9048455234247013);
  The context is: ; ------- ;  ground, rather than whistling through the woods and striking other people.   The problems primarily arise when hunters get in and out of position.   ``It's kind of hard climbing a tree with a gun,'' Rob Williams said, as he and a hunting partner, Art Bush, waited on a recent morning in a conventional earthbound hunting blind about 20 miles west of Detroit.   For Williams, Rule No. 1 is not to cli
Candidates Entropy: 0.3143039106885486
Final System Output:Correct Wikification of: Detroit to : http://en.wikipedia.org/wiki/Detroit
Candidates Entropy: 0.8575767104865031
Final System Output:Correct Wikification of: Peter Thompson to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 1.1200452717648028
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/NYT20001125.1558.0117.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/VOA20001020.2100.1853
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =62
		- Total unique tokens  =51
		- Total unique tokens ignore case =50
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =0
		- OOV tokens, no repetitions, Case Sensitive =0
		- Total OOV tokens even after lowercasing  =0
		- OOV tokens even after lowercasing, no repetition  =0
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =0
		- OOV tokens, no repetitions, Case Sensitive =0
		- Total OOV tokens even after lowercasing  =0
		- OOV tokens even after lowercasing, no repetition  =0
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =1
		- OOV tokens, no repetitions, Case Sensitive =1
		- Total OOV tokens even after lowercasing  =1
		- OOV tokens even after lowercasing, no repetition  =1
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 72 milliseconds
Constructing a problem for the following text: 
 The US navy now says the USS Cole was being refueled when an explosion ripped through it in Yemen last week, killing 17. The revised accounting of the incident was given in a navy statement Friday...
0 milliseconds elapsed on constructing the TF-IDF representation of the input text...VOA20001020.2100.1853
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Annotating mention view..
Adding NER candidates for VOA20001020.2100.1853
Adding SHALLOW_PARSE and subChunk candidates for VOA20001020.2100.1853
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Done constructing the Wikifiable entities
     ----  almost there....
53 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...VOA20001020.2100.1853
Inference on the document  -- VOA20001020.2100.1853
1 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
0 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
13 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
1 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
4 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
1 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: Yemen to : http://en.wikipedia.org/wiki/Yemen
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: navy; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Seabee ; the gold is: http://en.wikipedia.org/wiki/United_States_Navy;
  The surface form has a single disambiguation candidate : Seabee(ranker score=3.9580833967444082) ;
  The context is: ; ------- ;  The US navy now says the USS Cole was being refueled when an explosion ripped through it in Yemen last week, killing 17. The revised accounting of the incident was given in a navy statement Friday raising ne
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: USS Cole; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/USS_Cole_(DDG-67) ; the gold is: http://en.wikipedia.org/wiki/USS_COLE_(DDG-67);
  The confusions set is : USS_Cole(ranker score=5.142359633035273) Vs: USS_Cole_(DDG-67)(ranker score=5.2181619989539305);
  The context is: ; ------- ;  The US navy now says the USS Cole was being refueled when an explosion ripped through it in Yemen last week, killing 17. The revised accounting of the incident was given in a navy statement Friday raising new questions about 
Level:FeatureExtractorCoherenceCorrect Wikification of: Yemen to : http://en.wikipedia.org/wiki/Yemen
Relational inference took 2ms
CoherenceRelation 26 [arg1=[surface=USS, solution=USS_Cole_(DDG-67)], arg2=[surface=USS Cole, solution=USS_Cole_(DDG-67)], weight=10.0] is captured by ILP inference.
CoherenceRelation 26 [arg1=[surface=Cole, solution=USS_Cole_(DDG-67)], arg2=[surface=USS Cole, solution=USS_Cole_(DDG-67)], weight=10.0] is captured by ILP inference.
Discarded 4 hypothesis
Level: Relational Coherence : Still Incorrect Wikification of: navy; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Seabee ; the gold is: http://en.wikipedia.org/wiki/United_States_Navy;
  The surface form has a single disambiguation candidate : Seabee(ranker score=1.0) ;
  The context is: ; ------- ;  The US navy now says the USS Cole was being refueled when an explosion ripped through it in Yemen last week, killing 17. The revised accounting of the incident was given in a navy statement Friday raising ne
Level: Relational Coherence : Still Incorrect Wikification of: USS Cole; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/USS_Cole_(DDG-67) ; the gold is: http://en.wikipedia.org/wiki/USS_COLE_(DDG-67);
  The confusions set is : USS_Cole(ranker score=0.446752203424837) Vs: USS_Cole_(DDG-67)(ranker score=0.48193365149062156);
  The context is: ; ------- ;  The US navy now says the USS Cole was being refueled when an explosion ripped through it in Yemen last week, killing 17. The revised accounting of the incident was given in a navy statement Friday raising new questions about 
Level: Relational Coherence Correct Wikification of: Yemen to : http://en.wikipedia.org/wiki/Yemen
Annotation at test time--105 milliseconds elapsed to annotate the document VOA20001020.2100.1853
Final System Output:: Still Incorrect Wikification of: navy; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Seabee ; the gold is: http://en.wikipedia.org/wiki/United_States_Navy;
  The surface form has a single disambiguation candidate : Seabee(ranker score=1.0) ;
  The context is: ; ------- ;  The US navy now says the USS Cole was being refueled when an explosion ripped through it in Yemen last week, killing 17. The revised accounting of the incident was given in a navy statement Friday raising ne
Candidates Entropy: 0.0
Final System Output:: Still Incorrect Wikification of: USS Cole; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/USS_Cole_(DDG-67) ; the gold is: http://en.wikipedia.org/wiki/USS_COLE_(DDG-67);
  The confusions set is : USS_Cole(ranker score=0.446752203424837) Vs: USS_Cole_(DDG-67)(ranker score=0.48193365149062156);
  The context is: ; ------- ;  The US navy now says the USS Cole was being refueled when an explosion ripped through it in Yemen last week, killing 17. The revised accounting of the incident was given in a navy statement Friday raising new questions about 
Candidates Entropy: 0.9000744762995594
Final System Output:Correct Wikification of: Yemen to : http://en.wikipedia.org/wiki/Yemen
Candidates Entropy: 0.22019027536676217
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/VOA20001020.2100.1853.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/APW20001225.2035.0477
Empty problem - no reference instances!!!
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/chtb_165.eng
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =422
		- Total unique tokens  =187
		- Total unique tokens ignore case =178
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =5
		- OOV tokens, no repetitions, Case Sensitive =5
		- Total OOV tokens even after lowercasing  =5
		- OOV tokens even after lowercasing, no repetition  =5
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =23
		- OOV tokens, no repetitions, Case Sensitive =10
		- Total OOV tokens even after lowercasing  =23
		- OOV tokens even after lowercasing, no repetition  =10
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =6
		- OOV tokens, no repetitions, Case Sensitive =6
		- Total OOV tokens even after lowercasing  =6
		- OOV tokens even after lowercasing, no repetition  =6
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 464 milliseconds
Constructing a problem for the following text: 
  Xinhua News Agency, Shanghai, April 3rd, by reporter Jierong Zhou  Recently, HSBC has moved its Shanghai branch to the China Shipping Mansion in the Pudong Lujiazui financial trading district, be...
Annotating mention view..
1 milliseconds elapsed on constructing the TF-IDF representation of the input text...chtb_165.eng
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Adding NER candidates for chtb_165.eng
Adding SHALLOW_PARSE and subChunk candidates for chtb_165.eng
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Matched regex entity Shanghai, April[22-37]{4-7}
Matched regex entity Jierong Zhou Recently, HSBC[55-83]{11-16}
Matched regex entity China Shipping Mansion in the Pudong Lujiazui[121-166]{23-30}
Matched regex entity Shanghai's BNP Paris Bank, the Shanghai Branch of Japan's Dai-Ichi Kangyo Bank and the Shanghai Branch of Japan's Sanwa Bank[549-673]{102-126}
Matched regex entity BNP Paris Bank, the Shanghai Branch of Japan's Dai-Ichi Kangyo Bank and the Shanghai Branch of Japan's Sanwa Bank[560-673]{104-126}
Matched regex entity Shanghai Branch of Japan's Dai-Ichi Kangyo Bank and the Shanghai Branch of Japan's Sanwa Bank[580-673]{109-126}
Matched regex entity Japan's Dai-Ichi Kangyo Bank and the Shanghai Branch of Japan's Sanwa Bank[599-673]{112-126}
Matched regex entity Dai-Ichi Kangyo Bank and the Shanghai Branch of Japan's Sanwa Bank[607-673]{114-126}
Matched regex entity Ichi Kangyo Bank and the Shanghai Branch of Japan's Sanwa Bank[611-673]{114-126}
Matched regex entity Shanghai Branch of Japan's Sanwa Bank[636-673]{119-126}
Matched regex entity Japan's Sanwa Bank[655-673]{122-126}
Matched regex entity The Franklin Templeton Company[1229-1259]{219-223}
Matched regex entity Franklin Templeton Company[1233-1259]{220-223}
Matched regex entity Templeton Company[1242-1259]{221-223}
Matched regex entity California, the US[1287-1305]{228-232}
Matched regex entity Now, the Templeton Company[1680-1706]{297-302}
Matched regex entity Templeton Company[1689-1706]{300-302}
Matched regex entity Holland Co-operation Bank, Shanghai Branch of the Belgium Credit Bank[1960-2029]{347-358}
Matched regex entity Shanghai Branch of the Belgium Credit Bank[1987-2029]{351-358}
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Important warning: the manually defined entity Pudong Lujiazui financial trading district had 0 disambiguation candidates
Done constructing the Wikifiable entities
     ----  almost there....
627 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...chtb_165.eng
Inference on the document  -- chtb_165.eng
4 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
8 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
96 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
12 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
496 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
7 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: Xinhua News Agency to : http://en.wikipedia.org/wiki/Xinhua_News_Agency
Level:FeatureExtractorCoherenceCorrect Wikification of: Shanghai to : http://en.wikipedia.org/wiki/Shanghai
Level:FeatureExtractorCoherenceCorrect Wikification of: HSBC to : http://en.wikipedia.org/wiki/HSBC
Level:FeatureExtractorCoherenceCorrect Wikification of: Pudong to : http://en.wikipedia.org/wiki/Pudong
Level:FeatureExtractorCoherenceCorrect Wikification of: US to : http://en.wikipedia.org/wiki/United_States
Level:FeatureExtractorCoherenceCorrect Wikification of: Citibank to : http://en.wikipedia.org/wiki/Citibank
Level:FeatureExtractorCoherenceCorrect Wikification of: Hong Kong to : http://en.wikipedia.org/wiki/Hong_Kong
Level:FeatureExtractorCoherenceCorrect Wikification of: Japan to : http://en.wikipedia.org/wiki/Japan
Level:FeatureExtractorCoherenceCorrect Wikification of: Tokyo Mitsubishi Bank to : http://en.wikipedia.org/wiki/The_Bank_of_Tokyo-Mitsubishi_UFJ
Level:FeatureExtractorCoherenceCorrect Wikification of: Xinhua News Agency to : http://en.wikipedia.org/wiki/Xinhua_News_Agency
Level:FeatureExtractorCoherenceCorrect Wikification of: Shanghai to : http://en.wikipedia.org/wiki/Shanghai
Level:FeatureExtractorCoherence: this introduces a Wikification error(!!!): HSBC; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/HSBC;
  The confusions set is : The_Hongkong_and_Shanghai_Banking_Corporation(ranker score=5.536256179372992) Vs: HSBC(ranker score=5.815407469274047);
  The context is: ; ------- ;   Xinhua News Agency, Shanghai, April 3rd, by reporter Jierong Zhou  Recently, HSBC has moved its Shanghai branch to the China Shipping Mansion in the Pudong Lujiazui financial trading district, becoming the third foreign capital bank to be approved to operate RMB business and s
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: China Shipping Mansion; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/International_Ocean_Shipping_Building;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ;   Xinhua News Agency, Shanghai, April 3rd, by reporter Jierong Zhou  Recently, HSBC has moved its Shanghai branch to the China Shipping Mansion in the Pudong Lujiazui financial trading district, becoming the third foreign capital bank to be approved to operate RMB business and shift to Pudong.   At the moment, Shanghai 
Level:FeatureExtractorCoherenceCorrect Wikification of: Pudong to : http://en.wikipedia.org/wiki/Pudong
Level:FeatureExtractorCoherenceCorrect Wikification of: US to : http://en.wikipedia.org/wiki/United_States
Level:FeatureExtractorCoherenceCorrect Wikification of: Citibank to : http://en.wikipedia.org/wiki/Citibank
Level:FeatureExtractorCoherenceCorrect Wikification of: Hong Kong to : http://en.wikipedia.org/wiki/Hong_Kong
Level:FeatureExtractorCoherenceCorrect Wikification of: Japan to : http://en.wikipedia.org/wiki/Japan
Level:FeatureExtractorCoherenceCorrect Wikification of: Tokyo Mitsubishi Bank to : http://en.wikipedia.org/wiki/The_Bank_of_Tokyo-Mitsubishi_UFJ
Could not find WikiMatchData for title Allow
Could not find WikiMatchData for title Gross_floor_area
Could not find WikiMatchData for title Credit_Bank
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Pudong, pred=WIKI_LINK_RELATION, arg2=Lujiazui, score=13.201040210723878, normalizedScore=100.0]For surfaces Pudong and Lujiazui
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Shanghai_Stock_Exchange, pred=WIKI_LINK_RELATION, arg2=Security_(finance), score=1.8201709985733032, normalizedScore=100.0]For surfaces Shanghai and Securities
Relational inference took 12ms
CoherenceRelation 879 [arg1=[surface=RMB, solution=Renminbi], arg2=[surface=RMB, solution=Renminbi], weight=10.0] is captured by ILP inference.
CoherenceRelation 1233 [arg1=[surface=Templeton Company, solution=*null*], arg2=[surface=Franklin Templeton Company, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 1900 [arg1=[surface=HSBC, solution=The_Hongkong_and_Shanghai_Banking_Corporation], arg2=[surface=HSBC, solution=The_Hongkong_and_Shanghai_Banking_Corporation], weight=10.0] is captured by ILP inference.
CoherenceRelation 879 [arg1=[surface=RMB, solution=Renminbi], arg2=[surface=RMB, solution=Renminbi], weight=10.0] is captured by ILP inference.
CoherenceRelation 2 [arg1=[surface=Agency, solution=Xinhua_News_Agency], arg2=[surface=Xinhua News Agency, solution=Xinhua_News_Agency], weight=10.0] is captured by ILP inference.
CoherenceRelation 1910 [arg1=[surface=Shanghai Branch of Japan, solution=*null*], arg2=[surface=Shanghai Branch of the Japan Industrial Bank, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 1588 [arg1=[surface=Shanghai, solution=Shanghai_Stock_Exchange], arg2=[surface=Securities, solution=Security_(finance)], weight=100.0] is captured by ILP inference.
CoherenceRelation 1579 [arg1=[surface=Securities Building, solution=*null*], arg2=[surface=Shanghai Securities Building, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 803 [arg1=[surface=Pudong, solution=Pudong], arg2=[surface=Lujiazui, solution=Lujiazui], weight=100.0] is captured by ILP inference.
CoherenceRelation 1233 [arg1=[surface=Templeton Company, solution=*null*], arg2=[surface=Franklin Templeton Company, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 55 [arg1=[surface=Zhou, solution=*null*], arg2=[surface=Jierong Zhou, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 1900 [arg1=[surface=HSBC, solution=The_Hongkong_and_Shanghai_Banking_Corporation], arg2=[surface=HSBC, solution=The_Hongkong_and_Shanghai_Banking_Corporation], weight=10.0] is captured by ILP inference.
CoherenceRelation 445 [arg1=[surface=Mitsubishi Bank, solution=The_Bank_of_Tokyo-Mitsubishi_UFJ], arg2=[surface=Tokyo Mitsubishi Bank, solution=The_Bank_of_Tokyo-Mitsubishi_UFJ], weight=10.0] is captured by ILP inference.
CoherenceRelation 1910 [arg1=[surface=Shanghai Branch of Japan, solution=*null*], arg2=[surface=Shanghai Branch of the Japan Industrial Bank, solution=*null*], weight=10.0] is captured by ILP inference.
Discarded 22 hypothesis
Level: Relational Coherence Correct Wikification of: Xinhua News Agency to : http://en.wikipedia.org/wiki/Xinhua_News_Agency
Level: Relational Coherence Correct Wikification of: Shanghai to : http://en.wikipedia.org/wiki/Shanghai
Level: Relational Coherence : Still Incorrect Wikification of: HSBC; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/The_Hongkong_and_Shanghai_Banking_Corporation ; the gold is: http://en.wikipedia.org/wiki/HSBC;
  The confusions set is : HSBC(ranker score=0.3050256372771582) Vs: The_Hongkong_and_Shanghai_Banking_Corporation(ranker score=0.6941953602899075);
  The context is: ; ------- ;   Xinhua News Agency, Shanghai, April 3rd, by reporter Jierong Zhou  Recently, HSBC has moved its Shanghai branch to the China Shipping Mansion in the Pudong Lujiazui financial trading district, becoming the third foreign capital bank to be approved to operate RMB business and s
Level: Relational Coherence : Still Incorrect Wikification of: China Shipping Mansion; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/International_Ocean_Shipping_Building;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ;   Xinhua News Agency, Shanghai, April 3rd, by reporter Jierong Zhou  Recently, HSBC has moved its Shanghai branch to the China Shipping Mansion in the Pudong Lujiazui financial trading district, becoming the third foreign capital bank to be approved to operate RMB business and shift to Pudong.   At the moment, Shanghai 
Level: Relational Coherence Correct Wikification of: Pudong to : http://en.wikipedia.org/wiki/Pudong
Level: Relational Coherence Correct Wikification of: US to : http://en.wikipedia.org/wiki/United_States
Level: Relational Coherence Correct Wikification of: Citibank to : http://en.wikipedia.org/wiki/Citibank
Level: Relational Coherence Correct Wikification of: Hong Kong to : http://en.wikipedia.org/wiki/Hong_Kong
Level: Relational Coherence Correct Wikification of: Japan to : http://en.wikipedia.org/wiki/Japan
Level: Relational Coherence Correct Wikification of: Tokyo Mitsubishi Bank to : http://en.wikipedia.org/wiki/The_Bank_of_Tokyo-Mitsubishi_UFJ
Annotation at test time--1633 milliseconds elapsed to annotate the document chtb_165.eng
Final System Output:Correct Wikification of: Xinhua News Agency to : http://en.wikipedia.org/wiki/Xinhua_News_Agency
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Shanghai to : http://en.wikipedia.org/wiki/Shanghai
Candidates Entropy: 0.1852710019701504
Final System Output:: Still Incorrect Wikification of: HSBC; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/The_Hongkong_and_Shanghai_Banking_Corporation ; the gold is: http://en.wikipedia.org/wiki/HSBC;
  The confusions set is : HSBC(ranker score=0.3050256372771582) Vs: The_Hongkong_and_Shanghai_Banking_Corporation(ranker score=0.6941953602899075);
  The context is: ; ------- ;   Xinhua News Agency, Shanghai, April 3rd, by reporter Jierong Zhou  Recently, HSBC has moved its Shanghai branch to the China Shipping Mansion in the Pudong Lujiazui financial trading district, becoming the third foreign capital bank to be approved to operate RMB business and s
Candidates Entropy: 0.6225691756745216
Final System Output:: Still Incorrect Wikification of: China Shipping Mansion; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/International_Ocean_Shipping_Building;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ;   Xinhua News Agency, Shanghai, April 3rd, by reporter Jierong Zhou  Recently, HSBC has moved its Shanghai branch to the China Shipping Mansion in the Pudong Lujiazui financial trading district, becoming the third foreign capital bank to be approved to operate RMB business and shift to Pudong.   At the moment, Shanghai 
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Pudong to : http://en.wikipedia.org/wiki/Pudong
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: US to : http://en.wikipedia.org/wiki/United_States
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Citibank to : http://en.wikipedia.org/wiki/Citibank
Candidates Entropy: 0.07293199910942634
Final System Output:Correct Wikification of: Hong Kong to : http://en.wikipedia.org/wiki/Hong_Kong
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Japan to : http://en.wikipedia.org/wiki/Japan
Candidates Entropy: 0.2957320507012199
Final System Output:Correct Wikification of: Tokyo Mitsubishi Bank to : http://en.wikipedia.org/wiki/The_Bank_of_Tokyo-Mitsubishi_UFJ
Candidates Entropy: 0.0
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/chtb_165.eng.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/APW20001216.2012.0590
Empty problem - no reference instances!!!
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/PRI20001031.2000.1824
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =192
		- Total unique tokens  =126
		- Total unique tokens ignore case =121
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =6
		- OOV tokens, no repetitions, Case Sensitive =2
		- Total OOV tokens even after lowercasing  =6
		- OOV tokens even after lowercasing, no repetition  =2
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =8
		- OOV tokens, no repetitions, Case Sensitive =4
		- Total OOV tokens even after lowercasing  =8
		- OOV tokens even after lowercasing, no repetition  =4
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =4
		- OOV tokens, no repetitions, Case Sensitive =3
		- Total OOV tokens even after lowercasing  =4
		- OOV tokens even after lowercasing, no repetition  =3
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 252 milliseconds
Constructing a problem for the following text: 
 From BBC News in London, I am Gregor Craigy for The World. A Singapore Airlines 747 flying from Taiwan to Los Angeles has crashed. Flight SQ006 was carrying 179 passengers and crew when it crashed...
Annotating mention view..
1 milliseconds elapsed on constructing the TF-IDF representation of the input text...PRI20001031.2000.1824
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Adding NER candidates for PRI20001031.2000.1824
Adding SHALLOW_PARSE and subChunk candidates for PRI20001031.2000.1824
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Matched regex entity From BBC News in London, I[1-27]{0-7}
Matched regex entity BBC News in London, I[6-27]{1-7}
Matched regex entity London, I[18-27]{4-7}
Matched regex entity Gregor Craigy for The World[31-58]{8-13}
Matched regex entity David Chezan, BBC News[951-973]{186-191}
Matched regex entity Chezan, BBC News[957-973]{187-191}
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Done constructing the Wikifiable entities
     ----  almost there....
153 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...PRI20001031.2000.1824
Inference on the document  -- PRI20001031.2000.1824
2 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
2 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
78 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
6 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
38 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
2 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: BBC News to : http://en.wikipedia.org/wiki/BBC_News
Level:FeatureExtractorCoherenceCorrect Wikification of: London to : http://en.wikipedia.org/wiki/London
Level:FeatureExtractorCoherenceCorrect Wikification of: Taiwan to : http://en.wikipedia.org/wiki/Taiwan
Level:FeatureExtractorCoherenceCorrect Wikification of: Los Angeles to : http://en.wikipedia.org/wiki/Los_Angeles
Level:FeatureExtractorCoherenceCorrect Wikification of: David Chezan to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: BBC News to : http://en.wikipedia.org/wiki/BBC_News
Level:FeatureExtractorCoherenceCorrect Wikification of: London to : http://en.wikipedia.org/wiki/London
Level:FeatureExtractorCoherenceCorrect Wikification of: Taiwan to : http://en.wikipedia.org/wiki/Taiwan
Level:FeatureExtractorCoherence: this introduces a Wikification error(!!!): Los Angeles; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Los_Angeles;
  The confusions set is : Los_Angeles_International_Airport(ranker score=3.8490657352210835) Vs: Los_Angeles(ranker score=4.876117215175014);
  The context is: ; ------- ;  From BBC News in London, I am Gregor Craigy for The World. A Singapore Airlines 747 flying from Taiwan to Los Angeles has crashed. Flight SQ006 was carrying 179 passengers and crew when it crashed in flames shortly after take off. At least 65 people are known to have been killed and around 30 passengers r
Level:FeatureExtractorCoherenceCorrect Wikification of: David Chezan to : http://en.wikipedia.org/wiki/*null*
Could not find WikiMatchData for title Chizan
Could not find WikiMatchData for title Chizan
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=BBC_News, pred=locationCity, arg2=London, score=12.553539037704468, normalizedScore=100.0]For surfaces BBC News and London
Relational inference took 4ms
CoherenceRelation 951 [arg1=[surface=David, solution=*null*], arg2=[surface=David Chezan, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 951 [arg1=[surface=Chezan, solution=*null*], arg2=[surface=David Chezan, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 62 [arg1=[surface=Singapore Airlines, solution=Singapore_Airlines], arg2=[surface=Singapore Airlines, solution=Singapore_Airlines], weight=10.0] is captured by ILP inference.
CoherenceRelation 18 [arg1=[surface=BBC News, solution=BBC_News], arg2=[surface=London, solution=London], weight=100.0] is captured by ILP inference.
CoherenceRelation 330 [arg1=[surface=Chezan, solution=*null*], arg2=[surface=David Chezan, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 951 [arg1=[surface=David Chezan, solution=*null*], arg2=[surface=David Chezan, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 6 [arg1=[surface=BBC News, solution=BBC_News], arg2=[surface=BBC News, solution=BBC_News], weight=10.0] is captured by ILP inference.
CoherenceRelation 330 [arg1=[surface=David, solution=*null*], arg2=[surface=David Chezan, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 31 [arg1=[surface=Gregor, solution=*null*], arg2=[surface=Gregor Craigy, solution=*null*], weight=10.0] is captured by ILP inference.
Discarded 3 hypothesis
Level: Relational Coherence Correct Wikification of: BBC News to : http://en.wikipedia.org/wiki/BBC_News
Level: Relational Coherence Correct Wikification of: London to : http://en.wikipedia.org/wiki/London
Level: Relational Coherence Correct Wikification of: Taiwan to : http://en.wikipedia.org/wiki/Taiwan
Level: Relational Coherence : Still Incorrect Wikification of: Los Angeles; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Los_Angeles;
  The confusions set is : Los_Angeles_International_Airport(ranker score=0.2395552626914817) Vs: Los_Angeles(ranker score=0.6690344891680887);
  The context is: ; ------- ;  From BBC News in London, I am Gregor Craigy for The World. A Singapore Airlines 747 flying from Taiwan to Los Angeles has crashed. Flight SQ006 was carrying 179 passengers and crew when it crashed in flames shortly after take off. At least 65 people are known to have been killed and around 30 passengers r
Level: Relational Coherence Correct Wikification of: David Chezan to : http://en.wikipedia.org/wiki/*null*
Annotation at test time--218 milliseconds elapsed to annotate the document PRI20001031.2000.1824
Final System Output:Correct Wikification of: BBC News to : http://en.wikipedia.org/wiki/BBC_News
Candidates Entropy: 0.3381627324820662
Final System Output:Correct Wikification of: London to : http://en.wikipedia.org/wiki/London
Candidates Entropy: 0.26228140134851147
Final System Output:Correct Wikification of: Taiwan to : http://en.wikipedia.org/wiki/Taiwan
Candidates Entropy: 0.5470337153183564
Final System Output:: Still Incorrect Wikification of: Los Angeles; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Los_Angeles;
  The confusions set is : Los_Angeles_International_Airport(ranker score=0.2395552626914817) Vs: Los_Angeles(ranker score=0.6690344891680887);
  The context is: ; ------- ;  From BBC News in London, I am Gregor Craigy for The World. A Singapore Airlines 747 flying from Taiwan to Los Angeles has crashed. Flight SQ006 was carrying 179 passengers and crew when it crashed in flames shortly after take off. At least 65 people are known to have been killed and around 30 passengers r
Candidates Entropy: 1.0940969968621743
Final System Output:Correct Wikification of: David Chezan to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/PRI20001031.2000.1824.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/APW20001208.1126.0362
Empty problem - no reference instances!!!
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/20001115_AFP_ARB.0030.eng
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =209
		- Total unique tokens  =121
		- Total unique tokens ignore case =117
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =11
		- OOV tokens, no repetitions, Case Sensitive =6
		- Total OOV tokens even after lowercasing  =11
		- OOV tokens even after lowercasing, no repetition  =6
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =14
		- OOV tokens, no repetitions, Case Sensitive =9
		- Total OOV tokens even after lowercasing  =13
		- OOV tokens even after lowercasing, no repetition  =8
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =5
		- OOV tokens, no repetitions, Case Sensitive =4
		- Total OOV tokens even after lowercasing  =5
		- OOV tokens even after lowercasing, no repetition  =4
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 195 milliseconds
Constructing a problem for the following text: 
  Gaza 11-15 (AFP) -  A Palestinian medical source reported today Wednesday that more than fifteen Palestinians were injured this morning in the town of Rafah in the southern Gaza Strip in clashes ...
Annotating mention view..
0 milliseconds elapsed on constructing the TF-IDF representation of the input text...20001115_AFP_ARB.0030.eng
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Adding NER candidates for 20001115_AFP_ARB.0030.eng
Adding SHALLOW_PARSE and subChunk candidates for 20001115_AFP_ARB.0030.eng
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Matched regex entity Elsewhere, Israeli[635-653]{111-114}
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Done constructing the Wikifiable entities
     ----  almost there....
193 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...20001115_AFP_ARB.0030.eng
Inference on the document  -- 20001115_AFP_ARB.0030.eng
2 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
3 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
53 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
6 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
25 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
3 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: Gaza to : http://en.wikipedia.org/wiki/Gaza
Level:FeatureExtractorCoherenceCorrect Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level:FeatureExtractorCoherenceCorrect Wikification of: Egypt to : http://en.wikipedia.org/wiki/Egypt
Level:FeatureExtractorCoherenceCorrect Wikification of: Gaza to : http://en.wikipedia.org/wiki/Gaza
Level:FeatureExtractorCoherenceCorrect Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level:FeatureExtractorCoherenceCorrect Wikification of: Egypt to : http://en.wikipedia.org/wiki/Egypt
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Nitsarim; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Netzarim_(settlement);
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; wo houses and a well, where the army erected a new military camp instead.   The town's authorities said last night the Israeli army dug up several hectares planted with orange trees in southern Gaza (Nitsarim).   The bulldozing of land began the night before last when an Israeli soldier was killed in a shooting incident in the area. 
Relational inference took 6ms
CoherenceRelation 99 [arg1=[surface=Palestinians, solution=Palestinian_people], arg2=[surface=Palestinians, solution=Palestinian_people], weight=10.0] is captured by ILP inference.
Discarded 10 hypothesis
Level: Relational Coherence Correct Wikification of: Gaza to : http://en.wikipedia.org/wiki/Gaza
Level: Relational Coherence Correct Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level: Relational Coherence Correct Wikification of: Egypt to : http://en.wikipedia.org/wiki/Egypt
Level: Relational Coherence : Still Incorrect Wikification of: Nitsarim; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Netzarim_(settlement);
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; wo houses and a well, where the army erected a new military camp instead.   The town's authorities said last night the Israeli army dug up several hectares planted with orange trees in southern Gaza (Nitsarim).   The bulldozing of land began the night before last when an Israeli soldier was killed in a shooting incident in the area. 
Annotation at test time--185 milliseconds elapsed to annotate the document 20001115_AFP_ARB.0030.eng
Final System Output:Correct Wikification of: Gaza to : http://en.wikipedia.org/wiki/Gaza
Candidates Entropy: 0.7551137638405194
Final System Output:Correct Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Candidates Entropy: 1.0667083768250765
Final System Output:Correct Wikification of: Egypt to : http://en.wikipedia.org/wiki/Egypt
Candidates Entropy: 0.03271843756428933
Final System Output:: Still Incorrect Wikification of: Nitsarim; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Netzarim_(settlement);
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; wo houses and a well, where the army erected a new military camp instead.   The town's authorities said last night the Israeli army dug up several hectares planted with orange trees in southern Gaza (Nitsarim).   The bulldozing of land began the night before last when an Israeli soldier was killed in a shooting incident in the area. 
Candidates Entropy: 0.0
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/20001115_AFP_ARB.0030.eng.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/NYT20001101.2212.0429
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =798
		- Total unique tokens  =358
		- Total unique tokens ignore case =344
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =39
		- OOV tokens, no repetitions, Case Sensitive =13
		- Total OOV tokens even after lowercasing  =39
		- OOV tokens even after lowercasing, no repetition  =13
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =54
		- OOV tokens, no repetitions, Case Sensitive =18
		- Total OOV tokens even after lowercasing  =53
		- OOV tokens even after lowercasing, no repetition  =17
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =32
		- OOV tokens, no repetitions, Case Sensitive =22
		- Total OOV tokens even after lowercasing  =30
		- OOV tokens even after lowercasing, no repetition  =20
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 909 milliseconds
Constructing a problem for the following text: 
 MERGER &QL; By ALEX BERENSON &QC; &LR; &QL; &UR; c.2000 N.Y. Times News Service &QC; &LR; &QL; &UR; &LR; Back in January, when Internet stocks were hot, America Online agreed to buy Time Warner wi...
Annotating mention view..
1 milliseconds elapsed on constructing the TF-IDF representation of the input text...NYT20001101.2212.0429
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Adding NER candidates for NYT20001101.2212.0429
Adding SHALLOW_PARSE and subChunk candidates for NYT20001101.2212.0429
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Matched regex entity Back in January[106-121]{39-42}
Matched regex entity Time Warner with AOL[183-203]{54-58}
Matched regex entity State Street Research in Boston[862-893]{186-191}
Matched regex entity Tom Wolzien of Sanford C. Bernstein[1577-1612]{325-331}
Matched regex entity Time and Warner[2036-2051]{412-415}
Matched regex entity Roger McNamee of Integral Capital[2128-2161]{433-438}
Matched regex entity Jessica Reif of Merrill Lynch[2449-2478]{491-496}
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Done constructing the Wikifiable entities
     ----  almost there....
566 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...NYT20001101.2212.0429
Inference on the document  -- NYT20001101.2212.0429
5 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
10 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
141 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
15 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
553 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
8 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: Time Warner to : http://en.wikipedia.org/wiki/Time_Warner
Level:FeatureExtractorCoherenceCorrect Wikification of: Larry Haverty to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Boston to : http://en.wikipedia.org/wiki/Boston
Level:FeatureExtractorCoherenceCorrect Wikification of: Tom Wolzien to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Disney to : http://en.wikipedia.org/wiki/The_Walt_Disney_Company
Level:FeatureExtractorCoherenceCorrect Wikification of: Roger McNamee to : http://en.wikipedia.org/wiki/Roger_McNamee
Level:FeatureExtractorCoherenceCorrect Wikification of: Integral Capital to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Jessica Reif to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Merrill Lynch to : http://en.wikipedia.org/wiki/Merrill_Lynch
Level:FeatureExtractorCoherenceCorrect Wikification of: NBC to : http://en.wikipedia.org/wiki/NBC
Level:FeatureExtractorCoherenceCorrect Wikification of: Comcast to : http://en.wikipedia.org/wiki/Comcast
Level:FeatureExtractorCoherenceCorrect Wikification of: Time Warner to : http://en.wikipedia.org/wiki/Time_Warner
Level:FeatureExtractorCoherenceCorrect Wikification of: Larry Haverty to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: State Street Research; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/State_Street_Corporation;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; Levin, into taking AOL's shares at the worst possible time.   ``Short term, anyone objective would say probably Steve got the better part of the deal,'' said Larry Haverty, a senior vice president at State Street Research in Boston and a longtime media investor.   But Haverty, like many other Time Warner shareholders and industry analysts, hardly cares. With the merger likely to be completed later
Level:FeatureExtractorCoherenceCorrect Wikification of: Boston to : http://en.wikipedia.org/wiki/Boston
Level:FeatureExtractorCoherenceCorrect Wikification of: Tom Wolzien to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Sanford C. Bernstein; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Sanford_Bernstein;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; rty said. ``Five years out, if you're a shareholder in this company, you're going to be a happy camper.''   That view is widely shared. ``Strategically, it makes a lot of sense,'' said Tom Wolzien of Sanford C. Bernstein. ``These companies fill the holes of the other one. They're subscription-advertising combo models. The reality is the pieces are very compatible.''   To be sure, the recent histor
Level:FeatureExtractorCoherenceCorrect Wikification of: Disney to : http://en.wikipedia.org/wiki/The_Walt_Disney_Company
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Capital Cities/ABC; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Capital_Cities_Communications;
  The confusions set is : Capital_Cities_Communications(ranker score=4.5948905413464045) Vs: The_Walt_Disney_Company(ranker score=4.850082640191754);
  The context is: ; ------- ; ty is the pieces are very compatible.''   To be sure, the recent history of big media mergers is hardly comforting for shareholders in either AOL or Time Warner. Disney stumbled badly after it bought Capital Cities/ABC in 1996, and Time Warner stagnated for five years after it was created in 1990 by the merger of Time and Warner. ``Huge deals are really hard to do and create a lot of uncertainty,'
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Time; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Time_(magazine) ; the gold is: http://en.wikipedia.org/wiki/Time_Inc.;
  The confusions set is : Time_(Fleetwood_Mac_album)(ranker score=2.404310747148659) Vs: Time_(magazine)(ranker score=4.107437413400849);
  The context is: ; ------- ; for shareholders in either AOL or Time Warner. Disney stumbled badly after it bought Capital Cities/ABC in 1996, and Time Warner stagnated for five years after it was created in 1990 by the merger of Time and Warner. ``Huge deals are really hard to do and create a lot of uncertainty,'' said Roger McNamee of Integral Capital, which sold its 404,000 AOL shares the day the merger was announced.   But
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Warner; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Time_Warner ; the gold is: http://en.wikipedia.org/wiki/Warner_Communications;
  The confusions set is : Warner_Bros.(ranker score=3.2119075024528954) Vs: Time_Warner(ranker score=4.346399910852549);
  The context is: ; ------- ; holders in either AOL or Time Warner. Disney stumbled badly after it bought Capital Cities/ABC in 1996, and Time Warner stagnated for five years after it was created in 1990 by the merger of Time and Warner. ``Huge deals are really hard to do and create a lot of uncertainty,'' said Roger McNamee of Integral Capital, which sold its 404,000 AOL shares the day the merger was announced.   But if the m
Level:FeatureExtractorCoherenceCorrect Wikification of: Roger McNamee to : http://en.wikipedia.org/wiki/Roger_McNamee
Level:FeatureExtractorCoherenceCorrect Wikification of: Integral Capital to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Jessica Reif to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Merrill Lynch to : http://en.wikipedia.org/wiki/Merrill_Lynch
Level:FeatureExtractorCoherenceCorrect Wikification of: NBC to : http://en.wikipedia.org/wiki/NBC
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Washington; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Washington,_D.C.;
  The confusions set is : Washington,_D.C.(ranker score=2.3212385643894153) Vs: Washington(ranker score=3.211746843243156);
  The context is: ; ------- ; ``Given the multiple distribution platforms that they have, it's obviously a very powerful consumer engine,'' Reif said. ``There's a reason that you see Disney and to a lesser extent NBC screaming in Washington.''   John Schreiber, an assistant portfolio manager at Janus Capital, the mutual fund company that is Time Warner's largest shareholder, with more than 120 million shares, said the companie
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: John Schreiber; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/John_Schreiber ; the gold is: http://en.wikipedia.org/wiki/*null*;
  The surface form has a single disambiguation candidate : John_Schreiber(ranker score=3.4577722340799792) ;
  The context is: ; ------- ; iple distribution platforms that they have, it's obviously a very powerful consumer engine,'' Reif said. ``There's a reason that you see Disney and to a lesser extent NBC screaming in Washington.''   John Schreiber, an assistant portfolio manager at Janus Capital, the mutual fund company that is Time Warner's largest shareholder, with more than 120 million shares, said the companies had already be
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Janus Capital; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Janus_Capital_Group;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; bviously a very powerful consumer engine,'' Reif said. ``There's a reason that you see Disney and to a lesser extent NBC screaming in Washington.''   John Schreiber, an assistant portfolio manager at Janus Capital, the mutual fund company that is Time Warner's largest shareholder, with more than 120 million shares, said the companies had already begun to demonstrate how they would work together. F
Level:FeatureExtractorCoherenceCorrect Wikification of: Comcast to : http://en.wikipedia.org/wiki/Comcast
Could not find WikiMatchData for title Sanford_Bernstein
Could not find WikiMatchData for title Deals
Could not find WikiMatchData for title Deals
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Time_Warner, pred=WIKI_LINK_RELATION, arg2=AOL, score=13.907927293777467, normalizedScore=100.0]For surfaces Time Warner and AOL
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Time_(magazine), pred=WIKI_LINK_RELATION, arg2=Time_Warner, score=2.2574975728988647, normalizedScore=100.0]For surfaces Time and Warner
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Stephen Case[597-609]{134-136} === America Online 's chairman
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Gerald Levin[655-667]{144-146} === his Time Warner counterpart
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Larry Haverty[820-833]{178-180} === a senior vice president at State Street Research in Boston
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:John Schreiber[2698-2712]{540-542} === an assistant portfolio manager
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - Force linking John Schreiber[2698-2712]{540-542} to null
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Schreiber[3251-3260]{639-640} === the people who watch Time Warner cable channels and read its magazines
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - Force linking Schreiber[3251-3260]{639-640} to null
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Schreiber[3833-3842]{745-746} === the combined company
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - Force linking Schreiber[3833-3842]{745-746} to null
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Time_Warner due to a longer mention than Warner that referred to the same thing
Relational inference took 56ms
CoherenceRelation 200 [arg1=[surface=Time Warner, solution=Time_Warner], arg2=[surface=AOL, solution=AOL], weight=100.0] is captured by ILP inference.
CoherenceRelation 2449 [arg1=[surface=Reif, solution=*null*], arg2=[surface=Jessica Reif, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 2698 [arg1=[surface=Schreiber, solution=*null*], arg2=[surface=John Schreiber, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 2698 [arg1=[surface=Schreiber, solution=*null*], arg2=[surface=John Schreiber, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 2960 [arg1=[surface=AOL, solution=AOL], arg2=[surface=AOL, solution=AOL], weight=10.0] is captured by ILP inference.
CoherenceRelation 1883 [arg1=[surface=Disney, solution=The_Walt_Disney_Company], arg2=[surface=Disney, solution=The_Walt_Disney_Company], weight=10.0] is captured by ILP inference.
CoherenceRelation 655 [arg1=[surface=Levin, solution=Gerald_M._Levin], arg2=[surface=Gerald Levin, solution=Gerald_M._Levin], weight=10.0] is captured by ILP inference.
CoherenceRelation 328 [arg1=[surface=Time Warner, solution=Time_Warner], arg2=[surface=Time Warner, solution=Time_Warner], weight=10.0] is captured by ILP inference.
CoherenceRelation 3919 [arg1=[surface=America Online, solution=AOL], arg2=[surface=America Online, solution=AOL], weight=10.0] is captured by ILP inference.
CoherenceRelation 820 [arg1=[surface=Haverty, solution=*null*], arg2=[surface=Larry Haverty, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 328 [arg1=[surface=Time Warner, solution=Time_Warner], arg2=[surface=Time Warner, solution=Time_Warner], weight=10.0] is captured by ILP inference.
CoherenceRelation 328 [arg1=[surface=Time Warner, solution=Time_Warner], arg2=[surface=Time Warner, solution=Time_Warner], weight=10.0] is captured by ILP inference.
CoherenceRelation 2960 [arg1=[surface=AOL, solution=AOL], arg2=[surface=AOL, solution=AOL], weight=10.0] is captured by ILP inference.
CoherenceRelation 597 [arg1=[surface=Stephen, solution=Steve_Case], arg2=[surface=Stephen Case, solution=Steve_Case], weight=10.0] is captured by ILP inference.
CoherenceRelation 655 [arg1=[surface=Gerald, solution=Gerald_M._Levin], arg2=[surface=Gerald Levin, solution=Gerald_M._Levin], weight=10.0] is captured by ILP inference.
CoherenceRelation 2698 [arg1=[surface=Schreiber, solution=*null*], arg2=[surface=John Schreiber, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 328 [arg1=[surface=Warner, solution=Time_Warner], arg2=[surface=Time Warner, solution=Time_Warner], weight=10.0] is captured by ILP inference.
CoherenceRelation 328 [arg1=[surface=Time Warner, solution=Time_Warner], arg2=[surface=Time Warner, solution=Time_Warner], weight=10.0] is captured by ILP inference.
CoherenceRelation 2960 [arg1=[surface=AOL, solution=AOL], arg2=[surface=AOL, solution=AOL], weight=10.0] is captured by ILP inference.
CoherenceRelation 3919 [arg1=[surface=America Online, solution=AOL], arg2=[surface=America Online, solution=AOL], weight=10.0] is captured by ILP inference.
CoherenceRelation 328 [arg1=[surface=Time Warner, solution=Time_Warner], arg2=[surface=Time Warner, solution=Time_Warner], weight=10.0] is captured by ILP inference.
CoherenceRelation 2960 [arg1=[surface=AOL, solution=AOL], arg2=[surface=AOL, solution=AOL], weight=10.0] is captured by ILP inference.
CoherenceRelation 2128 [arg1=[surface=Roger, solution=Roger_McNamee], arg2=[surface=Roger McNamee, solution=Roger_McNamee], weight=10.0] is captured by ILP inference.
CoherenceRelation 2698 [arg1=[surface=Schreiber, solution=*null*], arg2=[surface=John Schreiber, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 328 [arg1=[surface=Time Warner, solution=Time_Warner], arg2=[surface=Time Warner, solution=Time_Warner], weight=10.0] is captured by ILP inference.
CoherenceRelation 1883 [arg1=[surface=Disney, solution=The_Walt_Disney_Company], arg2=[surface=Disney, solution=The_Walt_Disney_Company], weight=10.0] is captured by ILP inference.
CoherenceRelation 820 [arg1=[surface=Haverty, solution=*null*], arg2=[surface=Larry Haverty, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 2434 [arg1=[surface=Internet, solution=Internet], arg2=[surface=Internet, solution=Internet], weight=10.0] is captured by ILP inference.
CoherenceRelation 2128 [arg1=[surface=McNamee, solution=Roger_McNamee], arg2=[surface=Roger McNamee, solution=Roger_McNamee], weight=10.0] is captured by ILP inference.
CoherenceRelation 3919 [arg1=[surface=America Online, solution=AOL], arg2=[surface=America Online, solution=AOL], weight=10.0] is captured by ILP inference.
CoherenceRelation 2449 [arg1=[surface=Reif, solution=*null*], arg2=[surface=Jessica Reif, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 2449 [arg1=[surface=Jessica, solution=*null*], arg2=[surface=Jessica Reif, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 328 [arg1=[surface=Time Warner, solution=Time_Warner], arg2=[surface=Time Warner, solution=Time_Warner], weight=10.0] is captured by ILP inference.
CoherenceRelation 328 [arg1=[surface=Time Warner, solution=Time_Warner], arg2=[surface=Time Warner, solution=Time_Warner], weight=10.0] is captured by ILP inference.
CoherenceRelation 1577 [arg1=[surface=Tom, solution=*null*], arg2=[surface=Tom Wolzien, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 328 [arg1=[surface=Time Warner, solution=Time_Warner], arg2=[surface=Time Warner, solution=Time_Warner], weight=10.0] is captured by ILP inference.
CoherenceRelation 328 [arg1=[surface=Time Warner, solution=Time_Warner], arg2=[surface=Time Warner, solution=Time_Warner], weight=10.0] is captured by ILP inference.
CoherenceRelation 655 [arg1=[surface=Levin, solution=Gerald_M._Levin], arg2=[surface=Gerald Levin, solution=Gerald_M._Levin], weight=10.0] is captured by ILP inference.
CoherenceRelation 2960 [arg1=[surface=AOL, solution=AOL], arg2=[surface=AOL, solution=AOL], weight=10.0] is captured by ILP inference.
CoherenceRelation 820 [arg1=[surface=Haverty, solution=*null*], arg2=[surface=Larry Haverty, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 2045 [arg1=[surface=Time, solution=Time_(magazine)], arg2=[surface=Warner, solution=Time_Warner], weight=50.0] is captured by ILP inference.
CoherenceRelation 328 [arg1=[surface=Time Warner, solution=Time_Warner], arg2=[surface=Time Warner, solution=Time_Warner], weight=10.0] is captured by ILP inference.
CoherenceRelation 328 [arg1=[surface=Time Warner, solution=Time_Warner], arg2=[surface=Time Warner, solution=Time_Warner], weight=10.0] is captured by ILP inference.
CoherenceRelation 820 [arg1=[surface=Larry, solution=*null*], arg2=[surface=Larry Haverty, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 597 [arg1=[surface=Case, solution=Steve_Case], arg2=[surface=Stephen Case, solution=Steve_Case], weight=10.0] is captured by ILP inference.
CoherenceRelation 2960 [arg1=[surface=AOL, solution=AOL], arg2=[surface=AOL, solution=AOL], weight=10.0] is captured by ILP inference.
CoherenceRelation 328 [arg1=[surface=Time Warner, solution=Time_Warner], arg2=[surface=Time Warner, solution=Time_Warner], weight=10.0] is captured by ILP inference.
CoherenceRelation 2960 [arg1=[surface=AOL, solution=AOL], arg2=[surface=AOL, solution=AOL], weight=10.0] is captured by ILP inference.
Discarded 138 hypothesis
Level: Relational Coherence Correct Wikification of: Time Warner to : http://en.wikipedia.org/wiki/Time_Warner
Level: Relational Coherence Correct Wikification of: Larry Haverty to : http://en.wikipedia.org/wiki/*null*
Level: Relational Coherence : Still Incorrect Wikification of: State Street Research; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/State_Street_Corporation;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; Levin, into taking AOL's shares at the worst possible time.   ``Short term, anyone objective would say probably Steve got the better part of the deal,'' said Larry Haverty, a senior vice president at State Street Research in Boston and a longtime media investor.   But Haverty, like many other Time Warner shareholders and industry analysts, hardly cares. With the merger likely to be completed later
Level: Relational Coherence Correct Wikification of: Boston to : http://en.wikipedia.org/wiki/Boston
Level: Relational Coherence Correct Wikification of: Tom Wolzien to : http://en.wikipedia.org/wiki/*null*
Level: Relational Coherence Correct Wikification of: Sanford C. Bernstein to : http://en.wikipedia.org/wiki/Sanford_Bernstein
Level: Relational Coherence this fixes the Wikification (!!!)Sanford C. Bernstein; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Sanford_Bernstein ; the gold is: http://en.wikipedia.org/wiki/Sanford_Bernstein;
  The surface form has a single disambiguation candidate : Sanford_Bernstein(ranker score=0.5) ;
  The context is: ; ------- ; rty said. ``Five years out, if you're a shareholder in this company, you're going to be a happy camper.''   That view is widely shared. ``Strategically, it makes a lot of sense,'' said Tom Wolzien of Sanford C. Bernstein. ``These companies fill the holes of the other one. They're subscription-advertising combo models. The reality is the pieces are very compatible.''   To be sure, the recent histor
Level: Relational Coherence Correct Wikification of: Disney to : http://en.wikipedia.org/wiki/The_Walt_Disney_Company
Level: Relational Coherence : Still Incorrect Wikification of: Capital Cities/ABC; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Capital_Cities_Communications;
  The confusions set is : Capital_Cities_Communications(ranker score=0.41754350918843275) Vs: The_Walt_Disney_Company(ranker score=0.5389273910387017);
  The context is: ; ------- ; ty is the pieces are very compatible.''   To be sure, the recent history of big media mergers is hardly comforting for shareholders in either AOL or Time Warner. Disney stumbled badly after it bought Capital Cities/ABC in 1996, and Time Warner stagnated for five years after it was created in 1990 by the merger of Time and Warner. ``Huge deals are really hard to do and create a lot of uncertainty,'
Level: Relational Coherence : Still Incorrect Wikification of: Time; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Time_(magazine) ; the gold is: http://en.wikipedia.org/wiki/Time_Inc.;
  The confusions set is : Time_(Fleetwood_Mac_album)(ranker score=0.11621523155692308) Vs: Time_(magazine)(ranker score=0.6381482241428851);
  The context is: ; ------- ; for shareholders in either AOL or Time Warner. Disney stumbled badly after it bought Capital Cities/ABC in 1996, and Time Warner stagnated for five years after it was created in 1990 by the merger of Time and Warner. ``Huge deals are really hard to do and create a lot of uncertainty,'' said Roger McNamee of Integral Capital, which sold its 404,000 AOL shares the day the merger was announced.   But
Level: Relational Coherence : Still Incorrect Wikification of: Warner; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Time_Warner ; the gold is: http://en.wikipedia.org/wiki/Warner_Communications;
  The confusions set is : Time_Inc.(ranker score=0.0073885668832557455) Vs: Time_Warner(ranker score=0.989597595934492);
  The context is: ; ------- ; holders in either AOL or Time Warner. Disney stumbled badly after it bought Capital Cities/ABC in 1996, and Time Warner stagnated for five years after it was created in 1990 by the merger of Time and Warner. ``Huge deals are really hard to do and create a lot of uncertainty,'' said Roger McNamee of Integral Capital, which sold its 404,000 AOL shares the day the merger was announced.   But if the m
Level: Relational Coherence Correct Wikification of: Roger McNamee to : http://en.wikipedia.org/wiki/Roger_McNamee
Level: Relational Coherence Correct Wikification of: Integral Capital to : http://en.wikipedia.org/wiki/*null*
Level: Relational Coherence Correct Wikification of: Jessica Reif to : http://en.wikipedia.org/wiki/*null*
Level: Relational Coherence Correct Wikification of: Merrill Lynch to : http://en.wikipedia.org/wiki/Merrill_Lynch
Level: Relational Coherence Correct Wikification of: NBC to : http://en.wikipedia.org/wiki/NBC
Level: Relational Coherence : Still Incorrect Wikification of: Washington; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Washington,_D.C.;
  The confusions set is : Washington,_D.C.(ranker score=0.19182449053072534) Vs: Washington(ranker score=0.467354991034331);
  The context is: ; ------- ; ``Given the multiple distribution platforms that they have, it's obviously a very powerful consumer engine,'' Reif said. ``There's a reason that you see Disney and to a lesser extent NBC screaming in Washington.''   John Schreiber, an assistant portfolio manager at Janus Capital, the mutual fund company that is Time Warner's largest shareholder, with more than 120 million shares, said the companie
Level: Relational Coherence Correct Wikification of: John Schreiber to : http://en.wikipedia.org/wiki/*null*
Level: Relational Coherence this fixes the Wikification (!!!)John Schreiber; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/*null*;
  The surface form has a single disambiguation candidate : John_Schreiber(ranker score=1.0) ;
  The context is: ; ------- ; iple distribution platforms that they have, it's obviously a very powerful consumer engine,'' Reif said. ``There's a reason that you see Disney and to a lesser extent NBC screaming in Washington.''   John Schreiber, an assistant portfolio manager at Janus Capital, the mutual fund company that is Time Warner's largest shareholder, with more than 120 million shares, said the companies had already be
Level: Relational Coherence : Still Incorrect Wikification of: Janus Capital; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Janus_Capital_Group;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; bviously a very powerful consumer engine,'' Reif said. ``There's a reason that you see Disney and to a lesser extent NBC screaming in Washington.''   John Schreiber, an assistant portfolio manager at Janus Capital, the mutual fund company that is Time Warner's largest shareholder, with more than 120 million shares, said the companies had already begun to demonstrate how they would work together. F
Level: Relational Coherence Correct Wikification of: Comcast to : http://en.wikipedia.org/wiki/Comcast
Annotation at test time--1331 milliseconds elapsed to annotate the document NYT20001101.2212.0429
Final System Output:Correct Wikification of: Time Warner to : http://en.wikipedia.org/wiki/Time_Warner
Candidates Entropy: 0.06574472147375632
Final System Output:Correct Wikification of: Larry Haverty to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Final System Output:: Still Incorrect Wikification of: State Street Research; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/State_Street_Corporation;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; Levin, into taking AOL's shares at the worst possible time.   ``Short term, anyone objective would say probably Steve got the better part of the deal,'' said Larry Haverty, a senior vice president at State Street Research in Boston and a longtime media investor.   But Haverty, like many other Time Warner shareholders and industry analysts, hardly cares. With the merger likely to be completed later
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Boston to : http://en.wikipedia.org/wiki/Boston
Candidates Entropy: 0.9823975662682874
Final System Output:Correct Wikification of: Tom Wolzien to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Sanford C. Bernstein to : http://en.wikipedia.org/wiki/Sanford_Bernstein
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Disney to : http://en.wikipedia.org/wiki/The_Walt_Disney_Company
Candidates Entropy: 0.14999209308293518
Final System Output:: Still Incorrect Wikification of: Capital Cities/ABC; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Capital_Cities_Communications;
  The confusions set is : Capital_Cities_Communications(ranker score=0.41754350918843275) Vs: The_Walt_Disney_Company(ranker score=0.5389273910387017);
  The context is: ; ------- ; ty is the pieces are very compatible.''   To be sure, the recent history of big media mergers is hardly comforting for shareholders in either AOL or Time Warner. Disney stumbled badly after it bought Capital Cities/ABC in 1996, and Time Warner stagnated for five years after it was created in 1990 by the merger of Time and Warner. ``Huge deals are really hard to do and create a lot of uncertainty,'
Candidates Entropy: 0.8342540277294248
Final System Output:: Still Incorrect Wikification of: Time; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Time_(magazine) ; the gold is: http://en.wikipedia.org/wiki/Time_Inc.;
  The confusions set is : Time_(Fleetwood_Mac_album)(ranker score=0.11621523155692308) Vs: Time_(magazine)(ranker score=0.6381482241428851);
  The context is: ; ------- ; for shareholders in either AOL or Time Warner. Disney stumbled badly after it bought Capital Cities/ABC in 1996, and Time Warner stagnated for five years after it was created in 1990 by the merger of Time and Warner. ``Huge deals are really hard to do and create a lot of uncertainty,'' said Roger McNamee of Integral Capital, which sold its 404,000 AOL shares the day the merger was announced.   But
Candidates Entropy: 1.5313490319881284
Final System Output:: Still Incorrect Wikification of: Warner; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Time_Warner ; the gold is: http://en.wikipedia.org/wiki/Warner_Communications;
  The confusions set is : Time_Inc.(ranker score=0.0073885668832557455) Vs: Time_Warner(ranker score=0.989597595934492);
  The context is: ; ------- ; holders in either AOL or Time Warner. Disney stumbled badly after it bought Capital Cities/ABC in 1996, and Time Warner stagnated for five years after it was created in 1990 by the merger of Time and Warner. ``Huge deals are really hard to do and create a lot of uncertainty,'' said Roger McNamee of Integral Capital, which sold its 404,000 AOL shares the day the merger was announced.   But if the m
Candidates Entropy: 0.06574472147375653
Final System Output:Correct Wikification of: Roger McNamee to : http://en.wikipedia.org/wiki/Roger_McNamee
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Integral Capital to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Jessica Reif to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Merrill Lynch to : http://en.wikipedia.org/wiki/Merrill_Lynch
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: NBC to : http://en.wikipedia.org/wiki/NBC
Candidates Entropy: 0.7027521522432382
Final System Output:: Still Incorrect Wikification of: Washington; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Washington,_D.C.;
  The confusions set is : Washington,_D.C.(ranker score=0.19182449053072534) Vs: Washington(ranker score=0.467354991034331);
  The context is: ; ------- ; ``Given the multiple distribution platforms that they have, it's obviously a very powerful consumer engine,'' Reif said. ``There's a reason that you see Disney and to a lesser extent NBC screaming in Washington.''   John Schreiber, an assistant portfolio manager at Janus Capital, the mutual fund company that is Time Warner's largest shareholder, with more than 120 million shares, said the companie
Candidates Entropy: 2.024104711209384
Final System Output:Correct Wikification of: John Schreiber to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Final System Output:: Still Incorrect Wikification of: Janus Capital; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Janus_Capital_Group;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; bviously a very powerful consumer engine,'' Reif said. ``There's a reason that you see Disney and to a lesser extent NBC screaming in Washington.''   John Schreiber, an assistant portfolio manager at Janus Capital, the mutual fund company that is Time Warner's largest shareholder, with more than 120 million shares, said the companies had already begun to demonstrate how they would work together. F
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Comcast to : http://en.wikipedia.org/wiki/Comcast
Candidates Entropy: 0.0
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/NYT20001101.2212.0429.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/APW20001202.0257.0120
Empty problem - no reference instances!!!
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/20001115_AFP_ARB.0072.eng
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =188
		- Total unique tokens  =102
		- Total unique tokens ignore case =99
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =9
		- OOV tokens, no repetitions, Case Sensitive =4
		- Total OOV tokens even after lowercasing  =9
		- OOV tokens even after lowercasing, no repetition  =4
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =16
		- OOV tokens, no repetitions, Case Sensitive =7
		- Total OOV tokens even after lowercasing  =16
		- OOV tokens even after lowercasing, no repetition  =7
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =3
		- OOV tokens, no repetitions, Case Sensitive =2
		- Total OOV tokens even after lowercasing  =3
		- OOV tokens even after lowercasing, no repetition  =2
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 166 milliseconds
Constructing a problem for the following text: 
  Baghdad 11-15 (AFP) -  The head of the French Interests Section in Baghdad, Ambassador Andre Janier, today Wednesday welcomed Iraq's decision to deal in euros and said this would encourage relati...
Annotating mention view..
1 milliseconds elapsed on constructing the TF-IDF representation of the input text...20001115_AFP_ARB.0072.eng
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Adding NER candidates for 20001115_AFP_ARB.0072.eng
Adding SHALLOW_PARSE and subChunk candidates for 20001115_AFP_ARB.0072.eng
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Matched regex entity French Interests Section in Baghdad, Ambassador Andre Janier[41-101]{10-19}
Matched regex entity Baghdad, Ambassador Andre Janier[69-101]{14-19}
Matched regex entity Iraq and France[481-496]{85-88}
Matched regex entity Europeans and French[584-604]{107-110}
Matched regex entity European and French[690-709]{126-129}
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Done constructing the Wikifiable entities
     ----  almost there....
115 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...20001115_AFP_ARB.0072.eng
Inference on the document  -- 20001115_AFP_ARB.0072.eng
1 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
1 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
42 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
2 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
9 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
1 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: Baghdad to : http://en.wikipedia.org/wiki/Baghdad
Level:FeatureExtractorCoherenceCorrect Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level:FeatureExtractorCoherenceCorrect Wikification of: Iraq to : http://en.wikipedia.org/wiki/Iraq
Level:FeatureExtractorCoherenceCorrect Wikification of: Baghdad to : http://en.wikipedia.org/wiki/Baghdad
Level:FeatureExtractorCoherenceCorrect Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level:FeatureExtractorCoherenceCorrect Wikification of: Iraq to : http://en.wikipedia.org/wiki/Iraq
Could not find WikiMatchData for title Interests
Could not find WikiMatchData for title Deals
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=European_Union, pred=WIKI_LINK_RELATION, arg2=France, score=2.126506805419922, normalizedScore=0.06233642529379007]For surfaces Europeans and French
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Europe, pred=WIKI_LINK_RELATION, arg2=French_Revolution, score=2.1071568727493286, normalizedScore=0.06323036606846211]For surfaces Europeans and French
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Europe, pred=WIKI_LINK_RELATION, arg2=French_people, score=1.7598977088928223, normalizedScore=0.05898792894121632]For surfaces Europeans and French
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Europe, pred=WIKI_LINK_RELATION, arg2=French_Navy, score=1.7598977088928223, normalizedScore=0.05898792894121632]For surfaces Europeans and French
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Europe, pred=WIKI_LINK_RELATION, arg2=First_French_Empire, score=1.4169437885284424, normalizedScore=0.0550775418798088]For surfaces Europeans and French
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Europe, pred=WIKI_LINK_RELATION, arg2=French_colonial_empire, score=1.4169437885284424, normalizedScore=0.0550775418798088]For surfaces Europeans and French
Relational inference took 3ms
CoherenceRelation 89 [arg1=[surface=Andre, solution=*null*], arg2=[surface=Andre Janier, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 89 [arg1=[surface=Janier, solution=*null*], arg2=[surface=Andre Janier, solution=*null*], weight=10.0] is captured by ILP inference.
Discarded 6 hypothesis
Level: Relational Coherence Correct Wikification of: Baghdad to : http://en.wikipedia.org/wiki/Baghdad
Level: Relational Coherence Correct Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level: Relational Coherence Correct Wikification of: Iraq to : http://en.wikipedia.org/wiki/Iraq
Annotation at test time--135 milliseconds elapsed to annotate the document 20001115_AFP_ARB.0072.eng
Final System Output:Correct Wikification of: Baghdad to : http://en.wikipedia.org/wiki/Baghdad
Candidates Entropy: 0.3276840291919965
Final System Output:Correct Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Candidates Entropy: 1.245290711150085
Final System Output:Correct Wikification of: Iraq to : http://en.wikipedia.org/wiki/Iraq
Candidates Entropy: 0.0
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/20001115_AFP_ARB.0072.eng.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/20001015_AFP_ARB.0053.eng
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =318
		- Total unique tokens  =165
		- Total unique tokens ignore case =159
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =13
		- OOV tokens, no repetitions, Case Sensitive =6
		- Total OOV tokens even after lowercasing  =13
		- OOV tokens even after lowercasing, no repetition  =6
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =23
		- OOV tokens, no repetitions, Case Sensitive =10
		- Total OOV tokens even after lowercasing  =23
		- OOV tokens even after lowercasing, no repetition  =10
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =12
		- OOV tokens, no repetitions, Case Sensitive =6
		- Total OOV tokens even after lowercasing  =11
		- OOV tokens even after lowercasing, no repetition  =5
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 194 milliseconds
Constructing a problem for the following text: 
  Beirut 10-15 (AFP) -  The Saudi Soccer Federation sacked the team's Czech coach Milan Machala from his post today Sunday and appointed his assistant, Nasser Jawhar, in his place.   The title-hold...
Annotating mention view..
1 milliseconds elapsed on constructing the TF-IDF representation of the input text...20001015_AFP_ARB.0053.eng
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Adding NER candidates for 20001015_AFP_ARB.0053.eng
Adding SHALLOW_PARSE and subChunk candidates for 20001015_AFP_ARB.0053.eng
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Matched regex entity The Youth and Sports Bureau in Saudi Arabia[337-380]{60-68}
Matched regex entity Youth and Sports Bureau in Saudi Arabia[341-380]{61-68}
Matched regex entity Sports Bureau in Saudi Arabia[351-380]{63-68}
Matched regex entity Youth and Sports Bureau[452-475]{82-86}
Matched regex entity Mexico in July[1362-1376]{250-253}
Matched regex entity Asian Nations Championship in the Emirates[1610-1652]{298-304}
Matched regex entity Asian Games in Bangkok[1685-1707]{312-316}
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Done constructing the Wikifiable entities
     ----  almost there....
381 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...20001015_AFP_ARB.0053.eng
Inference on the document  -- 20001015_AFP_ARB.0053.eng
2 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
4 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
46 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
7 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
136 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
3 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: Beirut to : http://en.wikipedia.org/wiki/Beirut
Level:FeatureExtractorCoherenceCorrect Wikification of: Saudi Soccer Federation to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Youth and Sports Bureau to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Lebanon to : http://en.wikipedia.org/wiki/Lebanon
Level:FeatureExtractorCoherenceCorrect Wikification of: Emirates to : http://en.wikipedia.org/wiki/United_Arab_Emirates
Level:FeatureExtractorCoherenceCorrect Wikification of: Mexico to : http://en.wikipedia.org/wiki/Mexico
Level:FeatureExtractorCoherenceCorrect Wikification of: Bangkok to : http://en.wikipedia.org/wiki/Bangkok
Level:FeatureExtractorCoherenceCorrect Wikification of: Beirut to : http://en.wikipedia.org/wiki/Beirut
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: AFP; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Agence_France-Presse;
  The confusions set is : Agence_France-Presse(ranker score=2.1541842170743877) Vs: AFP(ranker score=2.368366163733612);
  The context is: ; ------- ;   Beirut 10-15 (AFP) -  The Saudi Soccer Federation sacked the team's Czech coach Milan Machala from his post today Sunday and appointed his assistant, Nasser Jawhar, in his place.   The title-holding Saudi team suff
Level:FeatureExtractorCoherenceCorrect Wikification of: Saudi Soccer Federation to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Youth and Sports Bureau to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Lebanon to : http://en.wikipedia.org/wiki/Lebanon
Level:FeatureExtractorCoherenceCorrect Wikification of: Emirates to : http://en.wikipedia.org/wiki/United_Arab_Emirates
Level:FeatureExtractorCoherenceCorrect Wikification of: Mexico to : http://en.wikipedia.org/wiki/Mexico
Level:FeatureExtractorCoherenceCorrect Wikification of: Bangkok to : http://en.wikipedia.org/wiki/Bangkok
Could not find WikiMatchData for title Success_Is_Certain
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Saudi_Arabia, pred=WIKI_LINK_RELATION, arg2=Association_football, score=2.309312105178833, normalizedScore=100.0]For surfaces Saudi and Soccer
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Saudi_Arabia, pred=WIKI_LINK_RELATION, arg2=Association_football, score=2.309312105178833, normalizedScore=100.0]For surfaces Saudi and Soccer
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Milan Machala[82-95]{16-18} === the team 's Czech coach
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Sultan Ben Fahd[418-433]{75-78} === president of the Youth and Sports Bureau and president of the Saudi Soccer Federation
Relational inference took 6ms
CoherenceRelation 1054 [arg1=[surface=Nations Cup, solution=AFC_Asian_Cup], arg2=[surface=Asian Nations Cup, solution=AFC_Asian_Cup], weight=10.0] is captured by ILP inference.
CoherenceRelation 82 [arg1=[surface=Milan, solution=*null*], arg2=[surface=Milan Machala, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 503 [arg1=[surface=Saudi, solution=Saudi_Arabia], arg2=[surface=Soccer, solution=Association_football], weight=100.0] is captured by ILP inference.
CoherenceRelation 28 [arg1=[surface=Saudi Soccer Federation, solution=*null*], arg2=[surface=Saudi Soccer Federation, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 82 [arg1=[surface=Machala, solution=*null*], arg2=[surface=Milan Machala, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 152 [arg1=[surface=Jawhar, solution=*null*], arg2=[surface=Nasser Jawhar, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 606 [arg1=[surface=Jawhar, solution=*null*], arg2=[surface=Nasser Jawhar, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 606 [arg1=[surface=Nasser Jawhar, solution=*null*], arg2=[surface=Nasser Jawhar, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 152 [arg1=[surface=Nasser, solution=*null*], arg2=[surface=Nasser Jawhar, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 606 [arg1=[surface=Nasser, solution=*null*], arg2=[surface=Nasser Jawhar, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 28 [arg1=[surface=Saudi Federation, solution=*null*], arg2=[surface=Saudi Soccer Federation, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 34 [arg1=[surface=Saudi, solution=Saudi_Arabia], arg2=[surface=Soccer, solution=Association_football], weight=100.0] is captured by ILP inference.
Discarded 0 hypothesis
Level: Relational Coherence Correct Wikification of: Beirut to : http://en.wikipedia.org/wiki/Beirut
Level: Relational Coherence : Still Incorrect Wikification of: AFP; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Agence_France-Presse;
  The confusions set is : Agence_France-Presse(ranker score=0.33725333099626414) Vs: AFP(ranker score=0.4178056275994525);
  The context is: ; ------- ;   Beirut 10-15 (AFP) -  The Saudi Soccer Federation sacked the team's Czech coach Milan Machala from his post today Sunday and appointed his assistant, Nasser Jawhar, in his place.   The title-holding Saudi team suff
Level: Relational Coherence Correct Wikification of: Saudi Soccer Federation to : http://en.wikipedia.org/wiki/*null*
Level: Relational Coherence Correct Wikification of: Youth and Sports Bureau to : http://en.wikipedia.org/wiki/*null*
Level: Relational Coherence Correct Wikification of: Lebanon to : http://en.wikipedia.org/wiki/Lebanon
Level: Relational Coherence Correct Wikification of: Emirates to : http://en.wikipedia.org/wiki/United_Arab_Emirates
Level: Relational Coherence Correct Wikification of: Mexico to : http://en.wikipedia.org/wiki/Mexico
Level: Relational Coherence Correct Wikification of: Bangkok to : http://en.wikipedia.org/wiki/Bangkok
Annotation at test time--393 milliseconds elapsed to annotate the document 20001015_AFP_ARB.0053.eng
Final System Output:Correct Wikification of: Beirut to : http://en.wikipedia.org/wiki/Beirut
Candidates Entropy: 0.08460273582127459
Final System Output:: Still Incorrect Wikification of: AFP; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Agence_France-Presse;
  The confusions set is : Agence_France-Presse(ranker score=0.33725333099626414) Vs: AFP(ranker score=0.4178056275994525);
  The context is: ; ------- ;   Beirut 10-15 (AFP) -  The Saudi Soccer Federation sacked the team's Czech coach Milan Machala from his post today Sunday and appointed his assistant, Nasser Jawhar, in his place.   The title-holding Saudi team suff
Candidates Entropy: 1.452910811164111
Final System Output:Correct Wikification of: Saudi Soccer Federation to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Youth and Sports Bureau to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Lebanon to : http://en.wikipedia.org/wiki/Lebanon
Candidates Entropy: 0.29400694361266344
Final System Output:Correct Wikification of: Emirates to : http://en.wikipedia.org/wiki/United_Arab_Emirates
Candidates Entropy: 0.32264501892608305
Final System Output:Correct Wikification of: Mexico to : http://en.wikipedia.org/wiki/Mexico
Candidates Entropy: 1.1441600481012462
Final System Output:Correct Wikification of: Bangkok to : http://en.wikipedia.org/wiki/Bangkok
Candidates Entropy: 0.02834153683412413
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/20001015_AFP_ARB.0053.eng.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/chtb_267.eng
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =617
		- Total unique tokens  =245
		- Total unique tokens ignore case =239
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =8
		- OOV tokens, no repetitions, Case Sensitive =8
		- Total OOV tokens even after lowercasing  =8
		- OOV tokens even after lowercasing, no repetition  =8
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =12
		- OOV tokens, no repetitions, Case Sensitive =12
		- Total OOV tokens even after lowercasing  =12
		- OOV tokens even after lowercasing, no repetition  =12
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =9
		- OOV tokens, no repetitions, Case Sensitive =8
		- Total OOV tokens even after lowercasing  =9
		- OOV tokens even after lowercasing, no repetition  =8
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 444 milliseconds
Constructing a problem for the following text: 
  Xinhua News Agency, Beijing, September 1st, by reporter Jingcai Wu  The Weir Group of the US recently signed an implementation agreement in Beijing with Jiangsu Province's Electric Power Departme...
Annotating mention view..
1 milliseconds elapsed on constructing the TF-IDF representation of the input text...chtb_267.eng
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Adding NER candidates for chtb_267.eng
Adding SHALLOW_PARSE and subChunk candidates for chtb_267.eng
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Matched regex entity Beijing, September[22-40]{4-7}
Matched regex entity Jingcai Wu The Weir Group of the US[58-94]{11-19}
Matched regex entity Weir Group of the US[74-94]{14-19}
Matched regex entity Beijing with Jiangsu Province's Electric Power Department[142-199]{25-33}
Matched regex entity Jiangsu Province's Electric Power Department[155-199]{27-33}
Matched regex entity International Co-operation Department of the Electric Power Industry Ministry[316-393]{54-63}
Matched regex entity Yizhong Company of the US, the Weir Group and the Jiangsu Electric Power Department[1700-1783]{291-306}
Matched regex entity US, the Weir Group and the Jiangsu Electric Power Department[1723-1783]{295-306}
Matched regex entity Weir Group and the Jiangsu Electric Power Department[1731-1783]{298-306}
Matched regex entity Rudong, Jiangsu[1927-1942]{331-334}
Matched regex entity Japan, South Korea and Taiwan[2704-2733]{471-477}
Matched regex entity South Korea and Taiwan[2711-2733]{473-477}
Matched regex entity China with US Minister Brown[3151-3179]{548-553}
Matched regex entity US and China[3419-3431]{594-597}
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Done constructing the Wikifiable entities
     ----  almost there....
436 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...chtb_267.eng
Inference on the document  -- chtb_267.eng
5 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
10 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
110 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
16 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
430 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
8 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: Xinhua News Agency to : http://en.wikipedia.org/wiki/Xinhua_News_Agency
Level:FeatureExtractorCoherenceCorrect Wikification of: Beijing to : http://en.wikipedia.org/wiki/Beijing
Level:FeatureExtractorCoherenceCorrect Wikification of: Weir Group to : http://en.wikipedia.org/wiki/Weir_Group
Level:FeatureExtractorCoherenceCorrect Wikification of: US to : http://en.wikipedia.org/wiki/United_States
Level:FeatureExtractorCoherenceCorrect Wikification of: Jiangsu Province to : http://en.wikipedia.org/wiki/Jiangsu
Level:FeatureExtractorCoherenceCorrect Wikification of: Electric Power Department to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: China to : http://en.wikipedia.org/wiki/China
Level:FeatureExtractorCoherenceCorrect Wikification of: Aixing Dan to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: International Co-operation Department to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Electric Power Industry Ministry to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Yizhong Company to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Rudong to : http://en.wikipedia.org/wiki/Rudong_County
Level:FeatureExtractorCoherenceCorrect Wikification of: Renzu Luo to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Japan to : http://en.wikipedia.org/wiki/Japan
Level:FeatureExtractorCoherenceCorrect Wikification of: South Korea to : http://en.wikipedia.org/wiki/South_Korea
Level:FeatureExtractorCoherenceCorrect Wikification of: Taiwan to : http://en.wikipedia.org/wiki/Taiwan
Level:FeatureExtractorCoherenceCorrect Wikification of: Xinhua News Agency to : http://en.wikipedia.org/wiki/Xinhua_News_Agency
Level:FeatureExtractorCoherenceCorrect Wikification of: Beijing to : http://en.wikipedia.org/wiki/Beijing
Level:FeatureExtractorCoherenceCorrect Wikification of: Weir Group to : http://en.wikipedia.org/wiki/Weir_Group
Level:FeatureExtractorCoherenceCorrect Wikification of: US to : http://en.wikipedia.org/wiki/United_States
Level:FeatureExtractorCoherenceCorrect Wikification of: Jiangsu Province to : http://en.wikipedia.org/wiki/Jiangsu
Level:FeatureExtractorCoherenceCorrect Wikification of: Electric Power Department to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: China to : http://en.wikipedia.org/wiki/China
Level:FeatureExtractorCoherenceCorrect Wikification of: Aixing Dan to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: International Co-operation Department to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Electric Power Industry Ministry to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Yizhong Company to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Rudong to : http://en.wikipedia.org/wiki/Rudong_County
Level:FeatureExtractorCoherenceCorrect Wikification of: Renzu Luo to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Japan to : http://en.wikipedia.org/wiki/Japan
Level:FeatureExtractorCoherenceCorrect Wikification of: South Korea to : http://en.wikipedia.org/wiki/South_Korea
Level:FeatureExtractorCoherenceCorrect Wikification of: Taiwan to : http://en.wikipedia.org/wiki/Taiwan
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: John Weir; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/John_Weir ; the gold is: http://en.wikipedia.org/wiki/*null*;
  The surface form has a single disambiguation candidate : John_Weir(ranker score=4.477110808066419) ;
  The context is: ; ------- ; ational product in China's coastal regions begins to approach this benchmark, it can be said to have had the conditions for electricity generation using natural gas in terms of financial resources.   John Weir, president of the Weir Group who visited China with US Minister Brown and signed this agreement for electricity generation plant construction in Jiangsu, held that now is the best time to de
Level:FeatureExtractorCoherenceCorrect Wikification of: Brown to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherencethis fixes the Wikification (!!!)Brown; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/*null*;
  The confusions set is : Edward_Brown(ranker score=0.96859955066945) Vs: Brown_University(ranker score=1.1100855922312496);
  The context is: ; ------- ; rk, it can be said to have had the conditions for electricity generation using natural gas in terms of financial resources.   John Weir, president of the Weir Group who visited China with US Minister Brown and signed this agreement for electricity generation plant construction in Jiangsu, held that now is the best time to develop a project of joint circulatory electricity generation plant with nat
Could not find WikiMatchData for title Electric_power_industry
Could not find WikiMatchData for title Nameplate_capacity
Could not find WikiMatchData for title Best_Time
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Dan[295-298]{49-50} === director of the International Co-operation Department of the Electric Power Industry Ministry
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - Force linking Dan[295-298]{49-50} to null
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Renzu Luo[2280-2289]{399-401} === managing director of the Weir Group
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:John Weir[3100-3109]{538-540} === president of the Weir Group who
Relational inference took 20ms
CoherenceRelation 2280 [arg1=[surface=Luo, solution=*null*], arg2=[surface=Renzu Luo, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 2104 [arg1=[surface=Weir Group, solution=Weir_Group], arg2=[surface=Weir Group, solution=Weir_Group], weight=10.0] is captured by ILP inference.
CoherenceRelation 2104 [arg1=[surface=Weir Group, solution=Weir_Group], arg2=[surface=Weir Group, solution=Weir_Group], weight=10.0] is captured by ILP inference.
CoherenceRelation 2104 [arg1=[surface=Weir Group, solution=Weir_Group], arg2=[surface=Weir Group, solution=Weir_Group], weight=10.0] is captured by ILP inference.
CoherenceRelation 1750 [arg1=[surface=Electric Power Department, solution=*null*], arg2=[surface=Jiangsu Electric Power Department, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 2104 [arg1=[surface=Weir Group, solution=Weir_Group], arg2=[surface=Weir Group, solution=Weir_Group], weight=10.0] is captured by ILP inference.
CoherenceRelation 2104 [arg1=[surface=Weir Group, solution=Weir_Group], arg2=[surface=Weir Group, solution=Weir_Group], weight=10.0] is captured by ILP inference.
CoherenceRelation 424 [arg1=[surface=Agency, solution=Xinhua_News_Agency], arg2=[surface=Xinhua News Agency, solution=Xinhua_News_Agency], weight=10.0] is captured by ILP inference.
CoherenceRelation 70 [arg1=[surface=Group, solution=Weir_Group], arg2=[surface=The Weir Group, solution=Weir_Group], weight=10.0] is captured by ILP inference.
CoherenceRelation 58 [arg1=[surface=Wu, solution=*null*], arg2=[surface=Jingcai Wu, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 3100 [arg1=[surface=Weir, solution=John_Weir], arg2=[surface=John Weir, solution=John_Weir], weight=10.0] is captured by ILP inference.
CoherenceRelation 2 [arg1=[surface=Agency, solution=Xinhua_News_Agency], arg2=[surface=Xinhua News Agency, solution=Xinhua_News_Agency], weight=10.0] is captured by ILP inference.
CoherenceRelation 58 [arg1=[surface=Jingcai, solution=*null*], arg2=[surface=Jingcai Wu, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 3100 [arg1=[surface=John, solution=John_Weir], arg2=[surface=John Weir, solution=John_Weir], weight=10.0] is captured by ILP inference.
CoherenceRelation 2104 [arg1=[surface=Weir Group, solution=Weir_Group], arg2=[surface=Weir Group, solution=Weir_Group], weight=10.0] is captured by ILP inference.
CoherenceRelation 1423 [arg1=[surface=Group, solution=Weir_Group], arg2=[surface=The Weir Group, solution=Weir_Group], weight=10.0] is captured by ILP inference.
Discarded 0 hypothesis
Level: Relational Coherence Correct Wikification of: Xinhua News Agency to : http://en.wikipedia.org/wiki/Xinhua_News_Agency
Level: Relational Coherence Correct Wikification of: Beijing to : http://en.wikipedia.org/wiki/Beijing
Level: Relational Coherence Correct Wikification of: Weir Group to : http://en.wikipedia.org/wiki/Weir_Group
Level: Relational Coherence Correct Wikification of: US to : http://en.wikipedia.org/wiki/United_States
Level: Relational Coherence Correct Wikification of: Jiangsu Province to : http://en.wikipedia.org/wiki/Jiangsu
Level: Relational Coherence Correct Wikification of: Electric Power Department to : http://en.wikipedia.org/wiki/*null*
Level: Relational Coherence Correct Wikification of: China to : http://en.wikipedia.org/wiki/China
Level: Relational Coherence Correct Wikification of: Aixing Dan to : http://en.wikipedia.org/wiki/*null*
Level: Relational Coherence Correct Wikification of: International Co-operation Department to : http://en.wikipedia.org/wiki/*null*
Level: Relational Coherence Correct Wikification of: Electric Power Industry Ministry to : http://en.wikipedia.org/wiki/*null*
Level: Relational Coherence Correct Wikification of: Yizhong Company to : http://en.wikipedia.org/wiki/*null*
Level: Relational Coherence Correct Wikification of: Rudong to : http://en.wikipedia.org/wiki/Rudong_County
Level: Relational Coherence Correct Wikification of: Renzu Luo to : http://en.wikipedia.org/wiki/*null*
Level: Relational Coherence Correct Wikification of: Japan to : http://en.wikipedia.org/wiki/Japan
Level: Relational Coherence Correct Wikification of: South Korea to : http://en.wikipedia.org/wiki/South_Korea
Level: Relational Coherence Correct Wikification of: Taiwan to : http://en.wikipedia.org/wiki/Taiwan
Level: Relational Coherence : Still Incorrect Wikification of: John Weir; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/John_Weir ; the gold is: http://en.wikipedia.org/wiki/*null*;
  The surface form has a single disambiguation candidate : John_Weir(ranker score=1.0) ;
  The context is: ; ------- ; ational product in China's coastal regions begins to approach this benchmark, it can be said to have had the conditions for electricity generation using natural gas in terms of financial resources.   John Weir, president of the Weir Group who visited China with US Minister Brown and signed this agreement for electricity generation plant construction in Jiangsu, held that now is the best time to de
Level: Relational Coherence Correct Wikification of: Brown to : http://en.wikipedia.org/wiki/*null*
Annotation at test time--1206 milliseconds elapsed to annotate the document chtb_267.eng
Final System Output:Correct Wikification of: Xinhua News Agency to : http://en.wikipedia.org/wiki/Xinhua_News_Agency
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Beijing to : http://en.wikipedia.org/wiki/Beijing
Candidates Entropy: 0.3318739528827378
Final System Output:Correct Wikification of: Weir Group to : http://en.wikipedia.org/wiki/Weir_Group
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: US to : http://en.wikipedia.org/wiki/United_States
Candidates Entropy: 1.2321570757366584
Final System Output:Correct Wikification of: Jiangsu Province to : http://en.wikipedia.org/wiki/Jiangsu
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Electric Power Department to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: China to : http://en.wikipedia.org/wiki/China
Candidates Entropy: 0.3809858660210552
Final System Output:Correct Wikification of: Aixing Dan to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: International Co-operation Department to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Electric Power Industry Ministry to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Yizhong Company to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Rudong to : http://en.wikipedia.org/wiki/Rudong_County
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Renzu Luo to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Japan to : http://en.wikipedia.org/wiki/Japan
Candidates Entropy: 0.16536611045729863
Final System Output:Correct Wikification of: South Korea to : http://en.wikipedia.org/wiki/South_Korea
Candidates Entropy: 0.11514309322170407
Final System Output:Correct Wikification of: Taiwan to : http://en.wikipedia.org/wiki/Taiwan
Candidates Entropy: 0.07856865864069419
Final System Output:: Still Incorrect Wikification of: NIL [NER, PER]Entity:John Weir; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/John_Weir ; the gold is: http://en.wikipedia.org/wiki/*null*;
  The surface form has a single disambiguation candidate : John_Weir(ranker score=1.0) ;
  The context is: ; ------- ; ational product in China's coastal regions begins to approach this benchmark, it can be said to have had the conditions for electricity generation using natural gas in terms of financial resources.   John Weir, president of the Weir Group who visited China with US Minister Brown and signed this agreement for electricity generation plant construction in Jiangsu, held that now is the best time to de
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Brown to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 2.9153876790196422
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/chtb_267.eng.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/20000815_AFP_ARB.0071.eng
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =298
		- Total unique tokens  =174
		- Total unique tokens ignore case =171
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =2
		- OOV tokens, no repetitions, Case Sensitive =2
		- Total OOV tokens even after lowercasing  =2
		- OOV tokens even after lowercasing, no repetition  =2
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =10
		- OOV tokens, no repetitions, Case Sensitive =9
		- Total OOV tokens even after lowercasing  =10
		- OOV tokens even after lowercasing, no repetition  =9
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =7
		- OOV tokens, no repetitions, Case Sensitive =6
		- Total OOV tokens even after lowercasing  =7
		- OOV tokens even after lowercasing, no repetition  =6
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 288 milliseconds
Constructing a problem for the following text: 
  Beirut 8-15 (AFP) -  Lebanon has asked the international peacekeeping force operating in the south to investigate reports indicating that Israel is penetrating the shared border between the two c...
Annotating mention view..
1 milliseconds elapsed on constructing the TF-IDF representation of the input text...20000815_AFP_ARB.0071.eng
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Adding NER candidates for 20000815_AFP_ARB.0071.eng
Adding SHALLOW_PARSE and subChunk candidates for 20000815_AFP_ARB.0071.eng
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Matched regex entity Lebanon and Israel[780-798]{126-129}
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Important warning: the manually defined entity Abbad sector had 0 disambiguation candidates
Done constructing the Wikifiable entities
     ----  almost there....
229 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...20000815_AFP_ARB.0071.eng
Inference on the document  -- 20000815_AFP_ARB.0071.eng
2 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
3 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
89 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
6 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
81 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
3 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: Beirut to : http://en.wikipedia.org/wiki/Beirut
Level:FeatureExtractorCoherenceCorrect Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level:FeatureExtractorCoherenceCorrect Wikification of: Lebanon to : http://en.wikipedia.org/wiki/Lebanon
Level:FeatureExtractorCoherenceCorrect Wikification of: Israel to : http://en.wikipedia.org/wiki/Israel
Level:FeatureExtractorCoherenceCorrect Wikification of: Wadi Marjayoun to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Beirut to : http://en.wikipedia.org/wiki/Beirut
Level:FeatureExtractorCoherenceCorrect Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level:FeatureExtractorCoherenceCorrect Wikification of: Lebanon to : http://en.wikipedia.org/wiki/Lebanon
Level:FeatureExtractorCoherenceCorrect Wikification of: Israel to : http://en.wikipedia.org/wiki/Israel
Level:FeatureExtractorCoherenceCorrect Wikification of: Wadi Marjayoun to : http://en.wikipedia.org/wiki/*null*
Relational inference took 4ms
CoherenceRelation 719 [arg1=[surface=Abbad, solution=Abbad], arg2=[surface=Abbad, solution=Abbad], weight=10.0] is captured by ILP inference.
Discarded 0 hypothesis
Level: Relational Coherence Correct Wikification of: Beirut to : http://en.wikipedia.org/wiki/Beirut
Level: Relational Coherence Correct Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level: Relational Coherence Correct Wikification of: Lebanon to : http://en.wikipedia.org/wiki/Lebanon
Level: Relational Coherence Correct Wikification of: Israel to : http://en.wikipedia.org/wiki/Israel
Level: Relational Coherence Correct Wikification of: Wadi Marjayoun to : http://en.wikipedia.org/wiki/*null*
Annotation at test time--264 milliseconds elapsed to annotate the document 20000815_AFP_ARB.0071.eng
Final System Output:Correct Wikification of: Beirut to : http://en.wikipedia.org/wiki/Beirut
Candidates Entropy: 0.18222473575907577
Final System Output:Correct Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Candidates Entropy: 1.6583047254482395
Final System Output:Correct Wikification of: Lebanon to : http://en.wikipedia.org/wiki/Lebanon
Candidates Entropy: 0.05667607319632567
Final System Output:Correct Wikification of: Israel to : http://en.wikipedia.org/wiki/Israel
Candidates Entropy: 0.03030863097600705
Final System Output:Correct Wikification of: Wadi Marjayoun to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/20000815_AFP_ARB.0071.eng.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/APW20001023.2100.0686
Empty problem - no reference instances!!!
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/20001115_AFP_ARB.0013.eng
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =293
		- Total unique tokens  =170
		- Total unique tokens ignore case =168
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =10
		- OOV tokens, no repetitions, Case Sensitive =7
		- Total OOV tokens even after lowercasing  =10
		- OOV tokens even after lowercasing, no repetition  =7
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =15
		- OOV tokens, no repetitions, Case Sensitive =12
		- Total OOV tokens even after lowercasing  =14
		- OOV tokens even after lowercasing, no repetition  =11
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =6
		- OOV tokens, no repetitions, Case Sensitive =6
		- Total OOV tokens even after lowercasing  =6
		- OOV tokens even after lowercasing, no repetition  =6
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 375 milliseconds
Constructing a problem for the following text: 
  Bandar Seri Begawan 11-15 (AFP) -  American President Bill Clinton attempted today Wednesday to reassure money markets about doubts caused by the battle between the Republicans and Democrats on t...
Annotating mention view..
1 milliseconds elapsed on constructing the TF-IDF representation of the input text...20001115_AFP_ARB.0013.eng
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Adding NER candidates for 20001115_AFP_ARB.0013.eng
Adding SHALLOW_PARSE and subChunk candidates for 20001115_AFP_ARB.0013.eng
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Matched regex entity Republicans and Democrats[167-192]{27-30}
Matched regex entity State of Florida[333-349]{56-59}
Matched regex entity Vice-President Al Gore and Governor George Bush[492-539]{84-91}
Matched regex entity President Al Gore and Governor George Bush[497-539]{84-91}
Matched regex entity Gore and Governor George Bush[510-539]{86-91}
Matched regex entity Florida on Tuesday[1048-1066]{182-185}
Matched regex entity In Brunei, President Clinton[1239-1267]{212-217}
Matched regex entity Brunei, President Clinton[1242-1267]{213-217}
Matched regex entity Democratic and Republican[1384-1409]{235-238}
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Done constructing the Wikifiable entities
     ----  almost there....
363 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...20001115_AFP_ARB.0013.eng
Inference on the document  -- 20001115_AFP_ARB.0013.eng
2 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
5 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
119 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
10 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
158 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
4 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: Bandar Seri Begawan to : http://en.wikipedia.org/wiki/Bandar_Seri_Begawan
Level:FeatureExtractorCoherenceCorrect Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level:FeatureExtractorCoherenceCorrect Wikification of: State of Florida to : http://en.wikipedia.org/wiki/Florida
Level:FeatureExtractorCoherenceCorrect Wikification of: Brunei to : http://en.wikipedia.org/wiki/Brunei
Level:FeatureExtractorCoherenceCorrect Wikification of: Bandar Seri Begawan to : http://en.wikipedia.org/wiki/Bandar_Seri_Begawan
Level:FeatureExtractorCoherence: this introduces a Wikification error(!!!): AFP; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Agence_France-Presse;
  The confusions set is : Armed_Forces_of_the_Philippines(ranker score=0.9000949921546303) Vs: Agence_France-Presse(ranker score=1.4922454694870657);
  The context is: ; ------- ;   Bandar Seri Begawan 11-15 (AFP) -  American President Bill Clinton attempted today Wednesday to reassure money markets about doubts caused by the battle between the Republicans and Democrats on the result of the presidential el
Level:FeatureExtractorCoherenceCorrect Wikification of: State of Florida to : http://en.wikipedia.org/wiki/Florida
Level:FeatureExtractorCoherenceCorrect Wikification of: Brunei to : http://en.wikipedia.org/wiki/Brunei
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=President_of_the_United_States, pred=WIKI_LINK_RELATION, arg2=Bill_Clinton, score=7.646950435638427, normalizedScore=100.0]For surfaces American President and Bill Clinton
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Republican_Party_(United_States), pred=WIKI_LINK_RELATION, arg2=Democratic_Party_(United_States), score=1.737709641456604, normalizedScore=100.0]For surfaces Republicans and Democrats
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Al_Gore, pred=WIKI_LINK_RELATION, arg2=Governor_of_California, score=1.5080571174621582, normalizedScore=100.0]For surfaces Vice-President Al Gore and Governor
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Al_Gore, pred=WIKI_LINK_RELATION, arg2=Governor_of_California, score=1.5080571174621582, normalizedScore=100.0]For surfaces Gore and Governor
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Governor, pred=WIKI_LINK_RELATION, arg2=George_W._Bush, score=2.892906427383423, normalizedScore=100.0]For surfaces Governor and George Bush
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Al_Gore due to a longer mention than Gore that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Al_Gore_presidential_campaign,_2000 due to a longer mention than Gore that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Al_Gore due to a longer mention than Gore that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Al_Gore_and_information_technology due to a longer mention than Gore that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Asia-Pacific_Economic_Cooperation due to a longer mention than Apec that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bill_Clinton due to a longer mention than Clinton that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bill_Clinton due to a longer mention than Clinton that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bill_Clinton due to a longer mention than Clinton that referred to the same thing
Relational inference took 18ms
CoherenceRelation 1103 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 46 [arg1=[surface=Bill Clinton, solution=Bill_Clinton], arg2=[surface=President Bill Clinton, solution=Bill_Clinton], weight=10.0] is captured by ILP inference.
CoherenceRelation 1250 [arg1=[surface=Bill Clinton, solution=Bill_Clinton], arg2=[surface=President Clinton, solution=Bill_Clinton], weight=10.0] is captured by ILP inference.
CoherenceRelation 1082 [arg1=[surface=Republican, solution=Republican_Party_(United_States)], arg2=[surface=Republican, solution=Republican_Party_(United_States)], weight=10.0] is captured by ILP inference.
CoherenceRelation 1103 [arg1=[surface=George, solution=George_W._Bush], arg2=[surface=George Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 56 [arg1=[surface=American President, solution=President_of_the_United_States], arg2=[surface=Bill Clinton, solution=Bill_Clinton], weight=100.0] is captured by ILP inference.
CoherenceRelation 1250 [arg1=[surface=Clinton, solution=Bill_Clinton], arg2=[surface=President Clinton, solution=Bill_Clinton], weight=10.0] is captured by ILP inference.
CoherenceRelation 1159 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 528 [arg1=[surface=George, solution=George_W._Bush], arg2=[surface=George Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 56 [arg1=[surface=Clinton, solution=Bill_Clinton], arg2=[surface=Bill Clinton, solution=Bill_Clinton], weight=10.0] is captured by ILP inference.
CoherenceRelation 183 [arg1=[surface=Republicans, solution=Republican_Party_(United_States)], arg2=[surface=Democrats, solution=Democratic_Party_(United_States)], weight=50.0] is captured by ILP inference.
CoherenceRelation 1250 [arg1=[surface=President, solution=Bill_Clinton], arg2=[surface=President Clinton, solution=Bill_Clinton], weight=10.0] is captured by ILP inference.
CoherenceRelation 507 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 1103 [arg1=[surface=George Bush, solution=George_W._Bush], arg2=[surface=George Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 528 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 333 [arg1=[surface=State, solution=Florida], arg2=[surface=State of Florida, solution=Florida], weight=10.0] is captured by ILP inference.
CoherenceRelation 507 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 413 [arg1=[surface=Apec, solution=Asia-Pacific_Economic_Cooperation], arg2=[surface=Asia-Pacific Economic Cooperation, solution=Asia-Pacific_Economic_Cooperation], weight=10.0] is captured by ILP inference.
CoherenceRelation 1250 [arg1=[surface=Clinton, solution=Bill_Clinton], arg2=[surface=President Clinton, solution=Bill_Clinton], weight=10.0] is captured by ILP inference.
CoherenceRelation 528 [arg1=[surface=Governor, solution=Governor], arg2=[surface=George Bush, solution=George_W._Bush], weight=100.0] is captured by ILP inference.
CoherenceRelation 1250 [arg1=[surface=Clinton, solution=Bill_Clinton], arg2=[surface=President Clinton, solution=Bill_Clinton], weight=10.0] is captured by ILP inference.
CoherenceRelation 507 [arg1=[surface=Al Gore, solution=Al_Gore], arg2=[surface=Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
Discarded 49 hypothesis
Level: Relational Coherence Correct Wikification of: Bandar Seri Begawan to : http://en.wikipedia.org/wiki/Bandar_Seri_Begawan
Level: Relational Coherence : Still Incorrect Wikification of: AFP; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Agence_France-Presse;
  The confusions set is : Armed_Forces_of_the_Philippines(ranker score=0.18662067387751138) Vs: Agence_France-Presse(ranker score=0.33738629575863016);
  The context is: ; ------- ;   Bandar Seri Begawan 11-15 (AFP) -  American President Bill Clinton attempted today Wednesday to reassure money markets about doubts caused by the battle between the Republicans and Democrats on the result of the presidential el
Level: Relational Coherence Correct Wikification of: State of Florida to : http://en.wikipedia.org/wiki/Florida
Level: Relational Coherence Correct Wikification of: Brunei to : http://en.wikipedia.org/wiki/Brunei
Annotation at test time--608 milliseconds elapsed to annotate the document 20001115_AFP_ARB.0013.eng
Final System Output:Correct Wikification of: Bandar Seri Begawan to : http://en.wikipedia.org/wiki/Bandar_Seri_Begawan
Candidates Entropy: 0.12106053485126153
Final System Output:: Still Incorrect Wikification of: AFP; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Agence_France-Presse;
  The confusions set is : Armed_Forces_of_the_Philippines(ranker score=0.18662067387751138) Vs: Agence_France-Presse(ranker score=0.33738629575863016);
  The context is: ; ------- ;   Bandar Seri Begawan 11-15 (AFP) -  American President Bill Clinton attempted today Wednesday to reassure money markets about doubts caused by the battle between the Republicans and Democrats on the result of the presidential el
Candidates Entropy: 1.7655938620560216
Final System Output:Correct Wikification of: State of Florida to : http://en.wikipedia.org/wiki/Florida
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Brunei to : http://en.wikipedia.org/wiki/Brunei
Candidates Entropy: 0.5533595633429268
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/20001115_AFP_ARB.0013.eng.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/20001015_AFP_ARB.0229.eng
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =141
		- Total unique tokens  =91
		- Total unique tokens ignore case =90
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =7
		- OOV tokens, no repetitions, Case Sensitive =5
		- Total OOV tokens even after lowercasing  =7
		- OOV tokens even after lowercasing, no repetition  =5
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =9
		- OOV tokens, no repetitions, Case Sensitive =7
		- Total OOV tokens even after lowercasing  =9
		- OOV tokens even after lowercasing, no repetition  =7
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =5
		- OOV tokens, no repetitions, Case Sensitive =5
		- Total OOV tokens even after lowercasing  =5
		- OOV tokens even after lowercasing, no repetition  =5
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 124 milliseconds
Constructing a problem for the following text: 
  London 10-16 (AFP) -  A Saudi Airways spokesman in London announced that passengers on the Saudi 777 Boeing, hijacked to Baghdad on Saturday and which arrived in Riyadh yesterday evening Sunday, ...
Annotating mention view..
1 milliseconds elapsed on constructing the TF-IDF representation of the input text...20001015_AFP_ARB.0229.eng
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Adding NER candidates for 20001015_AFP_ARB.0229.eng
Adding SHALLOW_PARSE and subChunk candidates for 20001015_AFP_ARB.0229.eng
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Matched regex entity Baghdad on Saturday[123-142]{23-26}
Matched regex entity Omani, Palestinian and Lebanese[707-738]{130-135}
Matched regex entity Palestinian and Lebanese[714-738]{132-135}
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Done constructing the Wikifiable entities
     ----  almost there....
177 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...20001015_AFP_ARB.0229.eng
Inference on the document  -- 20001015_AFP_ARB.0229.eng
1 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
2 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
45 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
4 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
25 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
3 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: London to : http://en.wikipedia.org/wiki/London
Level:FeatureExtractorCoherenceCorrect Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level:FeatureExtractorCoherenceCorrect Wikification of: Baghdad to : http://en.wikipedia.org/wiki/Baghdad
Level:FeatureExtractorCoherenceCorrect Wikification of: Riyadh to : http://en.wikipedia.org/wiki/Riyadh
Level:FeatureExtractorCoherenceCorrect Wikification of: London to : http://en.wikipedia.org/wiki/London
Level:FeatureExtractorCoherenceCorrect Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level:FeatureExtractorCoherenceCorrect Wikification of: Baghdad to : http://en.wikipedia.org/wiki/Baghdad
Level:FeatureExtractorCoherenceCorrect Wikification of: Riyadh to : http://en.wikipedia.org/wiki/Riyadh
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Riyadh International Airport; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/King_Khalid_International_Airport;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ;  yesterday evening Sunday, left the Saudi capital for London at 2h43 local time (GMT 22h43), approximately 30 hours after the hijacking operation by two Saudi hijackers began.   The Boeing arrived at Riyadh International Airport at 21h30 yesterday Sunday from Baghdad through Jordanian air space with 104 passengers on board, including 14 crew members.  Saudi Airways said Saturday that 40 British, 1
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Riyadh, pred=WIKI_LINK_RELATION, arg2=International_airport, score=3.315082311630249, normalizedScore=100.0]For surfaces Riyadh and International Airport
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Palestinian_people, pred=WIKI_LINK_RELATION, arg2=Lebanon, score=2.9715212821960453, normalizedScore=100.0]For surfaces Palestinian and Lebanese
Relational inference took 3ms
CoherenceRelation 377 [arg1=[surface=Riyadh, solution=Riyadh], arg2=[surface=International Airport, solution=International_airport], weight=100.0] is captured by ILP inference.
CoherenceRelation 524 [arg1=[surface=Saudi Airways, solution=*null*], arg2=[surface=Saudi Airways, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 730 [arg1=[surface=Palestinian, solution=Palestinian_people], arg2=[surface=Lebanese, solution=Lebanon], weight=50.0] is captured by ILP inference.
CoherenceRelation 103 [arg1=[surface=Boeing, solution=Boeing], arg2=[surface=Boeing, solution=Boeing], weight=10.0] is captured by ILP inference.
Discarded 5 hypothesis
Level: Relational Coherence Correct Wikification of: London to : http://en.wikipedia.org/wiki/London
Level: Relational Coherence Correct Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level: Relational Coherence Correct Wikification of: Baghdad to : http://en.wikipedia.org/wiki/Baghdad
Level: Relational Coherence Correct Wikification of: Riyadh to : http://en.wikipedia.org/wiki/Riyadh
Level: Relational Coherence Correct Wikification of: Riyadh International Airport to : http://en.wikipedia.org/wiki/King_Khalid_International_Airport
Level: Relational Coherence this fixes the Wikification (!!!)Riyadh International Airport; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/King_Khalid_International_Airport ; the gold is: http://en.wikipedia.org/wiki/King_Khalid_International_Airport;
  The surface form has a single disambiguation candidate : King_Khalid_International_Airport(ranker score=0.5) ;
  The context is: ; ------- ;  yesterday evening Sunday, left the Saudi capital for London at 2h43 local time (GMT 22h43), approximately 30 hours after the hijacking operation by two Saudi hijackers began.   The Boeing arrived at Riyadh International Airport at 21h30 yesterday Sunday from Baghdad through Jordanian air space with 104 passengers on board, including 14 crew members.  Saudi Airways said Saturday that 40 British, 1
Annotation at test time--202 milliseconds elapsed to annotate the document 20001015_AFP_ARB.0229.eng
Final System Output:Correct Wikification of: London to : http://en.wikipedia.org/wiki/London
Candidates Entropy: 0.5776697689255758
Final System Output:Correct Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Candidates Entropy: 1.6503094417324222
Final System Output:Correct Wikification of: Baghdad to : http://en.wikipedia.org/wiki/Baghdad
Candidates Entropy: 0.5036933414274616
Final System Output:Correct Wikification of: Riyadh to : http://en.wikipedia.org/wiki/Riyadh
Candidates Entropy: 0.03140568946199697
Final System Output:Correct Wikification of: Riyadh International Airport to : http://en.wikipedia.org/wiki/King_Khalid_International_Airport
Candidates Entropy: 0.0
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/20001015_AFP_ARB.0229.eng.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/APW20001001.2021.0521
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =547
		- Total unique tokens  =275
		- Total unique tokens ignore case =269
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =9
		- OOV tokens, no repetitions, Case Sensitive =4
		- Total OOV tokens even after lowercasing  =9
		- OOV tokens even after lowercasing, no repetition  =4
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =18
		- OOV tokens, no repetitions, Case Sensitive =11
		- Total OOV tokens even after lowercasing  =18
		- OOV tokens even after lowercasing, no repetition  =11
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =1
		- OOV tokens, no repetitions, Case Sensitive =1
		- Total OOV tokens even after lowercasing  =1
		- OOV tokens even after lowercasing, no repetition  =1
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 518 milliseconds
Constructing a problem for the following text: 
  CAIRO, Egypt (AP) _ In his foreign policy debut as Syria's president, Bashar Assad met Sunday with Egyptian President Hosni Mubarak in talks on Mideast peace and the escalating violence in the Pa...
Annotating mention view..
1 milliseconds elapsed on constructing the TF-IDF representation of the input text...APW20001001.2021.0521
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Adding NER candidates for APW20001001.2021.0521
Adding SHALLOW_PARSE and subChunk candidates for APW20001001.2021.0521
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Matched regex entity CAIRO, Egypt[2-14]{0-3}
Matched regex entity Sunday with Egyptian President Hosni Mubarak[89-133]{20-26}
Matched regex entity Mubarak, Egyptian Foreign Minister Amr Mussa[340-384]{64-71}
Matched regex entity West Bank, Gaza Strip and Jerusalem[474-509]{90-97}
Matched regex entity Gaza Strip and Jerusalem[485-509]{93-97}
Matched regex entity Mubarak and Assad[599-616]{113-116}
Matched regex entity January, with Syria[1918-1937]{355-359}
Matched regex entity Mubarak and Assad[2242-2259]{415-418}
Matched regex entity France, Jordan and Yemen[2290-2314]{425-430}
Matched regex entity Jordan and Yemen[2298-2314]{427-430}
Matched regex entity Syria and Egypt[2646-2661]{489-492}
Matched regex entity Egypt and Syria[2705-2720]{500-503}
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Done constructing the Wikifiable entities
     ----  almost there....
514 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...APW20001001.2021.0521
Inference on the document  -- APW20001001.2021.0521
4 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
7 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
166 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
14 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
391 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
7 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: CAIRO to : http://en.wikipedia.org/wiki/Cairo
Level:FeatureExtractorCoherenceCorrect Wikification of: Egypt to : http://en.wikipedia.org/wiki/Egypt
Level:FeatureExtractorCoherenceCorrect Wikification of: AP to : http://en.wikipedia.org/wiki/Associated_Press
Level:FeatureExtractorCoherenceCorrect Wikification of: Syria to : http://en.wikipedia.org/wiki/Syria
Level:FeatureExtractorCoherenceCorrect Wikification of: President to : http://en.wikipedia.org/wiki/President_of_Egypt
Level:FeatureExtractorCoherenceCorrect Wikification of: Iraq to : http://en.wikipedia.org/wiki/Iraq
Level:FeatureExtractorCoherenceCorrect Wikification of: West Bank to : http://en.wikipedia.org/wiki/West_Bank
Level:FeatureExtractorCoherenceCorrect Wikification of: Gaza Strip to : http://en.wikipedia.org/wiki/Gaza_Strip
Level:FeatureExtractorCoherenceCorrect Wikification of: Jerusalem to : http://en.wikipedia.org/wiki/Jerusalem
Level:FeatureExtractorCoherenceCorrect Wikification of: CAIRO to : http://en.wikipedia.org/wiki/Cairo
Level:FeatureExtractorCoherenceCorrect Wikification of: Egypt to : http://en.wikipedia.org/wiki/Egypt
Level:FeatureExtractorCoherence: this introduces a Wikification error(!!!): AP; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Associated_Press;
  The confusions set is : AP(ranker score=1.5971941141321258) Vs: Associated_Press(ranker score=2.487535417028689);
  The context is: ; ------- ;   CAIRO, Egypt (AP) _ In his foreign policy debut as Syria's president, Bashar Assad met Sunday with Egyptian President Hosni Mubarak in talks on Mideast peace and the escalating violence in the Palestinian territori
Level:FeatureExtractorCoherenceCorrect Wikification of: Syria to : http://en.wikipedia.org/wiki/Syria
Level:FeatureExtractorCoherenceCorrect Wikification of: President to : http://en.wikipedia.org/wiki/President_of_Egypt
Level:FeatureExtractorCoherenceCorrect Wikification of: Iraq to : http://en.wikipedia.org/wiki/Iraq
Level:FeatureExtractorCoherenceCorrect Wikification of: West Bank to : http://en.wikipedia.org/wiki/West_Bank
Level:FeatureExtractorCoherenceCorrect Wikification of: Gaza Strip to : http://en.wikipedia.org/wiki/Gaza_Strip
Level:FeatureExtractorCoherenceCorrect Wikification of: Jerusalem to : http://en.wikipedia.org/wiki/Jerusalem
Could not find WikiMatchData for title Seriousness
Could not find WikiMatchData for title Repercussions
Could not find WikiMatchData for title List_of_Brothers_&_Sisters_episodes
Could not find WikiMatchData for title Follow
Could not find WikiMatchData for title Follow
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=President_of_Egypt, pred=title, arg2=Hosni_Mubarak, score=14.625517845153809, normalizedScore=100.0]For surfaces Egyptian President and Hosni Mubarak
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Prime_Minister_of_Israel, pred=shortDescription, arg2=Ehud_Barak, score=26.659513092041017, normalizedScore=100.0]For surfaces Israeli Prime Minister and Ehud Barak
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=France, pred=WIKI_LINK_RELATION, arg2=Jordan, score=3.5475627422332763, normalizedScore=100.0]For surfaces France and Jordan
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Bashar Assad[72-84]{17-19} === Syria 's president
2 too ambiguous for Assad[2254-2259]{417-418}, not adding cross cluster candidates.
2 too ambiguous for Assad[222-227]{40-41}, not adding cross cluster candidates.
2 too ambiguous for Assad[2142-2147]{396-397}, not adding cross cluster candidates.
2 too ambiguous for Assad[611-616]{115-116}, not adding cross cluster candidates.
2 too ambiguous for Assad[799-804]{150-151}, not adding cross cluster candidates.
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Hosni_Mubarak due to a longer mention than Mubarak that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Hosni_Mubarak due to a longer mention than Mubarak that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Hosni_Mubarak due to a longer mention than Mubarak that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bashar_al-Assad due to a longer mention than Bashar that referred to the same thing
Relational inference took 26ms
CoherenceRelation 72 [arg1=[surface=Bashar, solution=Bashar_al-Assad], arg2=[surface=Bashar Assad, solution=Bashar_al-Assad], weight=10.0] is captured by ILP inference.
CoherenceRelation 375 [arg1=[surface=Amr, solution=Amr_Moussa], arg2=[surface=Amr Mussa, solution=Amr_Moussa], weight=10.0] is captured by ILP inference.
CoherenceRelation 72 [arg1=[surface=Assad, solution=Bashar_al-Assad], arg2=[surface=Bashar Assad, solution=Bashar_al-Assad], weight=10.0] is captured by ILP inference.
CoherenceRelation 2515 [arg1=[surface=Moussa, solution=*null*], arg2=[surface=Moussa, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 1798 [arg1=[surface=Barak, solution=Ehud_Barak], arg2=[surface=Ehud Barak, solution=Ehud_Barak], weight=10.0] is captured by ILP inference.
CoherenceRelation 2777 [arg1=[surface=Hafez, solution=Hafez_al-Assad], arg2=[surface=Hafez Assad, solution=Hafez_al-Assad], weight=10.0] is captured by ILP inference.
CoherenceRelation 72 [arg1=[surface=Bashar, solution=Bashar_al-Assad], arg2=[surface=Bashar Assad, solution=Bashar_al-Assad], weight=10.0] is captured by ILP inference.
CoherenceRelation 1063 [arg1=[surface=Assad, solution=Bashar_al-Assad], arg2=[surface=Bashar Assad, solution=Bashar_al-Assad], weight=10.0] is captured by ILP inference.
CoherenceRelation 2515 [arg1=[surface=Moussa, solution=*null*], arg2=[surface=Moussa, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 2777 [arg1=[surface=Assad, solution=Hafez_al-Assad], arg2=[surface=Hafez Assad, solution=Hafez_al-Assad], weight=10.0] is captured by ILP inference.
CoherenceRelation 2777 [arg1=[surface=Hafez Assad, solution=Hafez_al-Assad], arg2=[surface=Hafez Assad, solution=Hafez_al-Assad], weight=10.0] is captured by ILP inference.
CoherenceRelation 1063 [arg1=[surface=Bashar, solution=Bashar_al-Assad], arg2=[surface=Bashar Assad, solution=Bashar_al-Assad], weight=10.0] is captured by ILP inference.
CoherenceRelation 375 [arg1=[surface=Mussa, solution=Amr_Moussa], arg2=[surface=Amr Mussa, solution=Amr_Moussa], weight=10.0] is captured by ILP inference.
CoherenceRelation 1259 [arg1=[surface=Arab, solution=Arab_people], arg2=[surface=Arab, solution=Arab_people], weight=10.0] is captured by ILP inference.
CoherenceRelation 1798 [arg1=[surface=Israeli Prime Minister, solution=Prime_Minister_of_Israel], arg2=[surface=Ehud Barak, solution=Ehud_Barak], weight=100.0] is captured by ILP inference.
CoherenceRelation 859 [arg1=[surface=Hafez, solution=Hafez_al-Assad], arg2=[surface=Hafez Assad, solution=Hafez_al-Assad], weight=10.0] is captured by ILP inference.
CoherenceRelation 1259 [arg1=[surface=Arab, solution=Arab_people], arg2=[surface=Arab, solution=Arab_people], weight=10.0] is captured by ILP inference.
CoherenceRelation 2 [arg1=[surface=CAIRO, solution=Cairo], arg2=[surface=CAIRO, Egypt, solution=Cairo], weight=10.0] is captured by ILP inference.
CoherenceRelation 110 [arg1=[surface=Hosni Mubarak, solution=Hosni_Mubarak], arg2=[surface=President Hosni Mubarak, solution=Hosni_Mubarak], weight=10.0] is captured by ILP inference.
CoherenceRelation 120 [arg1=[surface=Egyptian President, solution=President_of_Egypt], arg2=[surface=Hosni Mubarak, solution=Hosni_Mubarak], weight=100.0] is captured by ILP inference.
CoherenceRelation 120 [arg1=[surface=Mubarak, solution=Hosni_Mubarak], arg2=[surface=Hosni Mubarak, solution=Hosni_Mubarak], weight=10.0] is captured by ILP inference.
CoherenceRelation 859 [arg1=[surface=Assad, solution=Hafez_al-Assad], arg2=[surface=Hafez Assad, solution=Hafez_al-Assad], weight=10.0] is captured by ILP inference.
CoherenceRelation 72 [arg1=[surface=Bashar Assad, solution=Bashar_al-Assad], arg2=[surface=Bashar Assad, solution=Bashar_al-Assad], weight=10.0] is captured by ILP inference.
CoherenceRelation 2298 [arg1=[surface=France, solution=France], arg2=[surface=Jordan, solution=Jordan], weight=50.0] is captured by ILP inference.
CoherenceRelation 120 [arg1=[surface=Hosni, solution=Hosni_Mubarak], arg2=[surface=Hosni Mubarak, solution=Hosni_Mubarak], weight=10.0] is captured by ILP inference.
CoherenceRelation 120 [arg1=[surface=Mubarak, solution=Hosni_Mubarak], arg2=[surface=Hosni Mubarak, solution=Hosni_Mubarak], weight=10.0] is captured by ILP inference.
CoherenceRelation 120 [arg1=[surface=Mubarak, solution=Hosni_Mubarak], arg2=[surface=Hosni Mubarak, solution=Hosni_Mubarak], weight=10.0] is captured by ILP inference.
CoherenceRelation 120 [arg1=[surface=Mubarak, solution=Hosni_Mubarak], arg2=[surface=Hosni Mubarak, solution=Hosni_Mubarak], weight=10.0] is captured by ILP inference.
CoherenceRelation 1798 [arg1=[surface=Ehud, solution=Ehud_Barak], arg2=[surface=Ehud Barak, solution=Ehud_Barak], weight=10.0] is captured by ILP inference.
Discarded 43 hypothesis
Level: Relational Coherence Correct Wikification of: CAIRO to : http://en.wikipedia.org/wiki/Cairo
Level: Relational Coherence Correct Wikification of: Egypt to : http://en.wikipedia.org/wiki/Egypt
Level: Relational Coherence : Still Incorrect Wikification of: AP; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Associated_Press;
  The confusions set is : AP(ranker score=0.137337032632597) Vs: Associated_Press(ranker score=0.33454764298026907);
  The context is: ; ------- ;   CAIRO, Egypt (AP) _ In his foreign policy debut as Syria's president, Bashar Assad met Sunday with Egyptian President Hosni Mubarak in talks on Mideast peace and the escalating violence in the Palestinian territori
Level: Relational Coherence Correct Wikification of: Syria to : http://en.wikipedia.org/wiki/Syria
Level: Relational Coherence Correct Wikification of: President to : http://en.wikipedia.org/wiki/President_of_Egypt
Level: Relational Coherence Correct Wikification of: Iraq to : http://en.wikipedia.org/wiki/Iraq
Level: Relational Coherence Correct Wikification of: West Bank to : http://en.wikipedia.org/wiki/West_Bank
Level: Relational Coherence Correct Wikification of: Gaza Strip to : http://en.wikipedia.org/wiki/Gaza_Strip
Level: Relational Coherence Correct Wikification of: Jerusalem to : http://en.wikipedia.org/wiki/Jerusalem
Annotation at test time--908 milliseconds elapsed to annotate the document APW20001001.2021.0521
Final System Output:Correct Wikification of: CAIRO to : http://en.wikipedia.org/wiki/Cairo
Candidates Entropy: 0.03221945972731049
Final System Output:Correct Wikification of: Egypt to : http://en.wikipedia.org/wiki/Egypt
Candidates Entropy: 0.008386941748146174
Final System Output:: Still Incorrect Wikification of: AP; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Associated_Press;
  The confusions set is : AP(ranker score=0.137337032632597) Vs: Associated_Press(ranker score=0.33454764298026907);
  The context is: ; ------- ;   CAIRO, Egypt (AP) _ In his foreign policy debut as Syria's president, Bashar Assad met Sunday with Egyptian President Hosni Mubarak in talks on Mideast peace and the escalating violence in the Palestinian territori
Candidates Entropy: 2.4927403329897766
Final System Output:Correct Wikification of: Syria to : http://en.wikipedia.org/wiki/Syria
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: President to : http://en.wikipedia.org/wiki/President_of_Egypt
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Iraq to : http://en.wikipedia.org/wiki/Iraq
Candidates Entropy: 0.23636206826642944
Final System Output:Correct Wikification of: West Bank to : http://en.wikipedia.org/wiki/West_Bank
Candidates Entropy: 0.008035265021652778
Final System Output:Correct Wikification of: Gaza Strip to : http://en.wikipedia.org/wiki/Gaza_Strip
Candidates Entropy: 0.09951944482521541
Final System Output:Correct Wikification of: Jerusalem to : http://en.wikipedia.org/wiki/Jerusalem
Candidates Entropy: 0.19745044769915585
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/APW20001001.2021.0521.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/APW20001017.1313.0396
Empty problem - no reference instances!!!
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/APW20001102.1223.0376
Empty problem - no reference instances!!!
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/APW20001016.1325.0321
Empty problem - no reference instances!!!
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/VOA20001223.2000.0139
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =72
		- Total unique tokens  =52
		- Total unique tokens ignore case =51
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =2
		- OOV tokens, no repetitions, Case Sensitive =2
		- Total OOV tokens even after lowercasing  =2
		- OOV tokens even after lowercasing, no repetition  =2
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =5
		- OOV tokens, no repetitions, Case Sensitive =5
		- Total OOV tokens even after lowercasing  =4
		- OOV tokens even after lowercasing, no repetition  =4
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =3
		- OOV tokens, no repetitions, Case Sensitive =3
		- Total OOV tokens even after lowercasing  =3
		- OOV tokens even after lowercasing, no repetition  =3
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 56 milliseconds
Constructing a problem for the following text: 
 Reformist allies of Yugoslav President Vojislav Kostunica have scored a decisive victory in today's Serbian parliamentary elections. The Democratic opposition of Serbia, which supports the Preside...
0 milliseconds elapsed on constructing the TF-IDF representation of the input text...VOA20001223.2000.0139
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Adding NER candidates for VOA20001223.2000.0139
Adding SHALLOW_PARSE and subChunk candidates for VOA20001223.2000.0139
Annotating mention view..
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Matched regex entity Yugoslav President Slobodan Milosevic in October[306-354]{51-57}
Matched regex entity Milosevic's Socialist Party[360-387]{59-63}
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Done constructing the Wikifiable entities
     ----  almost there....
89 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...VOA20001223.2000.0139
Inference on the document  -- VOA20001223.2000.0139
1 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
2 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
21 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
3 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
11 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
1 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: Democratic opposition to : http://en.wikipedia.org/wiki/Democratic_Opposition_of_Serbia
Level:FeatureExtractorCoherenceCorrect Wikification of: Democratic opposition to : http://en.wikipedia.org/wiki/Democratic_Opposition_of_Serbia
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Slobodan Milosevic; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Slobodan_Milošević ; the gold is: http://en.wikipedia.org/wiki/*null*;
  The surface form has a single disambiguation candidate : Slobodan_Milošević(ranker score=10.624398677660471) ;
  The context is: ; ------- ; ections. The Democratic opposition of Serbia, which supports the President, estimates it has won 65% of the vote. The coalition took power after a popular uprising ousted long time Yugoslav President Slobodan Milosevic in October. Mr. Milosevic's Socialist Party and its allies won about 1/5th of the vote.  
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Socialist Party; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Socialist_Party_of_Serbia;
  The confusions set is : Socialist_Party_of_America(ranker score=2.595681504215533) Vs: Socialist_Party_(France)(ranker score=2.7756052982427892);
  The context is: ; ------- ; hich supports the President, estimates it has won 65% of the vote. The coalition took power after a popular uprising ousted long time Yugoslav President Slobodan Milosevic in October. Mr. Milosevic's Socialist Party and its allies won about 1/5th of the vote.  
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=List_of_heads_of_state_of_Yugoslavia, pred=WIKI_LINK_RELATION, arg2=Slobodan_Milošević, score=6.332220840454101, normalizedScore=100.0]For surfaces Yugoslav President and Slobodan Milosevic
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Slobodan_Milošević due to a longer mention than Milosevic that referred to the same thing
Relational inference took 3ms
CoherenceRelation 325 [arg1=[surface=Yugoslav President, solution=List_of_heads_of_state_of_Yugoslavia], arg2=[surface=Slobodan Milosevic, solution=Slobodan_Milošević], weight=100.0] is captured by ILP inference.
CoherenceRelation 40 [arg1=[surface=Kostunica, solution=Vojislav_Koštunica], arg2=[surface=Vojislav Kostunica, solution=Vojislav_Koštunica], weight=10.0] is captured by ILP inference.
CoherenceRelation 325 [arg1=[surface=Milosevic, solution=Slobodan_Milošević], arg2=[surface=Slobodan Milosevic, solution=Slobodan_Milošević], weight=10.0] is captured by ILP inference.
CoherenceRelation 325 [arg1=[surface=Slobodan, solution=Slobodan_Milošević], arg2=[surface=Slobodan Milosevic, solution=Slobodan_Milošević], weight=10.0] is captured by ILP inference.
CoherenceRelation 40 [arg1=[surface=Vojislav, solution=Vojislav_Koštunica], arg2=[surface=Vojislav Kostunica, solution=Vojislav_Koštunica], weight=10.0] is captured by ILP inference.
CoherenceRelation 325 [arg1=[surface=Milosevic, solution=Slobodan_Milošević], arg2=[surface=Slobodan Milosevic, solution=Slobodan_Milošević], weight=10.0] is captured by ILP inference.
Discarded 0 hypothesis
Level: Relational Coherence Correct Wikification of: Democratic opposition to : http://en.wikipedia.org/wiki/Democratic_Opposition_of_Serbia
Level: Relational Coherence : Still Incorrect Wikification of: Slobodan Milosevic; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Slobodan_Milošević ; the gold is: http://en.wikipedia.org/wiki/*null*;
  The surface form has a single disambiguation candidate : Slobodan_Milošević(ranker score=1.0) ;
  The context is: ; ------- ; ections. The Democratic opposition of Serbia, which supports the President, estimates it has won 65% of the vote. The coalition took power after a popular uprising ousted long time Yugoslav President Slobodan Milosevic in October. Mr. Milosevic's Socialist Party and its allies won about 1/5th of the vote.  
Level: Relational Coherence : Still Incorrect Wikification of: Socialist Party; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Socialist_Party_of_Serbia;
  The confusions set is : Socialist_Party_of_America(ranker score=0.25153738433383405) Vs: Socialist_Party_(France)(ranker score=0.3011219758312448);
  The context is: ; ------- ; hich supports the President, estimates it has won 65% of the vote. The coalition took power after a popular uprising ousted long time Yugoslav President Slobodan Milosevic in October. Mr. Milosevic's Socialist Party and its allies won about 1/5th of the vote.  
Annotation at test time--197 milliseconds elapsed to annotate the document VOA20001223.2000.0139
Final System Output:Correct Wikification of: Democratic opposition to : http://en.wikipedia.org/wiki/Democratic_Opposition_of_Serbia
Candidates Entropy: 0.0
Final System Output:: Still Incorrect Wikification of: NIL [NER, PER]Entity:Slobodan Milosevic; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Slobodan_Milošević ; the gold is: http://en.wikipedia.org/wiki/*null*;
  The surface form has a single disambiguation candidate : Slobodan_Milošević(ranker score=1.0) ;
  The context is: ; ------- ; ections. The Democratic opposition of Serbia, which supports the President, estimates it has won 65% of the vote. The coalition took power after a popular uprising ousted long time Yugoslav President Slobodan Milosevic in October. Mr. Milosevic's Socialist Party and its allies won about 1/5th of the vote.  
Candidates Entropy: 0.0
Final System Output:: Still Incorrect Wikification of: Socialist Party; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Socialist_Party_of_Serbia;
  The confusions set is : Socialist_Party_of_America(ranker score=0.25153738433383405) Vs: Socialist_Party_(France)(ranker score=0.3011219758312448);
  The context is: ; ------- ; hich supports the President, estimates it has won 65% of the vote. The coalition took power after a popular uprising ousted long time Yugoslav President Slobodan Milosevic in October. Mr. Milosevic's Socialist Party and its allies won about 1/5th of the vote.  
Candidates Entropy: 2.2403048670292476
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/VOA20001223.2000.0139.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/20001115_AFP_ARB.0089.eng
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =361
		- Total unique tokens  =196
		- Total unique tokens ignore case =190
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =18
		- OOV tokens, no repetitions, Case Sensitive =4
		- Total OOV tokens even after lowercasing  =18
		- OOV tokens even after lowercasing, no repetition  =4
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =34
		- OOV tokens, no repetitions, Case Sensitive =15
		- Total OOV tokens even after lowercasing  =31
		- OOV tokens even after lowercasing, no repetition  =14
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =9
		- OOV tokens, no repetitions, Case Sensitive =6
		- Total OOV tokens even after lowercasing  =7
		- OOV tokens even after lowercasing, no repetition  =5
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 391 milliseconds
Constructing a problem for the following text: 
  Albus (Lebanon) 11-15 (AFP) -  Thousands of Palestinian refugees in Lebanon commemorated in their camps today Wednesday the twelfth anniversary of the symbolic announcement of independence by the...
Annotating mention view..
1 milliseconds elapsed on constructing the TF-IDF representation of the input text...20001115_AFP_ARB.0089.eng
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Adding NER candidates for 20001115_AFP_ARB.0089.eng
Adding SHALLOW_PARSE and subChunk candidates for 20001115_AFP_ARB.0089.eng
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Matched regex entity Thousands of Palestinian[33-57]{9-12}
Matched regex entity Palestinian National Council in Algeria[198-237]{32-37}
Matched regex entity Israeli and American[911-931]{149-152}
Matched regex entity Israeli and American[1562-1582]{264-267}
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Done constructing the Wikifiable entities
     ----  almost there....
283 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...20001115_AFP_ARB.0089.eng
Inference on the document  -- 20001115_AFP_ARB.0089.eng
2 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
4 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
75 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
8 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
162 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
6 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: Lebanon to : http://en.wikipedia.org/wiki/Lebanon
Level:FeatureExtractorCoherenceCorrect Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level:FeatureExtractorCoherenceCorrect Wikification of: Palestinian National Council to : http://en.wikipedia.org/wiki/Palestinian_National_Council
Level:FeatureExtractorCoherenceCorrect Wikification of: Algeria to : http://en.wikipedia.org/wiki/Algeria
Level:FeatureExtractorCoherenceCorrect Wikification of: Albus Camp to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Beirut to : http://en.wikipedia.org/wiki/Beirut
Level:FeatureExtractorCoherenceCorrect Wikification of: Saida to : http://en.wikipedia.org/wiki/Sidon
Level:FeatureExtractorCoherenceCorrect Wikification of: Lebanon to : http://en.wikipedia.org/wiki/Lebanon
Level:FeatureExtractorCoherenceCorrect Wikification of: Khalid Arif to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Jerusalem to : http://en.wikipedia.org/wiki/Jerusalem
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Albus; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Geomantic_figures ; the gold is: http://en.wikipedia.org/wiki/*null*;
  The surface form has a single disambiguation candidate : Geomantic_figures(ranker score=2.530622463512363) ;
  The context is: ; ------- ;   Albus (Lebanon) 11-15 (AFP) -  Thousands of Palestinian refugees in Lebanon commemorated in their camps today Wednesday the twelfth anniversary of the symbolic announcement of independence by the Pale
Level:FeatureExtractorCoherenceCorrect Wikification of: Lebanon to : http://en.wikipedia.org/wiki/Lebanon
Level:FeatureExtractorCoherenceCorrect Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level:FeatureExtractorCoherenceCorrect Wikification of: Palestinian National Council to : http://en.wikipedia.org/wiki/Palestinian_National_Council
Level:FeatureExtractorCoherenceCorrect Wikification of: Algeria to : http://en.wikipedia.org/wiki/Algeria
Level:FeatureExtractorCoherenceCorrect Wikification of: Albus Camp to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Souer; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Tyre,_Lebanon;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; day Wednesday the twelfth anniversary of the symbolic announcement of independence by the Palestinian National Council in Algeria in 1988.   Around five thousand Palestinians form the Albus Camp near Souer (83 km south of Beirut) gathered and followed a march by children dressed in military clothing who held stones and raised pictures of Mohamed al-Dura, the 12-year-old Palestinian child killed by
Level:FeatureExtractorCoherenceCorrect Wikification of: Beirut to : http://en.wikipedia.org/wiki/Beirut
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Mohamed al-Dura; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Muhammad_al-Durrah_incident;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ;  Around five thousand Palestinians form the Albus Camp near Souer (83 km south of Beirut) gathered and followed a march by children dressed in military clothing who held stones and raised pictures of Mohamed al-Dura, the 12-year-old Palestinian child killed by Israeli army bullets in the Palestinian Territories in early October.   A France Presse correspondent reported that around 200 Palestinians
Level:FeatureExtractorCoherenceCorrect Wikification of: Saida to : http://en.wikipedia.org/wiki/Sidon
Level:FeatureExtractorCoherenceCorrect Wikification of: Lebanon to : http://en.wikipedia.org/wiki/Lebanon
Level:FeatureExtractorCoherenceCorrect Wikification of: Khalid Arif to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Jerusalem to : http://en.wikipedia.org/wiki/Jerusalem
Could not find WikiMatchData for title Muhammad_al-Durrah_incident
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=President_of_the_Palestinian_National_Authority, pred=WIKI_LINK_RELATION, arg2=Yasser_Arafat, score=8.702546310424804, normalizedScore=100.0]For surfaces Palestinian President and Yasser Arafat
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=President_of_the_Palestinian_National_Authority, pred=WIKI_LINK_RELATION, arg2=Yasser_Arafat, score=8.702546310424804, normalizedScore=100.0]For surfaces Palestinian President and Yasser Arafat
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Khalid Arif[966-977]{157-159} === am official with the Fatah movement in Saida
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Muhammad_al-Durrah_incident due to a longer mention than Mohamed that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Palestinian_territories due to a longer mention than Territories that referred to the same thing
Relational inference took 14ms
CoherenceRelation 829 [arg1=[surface=Arafat, solution=Yasser_Arafat], arg2=[surface=Yasser Arafat, solution=Yasser_Arafat], weight=10.0] is captured by ILP inference.
CoherenceRelation 292 [arg1=[surface=Albus, solution=*null*], arg2=[surface=Albus Camp, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 829 [arg1=[surface=Yasser, solution=Yasser_Arafat], arg2=[surface=Yasser Arafat, solution=Yasser_Arafat], weight=10.0] is captured by ILP inference.
CoherenceRelation 966 [arg1=[surface=Khalid, solution=*null*], arg2=[surface=Khalid Arif, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 448 [arg1=[surface=Mohamed, solution=Muhammad_al-Durrah_incident], arg2=[surface=Mohamed al-Dura, solution=Muhammad_al-Durrah_incident], weight=10.0] is captured by ILP inference.
CoherenceRelation 636 [arg1=[surface=Palestinians, solution=Palestinian_people], arg2=[surface=Palestinians, solution=Palestinian_people], weight=10.0] is captured by ILP inference.
CoherenceRelation 1216 [arg1=[surface=Territories, solution=Palestinian_territories], arg2=[surface=Palestinian Territories, solution=Palestinian_territories], weight=10.0] is captured by ILP inference.
CoherenceRelation 829 [arg1=[surface=Yasser Arafat, solution=Yasser_Arafat], arg2=[surface=Yasser Arafat, solution=Yasser_Arafat], weight=10.0] is captured by ILP inference.
CoherenceRelation 1933 [arg1=[surface=Palestinian President, solution=President_of_the_Palestinian_National_Authority], arg2=[surface=Yasser Arafat, solution=Yasser_Arafat], weight=100.0] is captured by ILP inference.
CoherenceRelation 2053 [arg1=[surface=Intifada, solution=Second_Intifada], arg2=[surface=Intifada, solution=Second_Intifada], weight=10.0] is captured by ILP inference.
CoherenceRelation 1933 [arg1=[surface=Arafat, solution=Yasser_Arafat], arg2=[surface=Yasser Arafat, solution=Yasser_Arafat], weight=10.0] is captured by ILP inference.
CoherenceRelation 636 [arg1=[surface=Palestinians, solution=Palestinian_people], arg2=[surface=Palestinians, solution=Palestinian_people], weight=10.0] is captured by ILP inference.
CoherenceRelation 448 [arg1=[surface=al-Dura, solution=Muhammad_al-Durrah_incident], arg2=[surface=Mohamed al-Dura, solution=Muhammad_al-Durrah_incident], weight=10.0] is captured by ILP inference.
CoherenceRelation 1933 [arg1=[surface=Yasser, solution=Yasser_Arafat], arg2=[surface=Yasser Arafat, solution=Yasser_Arafat], weight=10.0] is captured by ILP inference.
CoherenceRelation 829 [arg1=[surface=Palestinian President, solution=President_of_the_Palestinian_National_Authority], arg2=[surface=Yasser Arafat, solution=Yasser_Arafat], weight=100.0] is captured by ILP inference.
CoherenceRelation 2053 [arg1=[surface=Intifada, solution=Second_Intifada], arg2=[surface=Intifada, solution=Second_Intifada], weight=10.0] is captured by ILP inference.
CoherenceRelation 966 [arg1=[surface=Arif, solution=*null*], arg2=[surface=Khalid Arif, solution=*null*], weight=10.0] is captured by ILP inference.
Discarded 27 hypothesis
Level: Relational Coherence Correct Wikification of: Albus to : http://en.wikipedia.org/wiki/*null*
Level: Relational Coherence this fixes the Wikification (!!!)Albus; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/*null*;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ;   Albus (Lebanon) 11-15 (AFP) -  Thousands of Palestinian refugees in Lebanon commemorated in their camps today Wednesday the twelfth anniversary of the symbolic announcement of independence by the Pale
Level: Relational Coherence Correct Wikification of: Lebanon to : http://en.wikipedia.org/wiki/Lebanon
Level: Relational Coherence Correct Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level: Relational Coherence Correct Wikification of: Palestinian National Council to : http://en.wikipedia.org/wiki/Palestinian_National_Council
Level: Relational Coherence Correct Wikification of: Algeria to : http://en.wikipedia.org/wiki/Algeria
Level: Relational Coherence Correct Wikification of: Albus Camp to : http://en.wikipedia.org/wiki/*null*
Level: Relational Coherence : Still Incorrect Wikification of: Souer; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Tyre,_Lebanon;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; day Wednesday the twelfth anniversary of the symbolic announcement of independence by the Palestinian National Council in Algeria in 1988.   Around five thousand Palestinians form the Albus Camp near Souer (83 km south of Beirut) gathered and followed a march by children dressed in military clothing who held stones and raised pictures of Mohamed al-Dura, the 12-year-old Palestinian child killed by
Level: Relational Coherence Correct Wikification of: Beirut to : http://en.wikipedia.org/wiki/Beirut
Level: Relational Coherence Correct Wikification of: Mohamed al-Dura to : http://en.wikipedia.org/wiki/Muhammad_al-Durrah_incident
Level: Relational Coherence this fixes the Wikification (!!!)Mohamed al-Dura; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Muhammad_al-Durrah_incident ; the gold is: http://en.wikipedia.org/wiki/Muhammad_al-Durrah_incident;
  The surface form has a single disambiguation candidate : Muhammad_al-Durrah_incident(ranker score=0.5) ;
  The context is: ; ------- ;  Around five thousand Palestinians form the Albus Camp near Souer (83 km south of Beirut) gathered and followed a march by children dressed in military clothing who held stones and raised pictures of Mohamed al-Dura, the 12-year-old Palestinian child killed by Israeli army bullets in the Palestinian Territories in early October.   A France Presse correspondent reported that around 200 Palestinians
Level: Relational Coherence Correct Wikification of: Saida to : http://en.wikipedia.org/wiki/Sidon
Level: Relational Coherence Correct Wikification of: Lebanon to : http://en.wikipedia.org/wiki/Lebanon
Level: Relational Coherence Correct Wikification of: Khalid Arif to : http://en.wikipedia.org/wiki/*null*
Level: Relational Coherence Correct Wikification of: Jerusalem to : http://en.wikipedia.org/wiki/Jerusalem
Annotation at test time--490 milliseconds elapsed to annotate the document 20001115_AFP_ARB.0089.eng
Final System Output:Correct Wikification of: Albus to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Lebanon to : http://en.wikipedia.org/wiki/Lebanon
Candidates Entropy: 0.019892895340647313
Final System Output:Correct Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Candidates Entropy: 1.1543061789465752
Final System Output:Correct Wikification of: Palestinian National Council to : http://en.wikipedia.org/wiki/Palestinian_National_Council
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Algeria to : http://en.wikipedia.org/wiki/Algeria
Candidates Entropy: 0.2585104186910882
Final System Output:Correct Wikification of: Albus Camp to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Final System Output:: Still Incorrect Wikification of: Souer; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Tyre,_Lebanon;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; day Wednesday the twelfth anniversary of the symbolic announcement of independence by the Palestinian National Council in Algeria in 1988.   Around five thousand Palestinians form the Albus Camp near Souer (83 km south of Beirut) gathered and followed a march by children dressed in military clothing who held stones and raised pictures of Mohamed al-Dura, the 12-year-old Palestinian child killed by
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Beirut to : http://en.wikipedia.org/wiki/Beirut
Candidates Entropy: 0.08313687295361492
Final System Output:Correct Wikification of: Mohamed al-Dura to : http://en.wikipedia.org/wiki/Muhammad_al-Durrah_incident
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Saida to : http://en.wikipedia.org/wiki/Sidon
Candidates Entropy: 0.5731575744284888
Final System Output:Correct Wikification of: Lebanon to : http://en.wikipedia.org/wiki/Lebanon
Candidates Entropy: 0.021458191097050272
Final System Output:Correct Wikification of: Khalid Arif to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Jerusalem to : http://en.wikipedia.org/wiki/Jerusalem
Candidates Entropy: 0.0232879948159536
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/20001115_AFP_ARB.0089.eng.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/20001115_AFP_ARB.0093.eng
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =298
		- Total unique tokens  =153
		- Total unique tokens ignore case =148
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =16
		- OOV tokens, no repetitions, Case Sensitive =3
		- Total OOV tokens even after lowercasing  =16
		- OOV tokens even after lowercasing, no repetition  =3
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =25
		- OOV tokens, no repetitions, Case Sensitive =10
		- Total OOV tokens even after lowercasing  =24
		- OOV tokens even after lowercasing, no repetition  =9
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =5
		- OOV tokens, no repetitions, Case Sensitive =3
		- Total OOV tokens even after lowercasing  =4
		- OOV tokens even after lowercasing, no repetition  =2
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 410 milliseconds
Constructing a problem for the following text: 
  Bandar Seri Begawan 11-15 (AFP) -  The United States today Wednesday deemed the order issued by Palestinian President Yasser Arafat for a ceasefire in territories under Palestinian Authority cont...
Annotating mention view..
1 milliseconds elapsed on constructing the TF-IDF representation of the input text...20001115_AFP_ARB.0093.eng
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Adding NER candidates for 20001115_AFP_ARB.0093.eng
Adding SHALLOW_PARSE and subChunk candidates for 20001115_AFP_ARB.0093.eng
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Matched regex entity James Stewart, the White House's[335-367]{54-61}
Matched regex entity Stewart, the White House's[341-367]{55-61}
Matched regex entity Sultanate of Brunei[421-440]{71-74}
Matched regex entity Palestinian and Israeli[611-634]{103-106}
Matched regex entity Palestinian Authority in the West Bank and Gaza Strip[1707-1760]{288-297}
Matched regex entity West Bank and Gaza Strip[1736-1760]{292-297}
Matched regex entity Bank and Gaza Strip[1741-1760]{293-297}
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Important warning: the manually defined entity area "A had 0 disambiguation candidates
Done constructing the Wikifiable entities
     ----  almost there....
267 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...20001115_AFP_ARB.0093.eng
Inference on the document  -- 20001115_AFP_ARB.0093.eng
2 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
4 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
61 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
7 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
160 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
3 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: Bandar Seri Begawan to : http://en.wikipedia.org/wiki/Bandar_Seri_Begawan
Level:FeatureExtractorCoherenceCorrect Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level:FeatureExtractorCoherenceCorrect Wikification of: United States to : http://en.wikipedia.org/wiki/United_States
Level:FeatureExtractorCoherenceCorrect Wikification of: White House to : http://en.wikipedia.org/wiki/White_House
Level:FeatureExtractorCoherenceCorrect Wikification of: Bandar Seri Begawan to : http://en.wikipedia.org/wiki/Bandar_Seri_Begawan
Level:FeatureExtractorCoherenceCorrect Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level:FeatureExtractorCoherenceCorrect Wikification of: United States to : http://en.wikipedia.org/wiki/United_States
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: James Stewart; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/James_Stewart ; the gold is: http://en.wikipedia.org/wiki/*null*;
  The confusions set is : James_Stewart(ranker score=1.1722078327714813) Vs: James_Stewart(ranker score=4.237284147807598);
  The context is: ; ------- ; or a ceasefire in territories under Palestinian Authority control as a positive gesture but considered that it does not release constitute a release form the terms of the Sharm el-Sheikh agreement.   James Stewart, the White House's spokesman in Bandar Seri Begawan, the capital of the Sultanate of Brunei which American President Bill Clinton is visiting, said "of course we positively welcome the a
Level:FeatureExtractorCoherenceCorrect Wikification of: White House to : http://en.wikipedia.org/wiki/White_House
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Palestinian Superior Security Council; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Palestinian_National_Council;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ;  violence because we believe that it is extremely important for the sides to take immediate measures to end the tension and reduce the violence."   A high-level Palestinian source said today that the Palestinian Superior Security Council led by President Yasser Arafat issued orders to stop shooting inside area "A" under Palestinian control.   The source who wished to remain anonymous said that "th
Could not find WikiMatchData for title The_United
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=President_of_the_Palestinian_National_Authority, pred=WIKI_LINK_RELATION, arg2=Yasser_Arafat, score=8.702546310424804, normalizedScore=100.0]For surfaces Palestinian President and Yasser Arafat
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=President_of_the_United_States, pred=WIKI_LINK_RELATION, arg2=Bill_Clinton, score=7.646950435638427, normalizedScore=100.0]For surfaces American President and Bill Clinton
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Palestinian_territories, pred=WIKI_LINK_RELATION, arg2=Politics_of_Israel, score=2.2687740325927734, normalizedScore=0.15798952617965656]For surfaces Palestinian and Israeli officials
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Palestinian_refugee, pred=WIKI_LINK_RELATION, arg2=Politics_of_Israel, score=2.1225152015686035, normalizedScore=0.15343499233524674]For surfaces Palestinian and Israeli officials
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Palestinian_National_Authority, pred=WIKI_LINK_RELATION, arg2=Gaza_Strip, score=10.767663097381597, normalizedScore=100.0]For surfaces West Bank and Gaza and Strip
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:James Stewart[335-348]{54-56} === the White House 's spokesman in Bandar Seri Begawan
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - Force linking James Stewart[335-348]{54-56} to null
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bill_Clinton due to a longer mention than Clinton that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bill_Clinton due to a longer mention than Clinton that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bill_Clinton due to a longer mention than Clinton that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Asia-Pacific_Economic_Cooperation due to a longer mention than APEC that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Yasser_Arafat due to a longer mention than Arafat that referred to the same thing
Relational inference took 6ms
CoherenceRelation 120 [arg1=[surface=Arafat, solution=Yasser_Arafat], arg2=[surface=Yasser Arafat, solution=Yasser_Arafat], weight=10.0] is captured by ILP inference.
CoherenceRelation 1457 [arg1=[surface=Yasser, solution=Yasser_Arafat], arg2=[surface=Yasser Arafat, solution=Yasser_Arafat], weight=10.0] is captured by ILP inference.
CoherenceRelation 1255 [arg1=[surface=Yasser, solution=Yasser_Arafat], arg2=[surface=Yasser Arafat, solution=Yasser_Arafat], weight=10.0] is captured by ILP inference.
CoherenceRelation 748 [arg1=[surface=APEC, solution=Asia-Pacific_Economic_Cooperation], arg2=[surface=Asia-Pacific Economic Cooperation, solution=Asia-Pacific_Economic_Cooperation], weight=10.0] is captured by ILP inference.
CoherenceRelation 335 [arg1=[surface=James, solution=*null*], arg2=[surface=James Stewart, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 171 [arg1=[surface=Palestinian Authority, solution=Palestinian_National_Authority], arg2=[surface=Palestinian Authority, solution=Palestinian_National_Authority], weight=10.0] is captured by ILP inference.
CoherenceRelation 120 [arg1=[surface=Yasser Arafat, solution=Yasser_Arafat], arg2=[surface=Yasser Arafat, solution=Yasser_Arafat], weight=10.0] is captured by ILP inference.
CoherenceRelation 836 [arg1=[surface=Bill Clinton, solution=Bill_Clinton], arg2=[surface=President Bill Clinton, solution=Bill_Clinton], weight=10.0] is captured by ILP inference.
CoherenceRelation 421 [arg1=[surface=Sultanate, solution=Brunei], arg2=[surface=Sultanate of Brunei, solution=Brunei], weight=10.0] is captured by ILP inference.
CoherenceRelation 456 [arg1=[surface=Bill Clinton, solution=Bill_Clinton], arg2=[surface=President Bill Clinton, solution=Bill_Clinton], weight=10.0] is captured by ILP inference.
CoherenceRelation 836 [arg1=[surface=Bill Clinton, solution=Bill_Clinton], arg2=[surface=President Bill Clinton, solution=Bill_Clinton], weight=10.0] is captured by ILP inference.
CoherenceRelation 836 [arg1=[surface=Clinton, solution=Bill_Clinton], arg2=[surface=President Bill Clinton, solution=Bill_Clinton], weight=10.0] is captured by ILP inference.
CoherenceRelation 836 [arg1=[surface=Clinton, solution=Bill_Clinton], arg2=[surface=President Bill Clinton, solution=Bill_Clinton], weight=10.0] is captured by ILP inference.
CoherenceRelation 466 [arg1=[surface=Clinton, solution=Bill_Clinton], arg2=[surface=Bill Clinton, solution=Bill_Clinton], weight=10.0] is captured by ILP inference.
CoherenceRelation 120 [arg1=[surface=Arafat, solution=Yasser_Arafat], arg2=[surface=Yasser Arafat, solution=Yasser_Arafat], weight=10.0] is captured by ILP inference.
CoherenceRelation 1402 [arg1=[surface=Palestinian Superior Security Council, solution=*null*], arg2=[surface=Palestinian Superior Security Council, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 1457 [arg1=[surface=Arafat, solution=Yasser_Arafat], arg2=[surface=Yasser Arafat, solution=Yasser_Arafat], weight=10.0] is captured by ILP inference.
CoherenceRelation 836 [arg1=[surface=Clinton, solution=Bill_Clinton], arg2=[surface=President Bill Clinton, solution=Bill_Clinton], weight=10.0] is captured by ILP inference.
CoherenceRelation 37 [arg1=[surface=States, solution=United_States], arg2=[surface=The United States, solution=United_States], weight=10.0] is captured by ILP inference.
CoherenceRelation 120 [arg1=[surface=Yasser, solution=Yasser_Arafat], arg2=[surface=Yasser Arafat, solution=Yasser_Arafat], weight=10.0] is captured by ILP inference.
CoherenceRelation 1255 [arg1=[surface=Arafat, solution=Yasser_Arafat], arg2=[surface=Yasser Arafat, solution=Yasser_Arafat], weight=10.0] is captured by ILP inference.
CoherenceRelation 836 [arg1=[surface=President, solution=Bill_Clinton], arg2=[surface=President Bill Clinton, solution=Bill_Clinton], weight=10.0] is captured by ILP inference.
CoherenceRelation 335 [arg1=[surface=Stewart, solution=*null*], arg2=[surface=James Stewart, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 466 [arg1=[surface=American President, solution=President_of_the_United_States], arg2=[surface=Bill Clinton, solution=Bill_Clinton], weight=100.0] is captured by ILP inference.
CoherenceRelation 1755 [arg1=[surface=West Bank and Gaza, solution=Palestinian_National_Authority], arg2=[surface=Strip, solution=Gaza_Strip], weight=50.0] is captured by ILP inference.
CoherenceRelation 120 [arg1=[surface=Yasser Arafat, solution=Yasser_Arafat], arg2=[surface=Yasser Arafat, solution=Yasser_Arafat], weight=10.0] is captured by ILP inference.
CoherenceRelation 120 [arg1=[surface=Palestinian President, solution=President_of_the_Palestinian_National_Authority], arg2=[surface=Yasser Arafat, solution=Yasser_Arafat], weight=100.0] is captured by ILP inference.
Discarded 45 hypothesis
Level: Relational Coherence Correct Wikification of: Bandar Seri Begawan to : http://en.wikipedia.org/wiki/Bandar_Seri_Begawan
Level: Relational Coherence Correct Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level: Relational Coherence Correct Wikification of: United States to : http://en.wikipedia.org/wiki/United_States
Level: Relational Coherence Correct Wikification of: James Stewart to : http://en.wikipedia.org/wiki/*null*
Level: Relational Coherence this fixes the Wikification (!!!)James Stewart; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/*null*;
  The confusions set is : James_Stewart_(American_football)(ranker score=0.027897995417780656) Vs: James_Stewart(ranker score=0.7804317473962173);
  The context is: ; ------- ; or a ceasefire in territories under Palestinian Authority control as a positive gesture but considered that it does not release constitute a release form the terms of the Sharm el-Sheikh agreement.   James Stewart, the White House's spokesman in Bandar Seri Begawan, the capital of the Sultanate of Brunei which American President Bill Clinton is visiting, said "of course we positively welcome the a
Level: Relational Coherence Correct Wikification of: White House to : http://en.wikipedia.org/wiki/White_House
Level: Relational Coherence : Still Incorrect Wikification of: Palestinian Superior Security Council; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Palestinian_National_Council;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ;  violence because we believe that it is extremely important for the sides to take immediate measures to end the tension and reduce the violence."   A high-level Palestinian source said today that the Palestinian Superior Security Council led by President Yasser Arafat issued orders to stop shooting inside area "A" under Palestinian control.   The source who wished to remain anonymous said that "th
Annotation at test time--508 milliseconds elapsed to annotate the document 20001115_AFP_ARB.0093.eng
Final System Output:Correct Wikification of: Bandar Seri Begawan to : http://en.wikipedia.org/wiki/Bandar_Seri_Begawan
Candidates Entropy: 0.13995430708308323
Final System Output:Correct Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Candidates Entropy: 0.8716178075121828
Final System Output:Correct Wikification of: United States to : http://en.wikipedia.org/wiki/United_States
Candidates Entropy: 0.048204042604805875
Final System Output:Correct Wikification of: James Stewart to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 1.1530057140583112
Final System Output:Correct Wikification of: White House to : http://en.wikipedia.org/wiki/White_House
Candidates Entropy: 0.0
Final System Output:: Still Incorrect Wikification of: Palestinian Superior Security Council; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Palestinian_National_Council;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ;  violence because we believe that it is extremely important for the sides to take immediate measures to end the tension and reduce the violence."   A high-level Palestinian source said today that the Palestinian Superior Security Council led by President Yasser Arafat issued orders to stop shooting inside area "A" under Palestinian control.   The source who wished to remain anonymous said that "th
Candidates Entropy: 0.0
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/20001115_AFP_ARB.0093.eng.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/APW20001022.1735.0376
Empty problem - no reference instances!!!
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/20000715_AFP_ARB.0072.eng
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =447
		- Total unique tokens  =193
		- Total unique tokens ignore case =186
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =30
		- OOV tokens, no repetitions, Case Sensitive =6
		- Total OOV tokens even after lowercasing  =30
		- OOV tokens even after lowercasing, no repetition  =6
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =41
		- OOV tokens, no repetitions, Case Sensitive =10
		- Total OOV tokens even after lowercasing  =41
		- OOV tokens even after lowercasing, no repetition  =10
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =17
		- OOV tokens, no repetitions, Case Sensitive =7
		- Total OOV tokens even after lowercasing  =17
		- OOV tokens even after lowercasing, no repetition  =7
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 442 milliseconds
Constructing a problem for the following text: 
  Jerusalem 7-15 (AFP) -  A high level Israeli army official has said today Saturday that Israel believes Iran is set to begin acquiring nuclear capability for military purposes from 2005 and will ...
Annotating mention view..
1 milliseconds elapsed on constructing the TF-IDF representation of the input text...20000715_AFP_ARB.0072.eng
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Adding NER candidates for 20000715_AFP_ARB.0072.eng
Adding SHALLOW_PARSE and subChunk candidates for 20000715_AFP_ARB.0072.eng
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Matched regex entity Palestinian and Lebanese[1481-1505]{262-265}
Matched regex entity Israel's Deputy Defense Minister, Ephraim Sneh[1715-1761]{302-310}
Matched regex entity Deputy Defense Minister, Ephraim Sneh[1724-1761]{304-310}
Matched regex entity Iranian Ministry of Defense[2204-2231]{392-396}
Matched regex entity Ministry of Defense[2212-2231]{393-396}
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Done constructing the Wikifiable entities
     ----  almost there....
213 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...20000715_AFP_ARB.0072.eng
Inference on the document  -- 20000715_AFP_ARB.0072.eng
3 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
5 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
80 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
7 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
216 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
3 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: Jerusalem to : http://en.wikipedia.org/wiki/Jerusalem
Level:FeatureExtractorCoherenceCorrect Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level:FeatureExtractorCoherenceCorrect Wikification of: Iran to : http://en.wikipedia.org/wiki/Iran
Level:FeatureExtractorCoherenceCorrect Wikification of: Moscow to : http://en.wikipedia.org/wiki/Moscow
Level:FeatureExtractorCoherenceCorrect Wikification of: Tehran Radio to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Jerusalem to : http://en.wikipedia.org/wiki/Jerusalem
Level:FeatureExtractorCoherenceCorrect Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level:FeatureExtractorCoherenceCorrect Wikification of: Iran to : http://en.wikipedia.org/wiki/Iran
Level:FeatureExtractorCoherenceCorrect Wikification of: Moscow to : http://en.wikipedia.org/wiki/Moscow
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Ministry of Defense; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Ministry_of_Defense_(Israel) ; the gold is: http://en.wikipedia.org/wiki/Ministry_of_Defense_and_Armed_Forces_Logistics_(Iran);
  The confusions set is : Ministry_of_Defense_(Japan)(ranker score=1.8732853100479478) Vs: Ministry_of_Defense_(Israel)(ranker score=3.4824637974679566);
  The context is: ; ------- ; reat," without giving any further details.   The Iranian army announced today Saturday that it had "successfully" completed a new test on Shahab 3 ground-ground missiles.   An official at the Iranian Ministry of Defense told Tehran Radio that the "Shahab 3 defense missile was tested a second time to ensure it conforms to international standards."   In July 1998, the first test on this missile was 
Level:FeatureExtractorCoherenceCorrect Wikification of: Tehran Radio to : http://en.wikipedia.org/wiki/*null*
Could not find WikiMatchData for title Army_Radio
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Palestinian_people, pred=WIKI_LINK_RELATION, arg2=Lebanon, score=2.9715212821960453, normalizedScore=100.0]For surfaces Palestinian and Lebanese
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Israel, pred=WIKI_LINK_RELATION, arg2=Deputy_leaders_of_Israel, score=1.961082100868225, normalizedScore=100.0]For surfaces Israel and Deputy
Could not find WikiMatchData for title Ministry_of_Defense_and_Armed_Forces_Logistics_(Iran)
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Iran, pred=jurisdiction, arg2=Ministry_of_Defense_and_Armed_Forces_Logistics, score=7.2626423835754395, normalizedScore=100.0]For surfaces Iranian and Ministry of Defense
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Ephraim Sneh[1749-1761]{308-310} === Israel 's Deputy Defense Minister
Relational inference took 8ms
CoherenceRelation 1724 [arg1=[surface=Israel, solution=Israel], arg2=[surface=Deputy, solution=Deputy_leaders_of_Israel], weight=100.0] is captured by ILP inference.
CoherenceRelation 1497 [arg1=[surface=Palestinian, solution=Palestinian_people], arg2=[surface=Lebanese, solution=Lebanon], weight=50.0] is captured by ILP inference.
CoherenceRelation 1173 [arg1=[surface=Shahab, solution=Shahab], arg2=[surface=Shahab, solution=Shahab], weight=10.0] is captured by ILP inference.
CoherenceRelation 1173 [arg1=[surface=Shahab, solution=Shahab], arg2=[surface=Shahab, solution=Shahab], weight=10.0] is captured by ILP inference.
CoherenceRelation 1173 [arg1=[surface=Shahab, solution=Shahab], arg2=[surface=Shahab, solution=Shahab], weight=10.0] is captured by ILP inference.
CoherenceRelation 1173 [arg1=[surface=Shahab, solution=Shahab], arg2=[surface=Shahab, solution=Shahab], weight=10.0] is captured by ILP inference.
CoherenceRelation 2212 [arg1=[surface=Ministry, solution=Ministry_of_Defense_and_Armed_Forces_Logistics_(Iran)], arg2=[surface=Ministry of Defense, solution=Ministry_of_Defense_and_Armed_Forces_Logistics_(Iran)], weight=10.0] is captured by ILP inference.
CoherenceRelation 1749 [arg1=[surface=Sneh, solution=Efraim_Sneh], arg2=[surface=Ephraim Sneh, solution=Efraim_Sneh], weight=10.0] is captured by ILP inference.
CoherenceRelation 1173 [arg1=[surface=Shahab, solution=Shahab], arg2=[surface=Shahab, solution=Shahab], weight=10.0] is captured by ILP inference.
CoherenceRelation 1749 [arg1=[surface=Ephraim, solution=Efraim_Sneh], arg2=[surface=Ephraim Sneh, solution=Efraim_Sneh], weight=10.0] is captured by ILP inference.
CoherenceRelation 2212 [arg1=[surface=Iranian, solution=Iran], arg2=[surface=Ministry of Defense, solution=Ministry_of_Defense_and_Armed_Forces_Logistics_(Iran)], weight=100.0] is captured by ILP inference.
CoherenceRelation 1749 [arg1=[surface=Sneh, solution=Efraim_Sneh], arg2=[surface=Ephraim Sneh, solution=Efraim_Sneh], weight=10.0] is captured by ILP inference.
CoherenceRelation 1173 [arg1=[surface=Shahab, solution=Shahab], arg2=[surface=Shahab, solution=Shahab], weight=10.0] is captured by ILP inference.
Discarded 20 hypothesis
Level: Relational Coherence Correct Wikification of: Jerusalem to : http://en.wikipedia.org/wiki/Jerusalem
Level: Relational Coherence Correct Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level: Relational Coherence Correct Wikification of: Iran to : http://en.wikipedia.org/wiki/Iran
Level: Relational Coherence Correct Wikification of: Moscow to : http://en.wikipedia.org/wiki/Moscow
Level: Relational Coherence Correct Wikification of: Ministry of Defense to : http://en.wikipedia.org/wiki/Ministry_of_Defense_and_Armed_Forces_Logistics_(Iran)
Level: Relational Coherence this fixes the Wikification (!!!)Ministry of Defense; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Ministry_of_Defense_and_Armed_Forces_Logistics_(Iran) ; the gold is: http://en.wikipedia.org/wiki/Ministry_of_Defense_and_Armed_Forces_Logistics_(Iran);
  The confusions set is : Ministry_of_Defense_(Japan)(ranker score=0.11370309121390522) Vs: Ministry_of_Defense_(Israel)(ranker score=0.5683679880685952);
  The context is: ; ------- ; reat," without giving any further details.   The Iranian army announced today Saturday that it had "successfully" completed a new test on Shahab 3 ground-ground missiles.   An official at the Iranian Ministry of Defense told Tehran Radio that the "Shahab 3 defense missile was tested a second time to ensure it conforms to international standards."   In July 1998, the first test on this missile was 
Level: Relational Coherence Correct Wikification of: Tehran Radio to : http://en.wikipedia.org/wiki/*null*
Annotation at test time--402 milliseconds elapsed to annotate the document 20000715_AFP_ARB.0072.eng
Final System Output:Correct Wikification of: Jerusalem to : http://en.wikipedia.org/wiki/Jerusalem
Candidates Entropy: 0.14570599805444323
Final System Output:Correct Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Candidates Entropy: 1.0116977550062602
Final System Output:Correct Wikification of: Iran to : http://en.wikipedia.org/wiki/Iran
Candidates Entropy: 0.06133412505831765
Final System Output:Correct Wikification of: Moscow to : http://en.wikipedia.org/wiki/Moscow
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Ministry of Defense to : http://en.wikipedia.org/wiki/Ministry_of_Defense_and_Armed_Forces_Logistics_(Iran)
Candidates Entropy: 1.8512712516023682
Final System Output:Correct Wikification of: Tehran Radio to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/20000715_AFP_ARB.0072.eng.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/chtb_171.eng
Empty problem - no reference instances!!!
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/20001115_AFP_ARB.0212.eng
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =191
		- Total unique tokens  =115
		- Total unique tokens ignore case =111
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =6
		- OOV tokens, no repetitions, Case Sensitive =3
		- Total OOV tokens even after lowercasing  =6
		- OOV tokens even after lowercasing, no repetition  =3
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =7
		- OOV tokens, no repetitions, Case Sensitive =4
		- Total OOV tokens even after lowercasing  =7
		- OOV tokens even after lowercasing, no repetition  =4
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =1
		- OOV tokens, no repetitions, Case Sensitive =1
		- Total OOV tokens even after lowercasing  =0
		- OOV tokens even after lowercasing, no repetition  =0
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 133 milliseconds
Constructing a problem for the following text: 
  Washington 11-15 (AFP) -  Stewart Talbot, America's Assistant Secretary of State and "second in charge" at the State Department after Madeleine Albright, has decided to resign from the administra...
Annotating mention view..
0 milliseconds elapsed on constructing the TF-IDF representation of the input text...20001115_AFP_ARB.0212.eng
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Adding NER candidates for 20001115_AFP_ARB.0212.eng
Adding SHALLOW_PARSE and subChunk candidates for 20001115_AFP_ARB.0212.eng
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Matched regex entity Stewart Talbot, America's Assistant Secretary of State[28-82]{6-15}
Matched regex entity America's Assistant Secretary of State[44-82]{9-15}
Matched regex entity Assistant Secretary of State[54-82]{11-15}
Matched regex entity Richard Levin, the Chancellor[295-324]{54-59}
Matched regex entity Levin, the Chancellor[303-324]{55-59}
Matched regex entity Globalization Studies Center[384-412]{69-72}
Matched regex entity Middle East, Dennis Ross[670-694]{120-125}
Matched regex entity Secretary of State[948-966]{172-175}
Matched regex entity Soviet Union Affairs[1039-1059]{187-190}
Matched regex entity Union Affairs[1046-1059]{188-190}
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Done constructing the Wikifiable entities
     ----  almost there....
227 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...20001115_AFP_ARB.0212.eng
Inference on the document  -- 20001115_AFP_ARB.0212.eng
2 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
3 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
49 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
5 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
33 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
2 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: America to : http://en.wikipedia.org/wiki/United_States
Level:FeatureExtractorCoherenceCorrect Wikification of: Madeleine Albright to : http://en.wikipedia.org/wiki/Madeleine_Albright
Level:FeatureExtractorCoherenceCorrect Wikification of: Yale University to : http://en.wikipedia.org/wiki/Yale_University
Level:FeatureExtractorCoherenceCorrect Wikification of: Richard Levin to : http://en.wikipedia.org/wiki/Rick_Levin
Level:FeatureExtractorCoherenceCorrect Wikification of: Middle East to : http://en.wikipedia.org/wiki/Middle_East
Level:FeatureExtractorCoherenceCorrect Wikification of: Time magazine to : http://en.wikipedia.org/wiki/Time_(magazine)
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Stewart Talbot; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Stewart_Talbot ; the gold is: http://en.wikipedia.org/wiki/*null*;
  The surface form has a single disambiguation candidate : Stewart_Talbot(ranker score=3.4801285430031115) ;
  The context is: ; ------- ;   Washington 11-15 (AFP) -  Stewart Talbot, America's Assistant Secretary of State and "second in charge" at the State Department after Madeleine Albright, has decided to resign from the administration to head one of the departm
Level:FeatureExtractorCoherenceCorrect Wikification of: America to : http://en.wikipedia.org/wiki/United_States
Level:FeatureExtractorCoherenceCorrect Wikification of: State to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherencethis fixes the Wikification (!!!)State; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/*null*;
  The confusions set is : United_States_Secretary_of_State(ranker score=3.6223686880024175) Vs: United_States_Department_of_State(ranker score=4.340593239475327);
  The context is: ; ------- ;   Washington 11-15 (AFP) -  Stewart Talbot, America's Assistant Secretary of State and "second in charge" at the State Department after Madeleine Albright, has decided to resign from the administration to head one of the departments at Yale University in the state of Connectic
Level:FeatureExtractorCoherenceCorrect Wikification of: Madeleine Albright to : http://en.wikipedia.org/wiki/Madeleine_Albright
Level:FeatureExtractorCoherenceCorrect Wikification of: Yale University to : http://en.wikipedia.org/wiki/Yale_University
Level:FeatureExtractorCoherenceCorrect Wikification of: northeast to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherencethis fixes the Wikification (!!!)northeast; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/*null*;
  The confusions set is : Northeast(ranker score=1.1775038521203136) Vs: Northeastern_United_States(ranker score=2.149622686121817);
  The context is: ; ------- ; e and "second in charge" at the State Department after Madeleine Albright, has decided to resign from the administration to head one of the departments at Yale University in the state of Connecticut (northeast).   Richard Levin, the Chancellor of this prestigious university, said Talbot would head the Globalization Studies Center as of next July and would also teach at the university.   Talbot is 
Level:FeatureExtractorCoherenceCorrect Wikification of: Richard Levin to : http://en.wikipedia.org/wiki/Rick_Levin
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Globalization Studies Center; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Yale_Center_for_the_Study_of_Globalization;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; he administration to head one of the departments at Yale University in the state of Connecticut (northeast).   Richard Levin, the Chancellor of this prestigious university, said Talbot would head the Globalization Studies Center as of next July and would also teach at the university.   Talbot is the second top-ranking American diplomat in a few days to announce his intention of resigning at the en
Level:FeatureExtractorCoherenceCorrect Wikification of: Middle East to : http://en.wikipedia.org/wiki/Middle_East
Level:FeatureExtractorCoherenceCorrect Wikification of: Time magazine to : http://en.wikipedia.org/wiki/Time_(magazine)
Could not find WikiMatchData for title Top_Ranking:_A_Diplo_Dub
Could not find WikiMatchData for title Center_for_Global_Studies
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Stewart Talbot[28-42]{6-8} === America 's Assistant Secretary of State
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - Force linking Stewart Talbot[28-42]{6-8} to null
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Richard Levin[295-308]{54-56} === the Chancellor of this prestigious university
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Dennis Ross[683-694]{123-125} === The special envoy to the Middle East
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Talbot[848-854]{155-156} === a Yale graduate
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - Force linking Talbot[848-854]{155-156} to null
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bill_Clinton due to a longer mention than Clinton that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Yale_School_of_Architecture due to a longer mention than Yale that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Yale_University due to a longer mention than Yale that referred to the same thing
Relational inference took 8ms
CoherenceRelation 28 [arg1=[surface=Talbot, solution=*null*], arg2=[surface=Stewart Talbot, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 136 [arg1=[surface=Madeleine, solution=Madeleine_Albright], arg2=[surface=Madeleine Albright, solution=Madeleine_Albright], weight=10.0] is captured by ILP inference.
CoherenceRelation 236 [arg1=[surface=Yale, solution=Yale_University], arg2=[surface=Yale University, solution=Yale_University], weight=10.0] is captured by ILP inference.
CoherenceRelation 136 [arg1=[surface=Albright, solution=Madeleine_Albright], arg2=[surface=Madeleine Albright, solution=Madeleine_Albright], weight=10.0] is captured by ILP inference.
CoherenceRelation 295 [arg1=[surface=Levin, solution=Rick_Levin], arg2=[surface=Richard Levin, solution=Rick_Levin], weight=10.0] is captured by ILP inference.
CoherenceRelation 28 [arg1=[surface=Talbot, solution=*null*], arg2=[surface=Stewart Talbot, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 28 [arg1=[surface=Talbot, solution=*null*], arg2=[surface=Stewart Talbot, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 589 [arg1=[surface=President, solution=Bill_Clinton], arg2=[surface=President Bill Clinton, solution=Bill_Clinton], weight=10.0] is captured by ILP inference.
CoherenceRelation 28 [arg1=[surface=Talbot, solution=*null*], arg2=[surface=Stewart Talbot, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 589 [arg1=[surface=Bill Clinton, solution=Bill_Clinton], arg2=[surface=President Bill Clinton, solution=Bill_Clinton], weight=10.0] is captured by ILP inference.
CoherenceRelation 295 [arg1=[surface=Richard, solution=Rick_Levin], arg2=[surface=Richard Levin, solution=Rick_Levin], weight=10.0] is captured by ILP inference.
CoherenceRelation 683 [arg1=[surface=Dennis, solution=Dennis_Ross], arg2=[surface=Dennis Ross, solution=Dennis_Ross], weight=10.0] is captured by ILP inference.
CoherenceRelation 54 [arg1=[surface=Assistant Secretary, solution=United_States_Assistant_Secretary_of_State], arg2=[surface=Assistant Secretary of State, solution=United_States_Assistant_Secretary_of_State], weight=10.0] is captured by ILP inference.
CoherenceRelation 683 [arg1=[surface=Ross, solution=Dennis_Ross], arg2=[surface=Dennis Ross, solution=Dennis_Ross], weight=10.0] is captured by ILP inference.
CoherenceRelation 589 [arg1=[surface=Clinton, solution=Bill_Clinton], arg2=[surface=President Bill Clinton, solution=Bill_Clinton], weight=10.0] is captured by ILP inference.
CoherenceRelation 28 [arg1=[surface=Stewart, solution=*null*], arg2=[surface=Stewart Talbot, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 948 [arg1=[surface=Secretary, solution=Secretary_of_State], arg2=[surface=Secretary of State, solution=Secretary_of_State], weight=10.0] is captured by ILP inference.
Discarded 28 hypothesis
Level: Relational Coherence Correct Wikification of: Stewart Talbot to : http://en.wikipedia.org/wiki/*null*
Level: Relational Coherence this fixes the Wikification (!!!)Stewart Talbot; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/*null*;
  The surface form has a single disambiguation candidate : Stewart_Talbot(ranker score=1.0) ;
  The context is: ; ------- ;   Washington 11-15 (AFP) -  Stewart Talbot, America's Assistant Secretary of State and "second in charge" at the State Department after Madeleine Albright, has decided to resign from the administration to head one of the departm
Level: Relational Coherence Correct Wikification of: America to : http://en.wikipedia.org/wiki/United_States
Level: Relational Coherence Correct Wikification of: State to : http://en.wikipedia.org/wiki/*null*
Level: Relational Coherence Correct Wikification of: Madeleine Albright to : http://en.wikipedia.org/wiki/Madeleine_Albright
Level: Relational Coherence Correct Wikification of: Yale University to : http://en.wikipedia.org/wiki/Yale_University
Level: Relational Coherence Correct Wikification of: northeast to : http://en.wikipedia.org/wiki/*null*
Level: Relational Coherence Correct Wikification of: Richard Levin to : http://en.wikipedia.org/wiki/Rick_Levin
Level: Relational Coherence : Still Incorrect Wikification of: Globalization Studies Center; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Center_for_Global_Studies ; the gold is: http://en.wikipedia.org/wiki/Yale_Center_for_the_Study_of_Globalization;
  The surface form has a single disambiguation candidate : Center_for_Global_Studies(ranker score=0.5) ;
  The context is: ; ------- ; he administration to head one of the departments at Yale University in the state of Connecticut (northeast).   Richard Levin, the Chancellor of this prestigious university, said Talbot would head the Globalization Studies Center as of next July and would also teach at the university.   Talbot is the second top-ranking American diplomat in a few days to announce his intention of resigning at the en
Level: Relational Coherence Correct Wikification of: Middle East to : http://en.wikipedia.org/wiki/Middle_East
Level: Relational Coherence Correct Wikification of: Time magazine to : http://en.wikipedia.org/wiki/Time_(magazine)
Annotation at test time--346 milliseconds elapsed to annotate the document 20001115_AFP_ARB.0212.eng
Final System Output:Correct Wikification of: Stewart Talbot to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: America to : http://en.wikipedia.org/wiki/United_States
Candidates Entropy: 0.013671485289814801
Final System Output:Correct Wikification of: State to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 1.5428999437421882
Final System Output:Correct Wikification of: Madeleine Albright to : http://en.wikipedia.org/wiki/Madeleine_Albright
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Yale University to : http://en.wikipedia.org/wiki/Yale_University
Candidates Entropy: 0.0955333510910518
Final System Output:Correct Wikification of: northeast to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 2.530087587028959
Final System Output:Correct Wikification of: Richard Levin to : http://en.wikipedia.org/wiki/Rick_Levin
Candidates Entropy: 0.0
Final System Output:: Still Incorrect Wikification of: Globalization Studies Center; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Center_for_Global_Studies ; the gold is: http://en.wikipedia.org/wiki/Yale_Center_for_the_Study_of_Globalization;
  The surface form has a single disambiguation candidate : Center_for_Global_Studies(ranker score=0.5) ;
  The context is: ; ------- ; he administration to head one of the departments at Yale University in the state of Connecticut (northeast).   Richard Levin, the Chancellor of this prestigious university, said Talbot would head the Globalization Studies Center as of next July and would also teach at the university.   Talbot is the second top-ranking American diplomat in a few days to announce his intention of resigning at the en
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Middle East to : http://en.wikipedia.org/wiki/Middle_East
Candidates Entropy: 0.1297616274110785
Final System Output:Correct Wikification of: Time magazine to : http://en.wikipedia.org/wiki/Time_(magazine)
Candidates Entropy: 0.0
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/20001115_AFP_ARB.0212.eng.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/NYT20001217.2241.0165
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =901
		- Total unique tokens  =429
		- Total unique tokens ignore case =397
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =51
		- OOV tokens, no repetitions, Case Sensitive =42
		- Total OOV tokens even after lowercasing  =50
		- OOV tokens even after lowercasing, no repetition  =41
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =79
		- OOV tokens, no repetitions, Case Sensitive =46
		- Total OOV tokens even after lowercasing  =76
		- OOV tokens even after lowercasing, no repetition  =43
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =59
		- OOV tokens, no repetitions, Case Sensitive =51
		- Total OOV tokens even after lowercasing  =53
		- OOV tokens even after lowercasing, no repetition  =45
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 903 milliseconds
Constructing a problem for the following text: 
 &LR; (ART ADV: Photo _ NYT8 _ is being sent to NYT photo clients. Graphic is being sent to NYT graphics clients. Nonsubscribers can make one-time purchases by calling 888-603-1036 or 888-346-9867....
Annotating mention view..
1 milliseconds elapsed on constructing the TF-IDF representation of the input text...NYT20001217.2241.0165
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Adding NER candidates for NYT20001217.2241.0165
Adding SHALLOW_PARSE and subChunk candidates for NYT20001217.2241.0165
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Matched regex entity Chicago O'Hare and La Guardia in New York[539-580]{119-127}
Matched regex entity La Guardia in New York[558-580]{122-127}
Matched regex entity Guardia in New York[561-580]{123-127}
Matched regex entity The Transportation Department[1014-1043]{201-204}
Matched regex entity Transportation Department[1018-1043]{202-204}
Matched regex entity Instead of Los Angeles International[1653-1689]{307-312}
Matched regex entity John Wayne Airport in Orange County, Calif[1736-1778]{321-329}
Matched regex entity Orange County, Calif[1758-1778]{325-329}
Matched regex entity JFK in New York[1826-1841]{337-341}
Matched regex entity Day of Departure[2492-2508]{457-460}
Matched regex entity The Federal Aviation Administration's Web[2700-2741]{493-499}
Matched regex entity Federal Aviation Administration's Web[2704-2741]{494-499}
Matched regex entity Transportation Department's[4649-4676]{875-878}
Matched regex entity Aviation Consumer Protection Div[4785-4817]{898-902}
Matched regex entity Department of Transportation[4828-4856]{906-909}
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Important warning: the manually defined entity 400 Seventh St. S.W. had 0 disambiguation candidates
Done constructing the Wikifiable entities
     ----  almost there....
313 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...NYT20001217.2241.0165
Inference on the document  -- NYT20001217.2241.0165
3 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
3 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
97 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
11 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
178 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
7 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: Chicago O'Hare to : http://en.wikipedia.org/wiki/O'Hare_International_Airport
Level:FeatureExtractorCoherenceCorrect Wikification of: La Guardia to : http://en.wikipedia.org/wiki/LaGuardia_Airport
Level:FeatureExtractorCoherenceCorrect Wikification of: South to : http://en.wikipedia.org/wiki/Southern_United_States
Level:FeatureExtractorCoherenceCorrect Wikification of: Transportation Department to : http://en.wikipedia.org/wiki/United_States_Department_of_Transportation
Level:FeatureExtractorCoherenceCorrect Wikification of: Los Angeles International to : http://en.wikipedia.org/wiki/Los_Angeles_International_Airport
Level:FeatureExtractorCoherenceCorrect Wikification of: John Wayne Airport to : http://en.wikipedia.org/wiki/John_Wayne_Airport
Level:FeatureExtractorCoherenceCorrect Wikification of: Orange County to : http://en.wikipedia.org/wiki/Orange_County,_California
Level:FeatureExtractorCoherenceCorrect Wikification of: Calif to : http://en.wikipedia.org/wiki/California
Level:FeatureExtractorCoherenceCorrect Wikification of: Westchester County Airport to : http://en.wikipedia.org/wiki/Westchester_County_Airport
Level:FeatureExtractorCoherenceCorrect Wikification of: JFK to : http://en.wikipedia.org/wiki/John_F._Kennedy_International_Airport
Level:FeatureExtractorCoherenceCorrect Wikification of: Federal Aviation Administration to : http://en.wikipedia.org/wiki/Federal_Aviation_Administration
Level:FeatureExtractorCoherenceCorrect Wikification of: Chicago O'Hare to : http://en.wikipedia.org/wiki/O'Hare_International_Airport
Level:FeatureExtractorCoherenceCorrect Wikification of: La Guardia to : http://en.wikipedia.org/wiki/LaGuardia_Airport
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: New York; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/New_York ; the gold is: http://en.wikipedia.org/wiki/New_York_City;
  The confusions set is : John_F._Kennedy_International_Airport(ranker score=3.7448127333917194) Vs: New_York(ranker score=5.797734414496884);
  The context is: ; ------- ; e lower the chance that you will suffer a delay.   _ Pick airports with care. If you have to connect, choose the least-congested airport possible; some airports, like Chicago O'Hare and La Guardia in New York, experience chronic delays. Take into consideration the weather and the season; an airport in the South might have fewer winter snowstorms but more spring and summer thunderstorms.   _ Check 
Level:FeatureExtractorCoherence: this introduces a Wikification error(!!!): South; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Southern_United_States;
  The confusions set is : South(ranker score=1.4287470576304269) Vs: Southern_United_States(ranker score=1.6245999442270906);
  The context is: ; ------- ; e the least-congested airport possible; some airports, like Chicago O'Hare and La Guardia in New York, experience chronic delays. Take into consideration the weather and the season; an airport in the South might have fewer winter snowstorms but more spring and summer thunderstorms.   _ Check times between connecting flights. Airlines often book tight connections and do not take responsibility if y
Level:FeatureExtractorCoherenceCorrect Wikification of: Transportation Department to : http://en.wikipedia.org/wiki/United_States_Department_of_Transportation
Level:FeatureExtractorCoherenceCorrect Wikification of: Los Angeles International to : http://en.wikipedia.org/wiki/Los_Angeles_International_Airport
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Burbank; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Bob_Hope_Airport;
  The confusions set is : Bob_Hope_Airport(ranker score=4.076186257362626) Vs: Burbank,_California(ranker score=4.410343186962253);
  The context is: ; ------- ; ess likely to be delayed, because of the cascading effect that disruptions have on airline schedules.   _ Use smaller airports. Instead of Los Angeles International, for example, consider flying into Burbank or John Wayne Airport in Orange County, Calif., or use Westchester County Airport instead of JFK in New York.   _ Avoid electronic tickets. Though they are convenient and more secure than an e
Level:FeatureExtractorCoherenceCorrect Wikification of: John Wayne Airport to : http://en.wikipedia.org/wiki/John_Wayne_Airport
Level:FeatureExtractorCoherence: this introduces a Wikification error(!!!): Orange County; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Orange_County,_California;
  The confusions set is : John_Wayne_Airport(ranker score=4.9369568997522455) Vs: Orange_County,_California(ranker score=5.5042063470159635);
  The context is: ; ------- ;  of the cascading effect that disruptions have on airline schedules.   _ Use smaller airports. Instead of Los Angeles International, for example, consider flying into Burbank or John Wayne Airport in Orange County, Calif., or use Westchester County Airport instead of JFK in New York.   _ Avoid electronic tickets. Though they are convenient and more secure than an easily lost paper ticket, they are
Level:FeatureExtractorCoherenceCorrect Wikification of: Calif to : http://en.wikipedia.org/wiki/California
Level:FeatureExtractorCoherenceCorrect Wikification of: Westchester County Airport to : http://en.wikipedia.org/wiki/Westchester_County_Airport
Level:FeatureExtractorCoherenceCorrect Wikification of: JFK to : http://en.wikipedia.org/wiki/John_F._Kennedy_International_Airport
Level:FeatureExtractorCoherenceCorrect Wikification of: Federal Aviation Administration to : http://en.wikipedia.org/wiki/Federal_Aviation_Administration
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Washington; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Washington ; the gold is: http://en.wikipedia.org/wiki/Washington,_D.C.;
  The confusions set is : Washington,_D.C.(ranker score=1.6940888517590513) Vs: Washington(ranker score=3.788638556858165);
  The context is: ; ------- ; most always offer a refund, reimbursement of expenses, a discount on your next ticket _ or all three. Be sure to save the relevant paperwork.   _ Make it a federal case. Send a copy of your letter to Washington. Complaints are charged against each airline in the Transportation Department's monthly Air Travel Consumer Report and serve as a basis for rule making and enforcement action. Write to:   A
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Aviation Consumer Protection Div; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Airline_complaints;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ;  Washington. Complaints are charged against each airline in the Transportation Department's monthly Air Travel Consumer Report and serve as a basis for rule making and enforcement action. Write to:   Aviation Consumer Protection Div. (C-75)   Department of Transportation   400 Seventh St. S.W.   Washington, DC 20590  
Could not find WikiMatchData for title Monday_Mornings
Could not find WikiMatchData for title Peak_car
Could not find WikiMatchData for title The_Federal_Kuala_Lumpur
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=John_Wayne_Airport, pred=city, arg2=Orange_County,_California, score=38.295303630828855, normalizedScore=100.0]For surfaces John Wayne Airport and Orange County
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Orange_County,_California, pred=isPartOf, arg2=California, score=6.653257608413696, normalizedScore=100.0]For surfaces Orange County and Calif
Relational inference took 10ms
CoherenceRelation 1758 [arg1=[surface=John Wayne Airport, solution=John_Wayne_Airport], arg2=[surface=Orange County, solution=Orange_County,_California], weight=100.0] is captured by ILP inference.
CoherenceRelation 1664 [arg1=[surface=International, solution=Los_Angeles_International_Airport], arg2=[surface=Los Angeles International, solution=Los_Angeles_International_Airport], weight=10.0] is captured by ILP inference.
CoherenceRelation 1736 [arg1=[surface=John Wayne, solution=John_Wayne_Airport], arg2=[surface=John Wayne Airport, solution=John_Wayne_Airport], weight=10.0] is captured by ILP inference.
CoherenceRelation 1773 [arg1=[surface=Orange County, solution=Orange_County,_California], arg2=[surface=Calif, solution=California], weight=1.0] is captured by ILP inference.
CoherenceRelation 1736 [arg1=[surface=John, solution=John_Wayne_Airport], arg2=[surface=John Wayne Airport, solution=John_Wayne_Airport], weight=10.0] is captured by ILP inference.
CoherenceRelation 1736 [arg1=[surface=Wayne, solution=John_Wayne_Airport], arg2=[surface=John Wayne Airport, solution=John_Wayne_Airport], weight=10.0] is captured by ILP inference.
CoherenceRelation 1018 [arg1=[surface=Transportation Department, solution=United_States_Department_of_Transportation], arg2=[surface=Transportation Department, solution=United_States_Department_of_Transportation], weight=10.0] is captured by ILP inference.
CoherenceRelation 1788 [arg1=[surface=Airport, solution=Westchester_County_Airport], arg2=[surface=Westchester County Airport, solution=Westchester_County_Airport], weight=10.0] is captured by ILP inference.
CoherenceRelation 1736 [arg1=[surface=Airport, solution=John_Wayne_Airport], arg2=[surface=John Wayne Airport, solution=John_Wayne_Airport], weight=10.0] is captured by ILP inference.
Discarded 0 hypothesis
Level: Relational Coherence Correct Wikification of: Chicago O'Hare to : http://en.wikipedia.org/wiki/O'Hare_International_Airport
Level: Relational Coherence Correct Wikification of: La Guardia to : http://en.wikipedia.org/wiki/LaGuardia_Airport
Level: Relational Coherence : Still Incorrect Wikification of: New York; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/New_York ; the gold is: http://en.wikipedia.org/wiki/New_York_City;
  The confusions set is : John_F._Kennedy_International_Airport(ranker score=0.10309266645693599) Vs: New_York(ranker score=0.803156781189385);
  The context is: ; ------- ; e lower the chance that you will suffer a delay.   _ Pick airports with care. If you have to connect, choose the least-congested airport possible; some airports, like Chicago O'Hare and La Guardia in New York, experience chronic delays. Take into consideration the weather and the season; an airport in the South might have fewer winter snowstorms but more spring and summer thunderstorms.   _ Check 
Level: Relational Coherence : Still Incorrect Wikification of: South; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Southern_United_States;
  The confusions set is : South(ranker score=0.15286799628499795) Vs: Southern_United_States(ranker score=0.18594067406767);
  The context is: ; ------- ; e the least-congested airport possible; some airports, like Chicago O'Hare and La Guardia in New York, experience chronic delays. Take into consideration the weather and the season; an airport in the South might have fewer winter snowstorms but more spring and summer thunderstorms.   _ Check times between connecting flights. Airlines often book tight connections and do not take responsibility if y
Level: Relational Coherence Correct Wikification of: Transportation Department to : http://en.wikipedia.org/wiki/United_States_Department_of_Transportation
Level: Relational Coherence Correct Wikification of: Los Angeles International to : http://en.wikipedia.org/wiki/Los_Angeles_International_Airport
Level: Relational Coherence : Still Incorrect Wikification of: Burbank; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Bob_Hope_Airport;
  The confusions set is : Bob_Hope_Airport(ranker score=0.36620918203396363) Vs: Burbank,_California(ranker score=0.5115071866034712);
  The context is: ; ------- ; ess likely to be delayed, because of the cascading effect that disruptions have on airline schedules.   _ Use smaller airports. Instead of Los Angeles International, for example, consider flying into Burbank or John Wayne Airport in Orange County, Calif., or use Westchester County Airport instead of JFK in New York.   _ Avoid electronic tickets. Though they are convenient and more secure than an e
Level: Relational Coherence Correct Wikification of: John Wayne Airport to : http://en.wikipedia.org/wiki/John_Wayne_Airport
Level: Relational Coherence Correct Wikification of: Orange County to : http://en.wikipedia.org/wiki/Orange_County,_California
Level: Relational Coherence this fixes the Wikification (!!!)Orange County; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Orange_County,_California ; the gold is: http://en.wikipedia.org/wiki/Orange_County,_California;
  The confusions set is : John_Wayne_Airport(ranker score=0.31641825356358855) Vs: Orange_County,_California(ranker score=0.557975119628464);
  The context is: ; ------- ;  of the cascading effect that disruptions have on airline schedules.   _ Use smaller airports. Instead of Los Angeles International, for example, consider flying into Burbank or John Wayne Airport in Orange County, Calif., or use Westchester County Airport instead of JFK in New York.   _ Avoid electronic tickets. Though they are convenient and more secure than an easily lost paper ticket, they are
Level: Relational Coherence Correct Wikification of: Calif to : http://en.wikipedia.org/wiki/California
Level: Relational Coherence Correct Wikification of: Westchester County Airport to : http://en.wikipedia.org/wiki/Westchester_County_Airport
Level: Relational Coherence Correct Wikification of: JFK to : http://en.wikipedia.org/wiki/John_F._Kennedy_International_Airport
Level: Relational Coherence Correct Wikification of: Federal Aviation Administration to : http://en.wikipedia.org/wiki/Federal_Aviation_Administration
Level: Relational Coherence : Still Incorrect Wikification of: Washington; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Washington ; the gold is: http://en.wikipedia.org/wiki/Washington,_D.C.;
  The confusions set is : Washington,_D.C.(ranker score=0.07704728280040539) Vs: Washington(ranker score=0.6257613077330035);
  The context is: ; ------- ; most always offer a refund, reimbursement of expenses, a discount on your next ticket _ or all three. Be sure to save the relevant paperwork.   _ Make it a federal case. Send a copy of your letter to Washington. Complaints are charged against each airline in the Transportation Department's monthly Air Travel Consumer Report and serve as a basis for rule making and enforcement action. Write to:   A
Level: Relational Coherence : Still Incorrect Wikification of: Aviation Consumer Protection Div; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Airline_complaints;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ;  Washington. Complaints are charged against each airline in the Transportation Department's monthly Air Travel Consumer Report and serve as a basis for rule making and enforcement action. Write to:   Aviation Consumer Protection Div. (C-75)   Department of Transportation   400 Seventh St. S.W.   Washington, DC 20590  
Annotation at test time--791 milliseconds elapsed to annotate the document NYT20001217.2241.0165
Final System Output:Correct Wikification of: Chicago O'Hare to : http://en.wikipedia.org/wiki/O'Hare_International_Airport
Candidates Entropy: 0.04297599615793815
Final System Output:Correct Wikification of: La Guardia to : http://en.wikipedia.org/wiki/LaGuardia_Airport
Candidates Entropy: 0.414677028733443
Final System Output:: Still Incorrect Wikification of: New York; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/New_York ; the gold is: http://en.wikipedia.org/wiki/New_York_City;
  The confusions set is : John_F._Kennedy_International_Airport(ranker score=0.10309266645693599) Vs: New_York(ranker score=0.803156781189385);
  The context is: ; ------- ; e lower the chance that you will suffer a delay.   _ Pick airports with care. If you have to connect, choose the least-congested airport possible; some airports, like Chicago O'Hare and La Guardia in New York, experience chronic delays. Take into consideration the weather and the season; an airport in the South might have fewer winter snowstorms but more spring and summer thunderstorms.   _ Check 
Candidates Entropy: 0.8139464600332298
Final System Output:: Still Incorrect Wikification of: South; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Southern_United_States;
  The confusions set is : South(ranker score=0.15286799628499795) Vs: Southern_United_States(ranker score=0.18594067406767);
  The context is: ; ------- ; e the least-congested airport possible; some airports, like Chicago O'Hare and La Guardia in New York, experience chronic delays. Take into consideration the weather and the season; an airport in the South might have fewer winter snowstorms but more spring and summer thunderstorms.   _ Check times between connecting flights. Airlines often book tight connections and do not take responsibility if y
Candidates Entropy: 2.784513719441679
Final System Output:Correct Wikification of: Transportation Department to : http://en.wikipedia.org/wiki/United_States_Department_of_Transportation
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Los Angeles International to : http://en.wikipedia.org/wiki/Los_Angeles_International_Airport
Candidates Entropy: 0.0
Final System Output:: Still Incorrect Wikification of: Burbank; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Bob_Hope_Airport;
  The confusions set is : Bob_Hope_Airport(ranker score=0.36620918203396363) Vs: Burbank,_California(ranker score=0.5115071866034712);
  The context is: ; ------- ; ess likely to be delayed, because of the cascading effect that disruptions have on airline schedules.   _ Use smaller airports. Instead of Los Angeles International, for example, consider flying into Burbank or John Wayne Airport in Orange County, Calif., or use Westchester County Airport instead of JFK in New York.   _ Avoid electronic tickets. Though they are convenient and more secure than an e
Candidates Entropy: 1.1956121409076252
Final System Output:Correct Wikification of: John Wayne Airport to : http://en.wikipedia.org/wiki/John_Wayne_Airport
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Orange County to : http://en.wikipedia.org/wiki/Orange_County,_California
Candidates Entropy: 1.094434217567585
Final System Output:Correct Wikification of: Calif to : http://en.wikipedia.org/wiki/California
Candidates Entropy: 0.07474020974866061
Final System Output:Correct Wikification of: Westchester County Airport to : http://en.wikipedia.org/wiki/Westchester_County_Airport
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: JFK to : http://en.wikipedia.org/wiki/John_F._Kennedy_International_Airport
Candidates Entropy: 0.16303512160145028
Final System Output:Correct Wikification of: Federal Aviation Administration to : http://en.wikipedia.org/wiki/Federal_Aviation_Administration
Candidates Entropy: 0.0
Final System Output:: Still Incorrect Wikification of: Washington; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Washington ; the gold is: http://en.wikipedia.org/wiki/Washington,_D.C.;
  The confusions set is : Washington,_D.C.(ranker score=0.07704728280040539) Vs: Washington(ranker score=0.6257613077330035);
  The context is: ; ------- ; most always offer a refund, reimbursement of expenses, a discount on your next ticket _ or all three. Be sure to save the relevant paperwork.   _ Make it a federal case. Send a copy of your letter to Washington. Complaints are charged against each airline in the Transportation Department's monthly Air Travel Consumer Report and serve as a basis for rule making and enforcement action. Write to:   A
Candidates Entropy: 1.6779416908659304
Final System Output:: Still Incorrect Wikification of: Aviation Consumer Protection Div; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Airline_complaints;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ;  Washington. Complaints are charged against each airline in the Transportation Department's monthly Air Travel Consumer Report and serve as a basis for rule making and enforcement action. Write to:   Aviation Consumer Protection Div. (C-75)   Department of Transportation   400 Seventh St. S.W.   Washington, DC 20590  
Candidates Entropy: 0.0
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/NYT20001217.2241.0165.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/20001115_AFP_ARB.0061.eng
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =123
		- Total unique tokens  =77
		- Total unique tokens ignore case =74
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =8
		- OOV tokens, no repetitions, Case Sensitive =3
		- Total OOV tokens even after lowercasing  =8
		- OOV tokens even after lowercasing, no repetition  =3
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =11
		- OOV tokens, no repetitions, Case Sensitive =6
		- Total OOV tokens even after lowercasing  =11
		- OOV tokens even after lowercasing, no repetition  =6
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =0
		- OOV tokens, no repetitions, Case Sensitive =0
		- Total OOV tokens even after lowercasing  =0
		- OOV tokens even after lowercasing, no repetition  =0
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 126 milliseconds
Constructing a problem for the following text: 
  Gaza 11-15 (AFP) -  A high-level Palestinian source said today Wednesday that the Palestinian Superior Security Council led by President Yasser Arafat issued orders to stop shooting inside area "...
Annotating mention view..
1 milliseconds elapsed on constructing the TF-IDF representation of the input text...20001115_AFP_ARB.0061.eng
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Adding NER candidates for 20001115_AFP_ARB.0061.eng
Adding SHALLOW_PARSE and subChunk candidates for 20001115_AFP_ARB.0061.eng
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Important warning: the manually defined entity area "A" had 0 disambiguation candidates
Done constructing the Wikifiable entities
     ----  almost there....
108 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...20001115_AFP_ARB.0061.eng
Inference on the document  -- 20001115_AFP_ARB.0061.eng
1 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
2 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
36 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
4 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
238 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
2 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: Gaza to : http://en.wikipedia.org/wiki/Gaza
Level:FeatureExtractorCoherenceCorrect Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level:FeatureExtractorCoherenceCorrect Wikification of: Palestinian Superior Security Council to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Gaza to : http://en.wikipedia.org/wiki/Gaza
Level:FeatureExtractorCoherenceCorrect Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level:FeatureExtractorCoherenceCorrect Wikification of: Palestinian Superior Security Council to : http://en.wikipedia.org/wiki/*null*
Could not find WikiMatchData for title Palestinian_Autonomous_Areas
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Prime_Minister_of_Israel, pred=shortDescription, arg2=Ehud_Barak, score=26.659513092041017, normalizedScore=100.0]For surfaces Israeli Prime Minister and Ehud Barak
Relational inference took 3ms
CoherenceRelation 139 [arg1=[surface=Yasser Arafat, solution=Yasser_Arafat], arg2=[surface=Yasser Arafat, solution=Yasser_Arafat], weight=10.0] is captured by ILP inference.
CoherenceRelation 310 [arg1=[surface=Arafat, solution=Yasser_Arafat], arg2=[surface=Yasser Arafat, solution=Yasser_Arafat], weight=10.0] is captured by ILP inference.
CoherenceRelation 139 [arg1=[surface=Yasser, solution=Yasser_Arafat], arg2=[surface=Yasser Arafat, solution=Yasser_Arafat], weight=10.0] is captured by ILP inference.
CoherenceRelation 139 [arg1=[surface=Arafat, solution=Yasser_Arafat], arg2=[surface=Yasser Arafat, solution=Yasser_Arafat], weight=10.0] is captured by ILP inference.
CoherenceRelation 597 [arg1=[surface=Israeli Prime Minister, solution=Prime_Minister_of_Israel], arg2=[surface=Ehud Barak, solution=Ehud_Barak], weight=100.0] is captured by ILP inference.
CoherenceRelation 310 [arg1=[surface=Yasser, solution=Yasser_Arafat], arg2=[surface=Yasser Arafat, solution=Yasser_Arafat], weight=10.0] is captured by ILP inference.
CoherenceRelation 597 [arg1=[surface=Barak, solution=Ehud_Barak], arg2=[surface=Ehud Barak, solution=Ehud_Barak], weight=10.0] is captured by ILP inference.
CoherenceRelation 597 [arg1=[surface=Ehud, solution=Ehud_Barak], arg2=[surface=Ehud Barak, solution=Ehud_Barak], weight=10.0] is captured by ILP inference.
CoherenceRelation 84 [arg1=[surface=Palestinian Superior Security Council, solution=*null*], arg2=[surface=Palestinian Superior Security Council, solution=*null*], weight=10.0] is captured by ILP inference.
Discarded 0 hypothesis
Level: Relational Coherence Correct Wikification of: Gaza to : http://en.wikipedia.org/wiki/Gaza
Level: Relational Coherence Correct Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level: Relational Coherence Correct Wikification of: Palestinian Superior Security Council to : http://en.wikipedia.org/wiki/*null*
Annotation at test time--402 milliseconds elapsed to annotate the document 20001115_AFP_ARB.0061.eng
Final System Output:Correct Wikification of: Gaza to : http://en.wikipedia.org/wiki/Gaza
Candidates Entropy: 0.3412439247673263
Final System Output:Correct Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Candidates Entropy: 0.6683680036266826
Final System Output:Correct Wikification of: Palestinian Superior Security Council to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/20001115_AFP_ARB.0061.eng.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/PRI20001128.2000.0055
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =551
		- Total unique tokens  =265
		- Total unique tokens ignore case =249
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =4
		- OOV tokens, no repetitions, Case Sensitive =3
		- Total OOV tokens even after lowercasing  =4
		- OOV tokens even after lowercasing, no repetition  =3
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =16
		- OOV tokens, no repetitions, Case Sensitive =11
		- Total OOV tokens even after lowercasing  =15
		- OOV tokens even after lowercasing, no repetition  =10
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =17
		- OOV tokens, no repetitions, Case Sensitive =11
		- Total OOV tokens even after lowercasing  =16
		- OOV tokens even after lowercasing, no repetition  =10
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 577 milliseconds
Constructing a problem for the following text: 
 Documented. From NPR news in Washington, I'm Corey Flintoff. A Florida State judge has ordered local election officials to ship thousands of ballots to the state capital. The move comes as the jud...
Annotating mention view..
1 milliseconds elapsed on constructing the TF-IDF representation of the input text...PRI20001128.2000.0055
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Adding NER candidates for PRI20001128.2000.0055
Adding SHALLOW_PARSE and subChunk candidates for PRI20001128.2000.0055
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Matched regex entity Washington, I'm Corey Flintoff[30-60]{6-12}
Matched regex entity NPR's Steve Inski[282-299]{52-56}
Matched regex entity NPR's Steven Inksi[1824-1842]{355-359}
Matched regex entity Tallahassee, Florida[1858-1878]{361-364}
Matched regex entity Florida, Washington State[1916-1941]{373-377}
Matched regex entity Washington State[1925-1941]{375-377}
Matched regex entity KPLU in Seattle[2065-2080]{400-403}
Matched regex entity Democrat Maria Catwell and Republican Senator Slate Gordon[2118-2176]{411-419}
Matched regex entity The State's Elections Director Garry Macintosh[2200-2246]{424-431}
Matched regex entity State's Elections Director Garry Macintosh[2204-2246]{425-431}
Matched regex entity I'm Jennifer Nesan in Seattle[2824-2853]{545-551}
Matched regex entity Jennifer Nesan in Seattle[2828-2853]{547-551}
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Done constructing the Wikifiable entities
     ----  almost there....
417 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...PRI20001128.2000.0055
Inference on the document  -- PRI20001128.2000.0055
3 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
6 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
81 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
11 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
112 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
6 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: NPR news to : http://en.wikipedia.org/wiki/NPR
Level:FeatureExtractorCoherenceCorrect Wikification of: Steve Inski to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Democrats to : http://en.wikipedia.org/wiki/Democratic_Party_(United_States)
Level:FeatureExtractorCoherenceCorrect Wikification of: Palm Beach County to : http://en.wikipedia.org/wiki/Palm_Beach_County,_Florida
Level:FeatureExtractorCoherenceCorrect Wikification of: Al Gore to : http://en.wikipedia.org/wiki/Al_Gore
Level:FeatureExtractorCoherenceCorrect Wikification of: Jennifer Nesan to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: NPR news to : http://en.wikipedia.org/wiki/NPR
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Washington; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Washington ; the gold is: http://en.wikipedia.org/wiki/Washington,_D.C.;
  The confusions set is : Washington,_D.C.(ranker score=2.9341376733794324) Vs: Washington(ranker score=4.6362464164966255);
  The context is: ; ------- ;  Documented. From NPR news in Washington, I'm Corey Flintoff. A Florida State judge has ordered local election officials to ship thousands of ballots to the state capital. The move comes as the judge decides whether to order a rec
Level:FeatureExtractorCoherenceCorrect Wikification of: Steve Inski to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Miami Dade County; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Miami-Dade_County,_Florida;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; urtroom. Steve, what are the issues that came up in this hearing tonight?   Corey judge N. Sander Sauls is deciding whether to order a recount as you said of those ballots, 9000 or more actually from Miami Dade County that apparently were never counted at all, at least according to the Democrats in the presidential election and about 3300 ballots from Palm Beach County that were considered by loca
Level:FeatureExtractorCoherenceCorrect Wikification of: Democrats to : http://en.wikipedia.org/wiki/Democratic_Party_(United_States)
Level:FeatureExtractorCoherenceCorrect Wikification of: Palm Beach County to : http://en.wikipedia.org/wiki/Palm_Beach_County,_Florida
Level:FeatureExtractorCoherenceCorrect Wikification of: Al Gore to : http://en.wikipedia.org/wiki/Al_Gore
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Washington State; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Washington_(state);
  The confusions set is : Washington_State_University(ranker score=2.0542187424779184) Vs: Washington(ranker score=2.8433088443020678);
  The context is: ; ------- ; the timetable but the judge said, well, I am going to make everybody equally unhappy.   Thank you. NPR's Steven Inksi reporting from Tallahassee, Florida. As the battle over votes goes on in Florida, Washington State is in the middle of recounting the votes cast in its very tight US Senate race. Jennifer Nesan reports from member station KPLU in Seattle.   The recount of the votes cast for Democra
Level:FeatureExtractorCoherenceCorrect Wikification of: Jennifer Nesan to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Seattle; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Seattle ; the gold is: http://en.wikipedia.org/wiki/*null*;
  The confusions set is : Seattle_Seahawks(ranker score=1.4236780044235897) Vs: Seattle(ranker score=5.5925596412372665);
  The context is: ; ------- ; orida. As the battle over votes goes on in Florida, Washington State is in the middle of recounting the votes cast in its very tight US Senate race. Jennifer Nesan reports from member station KPLU in Seattle.   The recount of the votes cast for Democrat Maria Catwell and Republican Senator Slate Gordon is calm and organized. The State's Elections Director Garry Macintosh says the process is about 
Could not find WikiMatchData for title Decide
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Miami-Dade_County,_Florida, pred=WIKI_LINK_RELATION, arg2=Miami-Dade_County,_Florida, score=18.294065895080564, normalizedScore=100.0]For surfaces Miami Dade and County
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Republican_Party_(United_States), pred=seats1Title, arg2=United_States_Senate, score=3.475419282913208, normalizedScore=100.0]For surfaces Republican and Senator
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Garry Macintosh[2231-2246]{429-431} === The State 's Elections Director
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Al_Gore due to a longer mention than Gore that referred to the same thing
Relational inference took 23ms
CoherenceRelation 2468 [arg1=[surface=Slate Gordon, solution=*null*], arg2=[surface=Slate Gordon, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 2828 [arg1=[surface=Jennifer Nesan, solution=*null*], arg2=[surface=Jennifer Nesan, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 2468 [arg1=[surface=Gordon, solution=*null*], arg2=[surface=Slate Gordon, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 2468 [arg1=[surface=Slate, solution=*null*], arg2=[surface=Slate Gordon, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 667 [arg1=[surface=County, solution=Palm_Beach_County,_Florida], arg2=[surface=Palm Beach County, solution=Palm_Beach_County,_Florida], weight=10.0] is captured by ILP inference.
CoherenceRelation 600 [arg1=[surface=Democrats, solution=Democratic_Party_(United_States)], arg2=[surface=Democrats, solution=Democratic_Party_(United_States)], weight=10.0] is captured by ILP inference.
CoherenceRelation 288 [arg1=[surface=Steve, solution=*null*], arg2=[surface=Steve Inski, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 2156 [arg1=[surface=Republican, solution=Republican_Party_(United_States)], arg2=[surface=Senator, solution=United_States_Senate], weight=100.0] is captured by ILP inference.
CoherenceRelation 401 [arg1=[surface=Sander, solution=*null*], arg2=[surface=N. Sander Sauls, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 2231 [arg1=[surface=Garry, solution=*null*], arg2=[surface=Garry Macintosh, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 18 [arg1=[surface=NPR, solution=NPR], arg2=[surface=NPR, solution=NPR], weight=10.0] is captured by ILP inference.
CoherenceRelation 2231 [arg1=[surface=Macintosh, solution=*null*], arg2=[surface=Garry Macintosh, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 1830 [arg1=[surface=Steven, solution=*null*], arg2=[surface=Steven Inksi, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 46 [arg1=[surface=Flintoff, solution=Corey_Flintoff], arg2=[surface=Corey Flintoff, solution=Corey_Flintoff], weight=10.0] is captured by ILP inference.
CoherenceRelation 288 [arg1=[surface=Steve, solution=*null*], arg2=[surface=Steve Inski, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 18 [arg1=[surface=NPR, solution=NPR], arg2=[surface=NPR, solution=NPR], weight=10.0] is captured by ILP inference.
CoherenceRelation 18 [arg1=[surface=NPR, solution=NPR], arg2=[surface=NPR, solution=NPR], weight=10.0] is captured by ILP inference.
CoherenceRelation 2164 [arg1=[surface=Gordon, solution=*null*], arg2=[surface=Slate Gordon, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 401 [arg1=[surface=N., solution=*null*], arg2=[surface=N. Sander Sauls, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 288 [arg1=[surface=Inski, solution=*null*], arg2=[surface=Steve Inski, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 2127 [arg1=[surface=Catwell, solution=*null*], arg2=[surface=Maria Catwell, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 524 [arg1=[surface=Miami Dade, solution=Miami-Dade_County,_Florida], arg2=[surface=County, solution=Miami-Dade_County,_Florida], weight=100.0] is captured by ILP inference.
CoherenceRelation 1858 [arg1=[surface=Tallahassee, solution=Tallahassee,_Florida], arg2=[surface=Tallahassee, Florida, solution=Tallahassee,_Florida], weight=10.0] is captured by ILP inference.
CoherenceRelation 46 [arg1=[surface=Corey, solution=Corey_Flintoff], arg2=[surface=Corey Flintoff, solution=Corey_Flintoff], weight=10.0] is captured by ILP inference.
CoherenceRelation 863 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 2828 [arg1=[surface=Jennifer, solution=*null*], arg2=[surface=Jennifer Nesan, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 600 [arg1=[surface=Democrats, solution=Democratic_Party_(United_States)], arg2=[surface=Democrats, solution=Democratic_Party_(United_States)], weight=10.0] is captured by ILP inference.
CoherenceRelation 2127 [arg1=[surface=Maria, solution=*null*], arg2=[surface=Maria Catwell, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 401 [arg1=[surface=Sauls, solution=*null*], arg2=[surface=N. Sander Sauls, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 2164 [arg1=[surface=Slate, solution=*null*], arg2=[surface=Slate Gordon, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 401 [arg1=[surface=Sander Sauls, solution=*null*], arg2=[surface=N. Sander Sauls, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 46 [arg1=[surface=Corey, solution=Corey_Flintoff], arg2=[surface=Corey Flintoff, solution=Corey_Flintoff], weight=10.0] is captured by ILP inference.
CoherenceRelation 2447 [arg1=[surface=Republican, solution=Republican_Party_(United_States)], arg2=[surface=Republican, solution=Republican_Party_(United_States)], weight=10.0] is captured by ILP inference.
CoherenceRelation 2022 [arg1=[surface=Jennifer, solution=*null*], arg2=[surface=Jennifer Nesan, solution=*null*], weight=10.0] is captured by ILP inference.
Discarded 60 hypothesis
Level: Relational Coherence Correct Wikification of: NPR news to : http://en.wikipedia.org/wiki/NPR
Level: Relational Coherence : Still Incorrect Wikification of: Washington; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Washington ; the gold is: http://en.wikipedia.org/wiki/Washington,_D.C.;
  The confusions set is : Washington,_D.C.(ranker score=0.1323994534444706) Vs: Washington(ranker score=0.7262775619883165);
  The context is: ; ------- ;  Documented. From NPR news in Washington, I'm Corey Flintoff. A Florida State judge has ordered local election officials to ship thousands of ballots to the state capital. The move comes as the judge decides whether to order a rec
Level: Relational Coherence Correct Wikification of: Steve Inski to : http://en.wikipedia.org/wiki/*null*
Level: Relational Coherence Correct Wikification of: Miami Dade County to : http://en.wikipedia.org/wiki/Miami-Dade_County,_Florida
Level: Relational Coherence this fixes the Wikification (!!!)Miami Dade County; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Miami-Dade_County,_Florida ; the gold is: http://en.wikipedia.org/wiki/Miami-Dade_County,_Florida;
  The surface form has a single disambiguation candidate : Miami-Dade_County,_Florida(ranker score=0.5) ;
  The context is: ; ------- ; urtroom. Steve, what are the issues that came up in this hearing tonight?   Corey judge N. Sander Sauls is deciding whether to order a recount as you said of those ballots, 9000 or more actually from Miami Dade County that apparently were never counted at all, at least according to the Democrats in the presidential election and about 3300 ballots from Palm Beach County that were considered by loca
Level: Relational Coherence Correct Wikification of: Democrats to : http://en.wikipedia.org/wiki/Democratic_Party_(United_States)
Level: Relational Coherence Correct Wikification of: Palm Beach County to : http://en.wikipedia.org/wiki/Palm_Beach_County,_Florida
Level: Relational Coherence Correct Wikification of: Al Gore to : http://en.wikipedia.org/wiki/Al_Gore
Level: Relational Coherence : Still Incorrect Wikification of: Washington State; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Washington_(state);
  The confusions set is : Washington_State_University(ranker score=0.18285258052497955) Vs: Washington(ranker score=0.4025302941990771);
  The context is: ; ------- ; the timetable but the judge said, well, I am going to make everybody equally unhappy.   Thank you. NPR's Steven Inksi reporting from Tallahassee, Florida. As the battle over votes goes on in Florida, Washington State is in the middle of recounting the votes cast in its very tight US Senate race. Jennifer Nesan reports from member station KPLU in Seattle.   The recount of the votes cast for Democra
Level: Relational Coherence Correct Wikification of: Jennifer Nesan to : http://en.wikipedia.org/wiki/*null*
Level: Relational Coherence : Still Incorrect Wikification of: Seattle; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Seattle ; the gold is: http://en.wikipedia.org/wiki/*null*;
  The confusions set is : Seattle_Seahawks(ranker score=0.014175715837661373) Vs: Seattle(ranker score=0.9163624600621182);
  The context is: ; ------- ; orida. As the battle over votes goes on in Florida, Washington State is in the middle of recounting the votes cast in its very tight US Senate race. Jennifer Nesan reports from member station KPLU in Seattle.   The recount of the votes cast for Democrat Maria Catwell and Republican Senator Slate Gordon is calm and organized. The State's Elections Director Garry Macintosh says the process is about 
Annotation at test time--721 milliseconds elapsed to annotate the document PRI20001128.2000.0055
Final System Output:Correct Wikification of: NPR news to : http://en.wikipedia.org/wiki/NPR
Candidates Entropy: 0.0
Final System Output:: Still Incorrect Wikification of: Washington; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Washington ; the gold is: http://en.wikipedia.org/wiki/Washington,_D.C.;
  The confusions set is : Washington,_D.C.(ranker score=0.1323994534444706) Vs: Washington(ranker score=0.7262775619883165);
  The context is: ; ------- ;  Documented. From NPR news in Washington, I'm Corey Flintoff. A Florida State judge has ordered local election officials to ship thousands of ballots to the state capital. The move comes as the judge decides whether to order a rec
Candidates Entropy: 1.1761042274040645
Final System Output:Correct Wikification of: Steve Inski to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Miami Dade County to : http://en.wikipedia.org/wiki/Miami-Dade_County,_Florida
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Democrats to : http://en.wikipedia.org/wiki/Democratic_Party_(United_States)
Candidates Entropy: 0.1642706002010131
Final System Output:Correct Wikification of: Palm Beach County to : http://en.wikipedia.org/wiki/Palm_Beach_County,_Florida
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Al Gore to : http://en.wikipedia.org/wiki/Al_Gore
Candidates Entropy: 0.0
Final System Output:: Still Incorrect Wikification of: Washington State; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Washington_(state);
  The confusions set is : Washington_State_University(ranker score=0.18285258052497955) Vs: Washington(ranker score=0.4025302941990771);
  The context is: ; ------- ; the timetable but the judge said, well, I am going to make everybody equally unhappy.   Thank you. NPR's Steven Inksi reporting from Tallahassee, Florida. As the battle over votes goes on in Florida, Washington State is in the middle of recounting the votes cast in its very tight US Senate race. Jennifer Nesan reports from member station KPLU in Seattle.   The recount of the votes cast for Democra
Candidates Entropy: 1.8655800996301048
Final System Output:Correct Wikification of: Jennifer Nesan to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Final System Output:: Still Incorrect Wikification of: NIL [NER, LOC]Entity:Seattle; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Seattle ; the gold is: http://en.wikipedia.org/wiki/*null*;
  The confusions set is : Seattle_Seahawks(ranker score=0.014175715837661373) Vs: Seattle(ranker score=0.9163624600621182);
  The context is: ; ------- ; orida. As the battle over votes goes on in Florida, Washington State is in the middle of recounting the votes cast in its very tight US Senate race. Jennifer Nesan reports from member station KPLU in Seattle.   The recount of the votes cast for Democrat Maria Catwell and Republican Senator Slate Gordon is calm and organized. The State's Elections Director Garry Macintosh says the process is about 
Candidates Entropy: 0.521107182178412
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/PRI20001128.2000.0055.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/20001115_AFP_ARB.0184.eng
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =334
		- Total unique tokens  =188
		- Total unique tokens ignore case =182
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =15
		- OOV tokens, no repetitions, Case Sensitive =5
		- Total OOV tokens even after lowercasing  =15
		- OOV tokens even after lowercasing, no repetition  =5
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =24
		- OOV tokens, no repetitions, Case Sensitive =11
		- Total OOV tokens even after lowercasing  =23
		- OOV tokens even after lowercasing, no repetition  =10
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =5
		- OOV tokens, no repetitions, Case Sensitive =3
		- Total OOV tokens even after lowercasing  =5
		- OOV tokens even after lowercasing, no repetition  =3
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 451 milliseconds
Constructing a problem for the following text: 
  Jerusalem 11-15 (AFP) -  Official Israeli radio reported that the lesser security cabinet which met this evening Wednesday has made a series of practical decisions pointing to its desire to avoid...
Annotating mention view..
0 milliseconds elapsed on constructing the TF-IDF representation of the input text...20001115_AFP_ARB.0184.eng
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Adding NER candidates for 20001115_AFP_ARB.0184.eng
Adding SHALLOW_PARSE and subChunk candidates for 20001115_AFP_ARB.0184.eng
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Matched regex entity Israelis in the West Bank and Gaza Strip[1266-1306]{221-229}
Matched regex entity West Bank and Gaza Strip[1282-1306]{224-229}
Matched regex entity Bank and Gaza Strip[1287-1306]{225-229}
Matched regex entity Hussein Abiyat[1408-1422]{250-252}
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Done constructing the Wikifiable entities
     ----  almost there....
250 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...20001115_AFP_ARB.0184.eng
Inference on the document  -- 20001115_AFP_ARB.0184.eng
2 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
4 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
63 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
7 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
157 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
5 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: Jerusalem to : http://en.wikipedia.org/wiki/Jerusalem
Level:FeatureExtractorCoherenceCorrect Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level:FeatureExtractorCoherenceCorrect Wikification of: Hussein Abiyat to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: West Bank to : http://en.wikipedia.org/wiki/West_Bank
Level:FeatureExtractorCoherenceCorrect Wikification of: Jerusalem to : http://en.wikipedia.org/wiki/Jerusalem
Level:FeatureExtractorCoherenceCorrect Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level:FeatureExtractorCoherenceCorrect Wikification of: Hussein Abiyat to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: West Bank to : http://en.wikipedia.org/wiki/West_Bank
Could not find WikiMatchData for title Kalateh-ye_Shir
Could not find WikiMatchData for title Kalateh-ye_Shir
Could not find WikiMatchData for title Political_opportunity
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Prime_Minister_of_Israel, pred=shortDescription, arg2=Ehud_Barak, score=40.56706771850586, normalizedScore=100.0]For surfaces Prime Minister and Ehud Barak
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=President_of_the_Palestinian_National_Authority, pred=WIKI_LINK_RELATION, arg2=Yasser_Arafat, score=8.702546310424804, normalizedScore=100.0]For surfaces Palestinian President and Yasser Arafat
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Palestinian_National_Authority, pred=WIKI_LINK_RELATION, arg2=Gaza_Strip, score=10.767663097381597, normalizedScore=100.0]For surfaces West Bank and Gaza and Strip
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Jalaad Shir[729-740]{125-127} === The head of the prime minister 's office
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Yasser_Arafat due to a longer mention than Arafat that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Ehud_Barak due to a longer mention than Barak that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Ehud_Barak due to a longer mention than Barak that referred to the same thing
Relational inference took 7ms
CoherenceRelation 222 [arg1=[surface=Palestinians, solution=Palestinian_people], arg2=[surface=Palestinians, solution=Palestinian_people], weight=10.0] is captured by ILP inference.
CoherenceRelation 582 [arg1=[surface=Palestinian President, solution=President_of_the_Palestinian_National_Authority], arg2=[surface=Yasser Arafat, solution=Yasser_Arafat], weight=100.0] is captured by ILP inference.
CoherenceRelation 370 [arg1=[surface=Barak, solution=Ehud_Barak], arg2=[surface=Ehud Barak, solution=Ehud_Barak], weight=10.0] is captured by ILP inference.
CoherenceRelation 1301 [arg1=[surface=West Bank and Gaza, solution=Palestinian_National_Authority], arg2=[surface=Strip, solution=Gaza_Strip], weight=50.0] is captured by ILP inference.
CoherenceRelation 729 [arg1=[surface=Shir, solution=*null*], arg2=[surface=Jalaad Shir, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 370 [arg1=[surface=Prime Minister, solution=Prime_Minister_of_Israel], arg2=[surface=Ehud Barak, solution=Ehud_Barak], weight=100.0] is captured by ILP inference.
CoherenceRelation 582 [arg1=[surface=Yasser, solution=Yasser_Arafat], arg2=[surface=Yasser Arafat, solution=Yasser_Arafat], weight=10.0] is captured by ILP inference.
CoherenceRelation 370 [arg1=[surface=Ehud, solution=Ehud_Barak], arg2=[surface=Ehud Barak, solution=Ehud_Barak], weight=10.0] is captured by ILP inference.
CoherenceRelation 1408 [arg1=[surface=Hussein, solution=*null*], arg2=[surface=Hussein Abiyat, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 1408 [arg1=[surface=Abiyat, solution=*null*], arg2=[surface=Hussein Abiyat, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 370 [arg1=[surface=Barak, solution=Ehud_Barak], arg2=[surface=Ehud Barak, solution=Ehud_Barak], weight=10.0] is captured by ILP inference.
CoherenceRelation 582 [arg1=[surface=Arafat, solution=Yasser_Arafat], arg2=[surface=Yasser Arafat, solution=Yasser_Arafat], weight=10.0] is captured by ILP inference.
CoherenceRelation 729 [arg1=[surface=Shir, solution=*null*], arg2=[surface=Jalaad Shir, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 370 [arg1=[surface=Barak, solution=Ehud_Barak], arg2=[surface=Ehud Barak, solution=Ehud_Barak], weight=10.0] is captured by ILP inference.
CoherenceRelation 582 [arg1=[surface=Arafat, solution=Yasser_Arafat], arg2=[surface=Yasser Arafat, solution=Yasser_Arafat], weight=10.0] is captured by ILP inference.
Discarded 10 hypothesis
Level: Relational Coherence Correct Wikification of: Jerusalem to : http://en.wikipedia.org/wiki/Jerusalem
Level: Relational Coherence Correct Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level: Relational Coherence Correct Wikification of: Hussein Abiyat to : http://en.wikipedia.org/wiki/*null*
Level: Relational Coherence Correct Wikification of: West Bank to : http://en.wikipedia.org/wiki/West_Bank
Annotation at test time--413 milliseconds elapsed to annotate the document 20001115_AFP_ARB.0184.eng
Final System Output:Correct Wikification of: Jerusalem to : http://en.wikipedia.org/wiki/Jerusalem
Candidates Entropy: 0.07518128542119962
Final System Output:Correct Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Candidates Entropy: 0.6546762466951381
Final System Output:Correct Wikification of: Hussein Abiyat to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: West Bank to : http://en.wikipedia.org/wiki/West_Bank
Candidates Entropy: 0.019613467003134537
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/20001115_AFP_ARB.0184.eng.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/APW20001130.2108.0849
Empty problem - no reference instances!!!
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/20001115_AFP_ARB.0060.eng
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =524
		- Total unique tokens  =247
		- Total unique tokens ignore case =243
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =21
		- OOV tokens, no repetitions, Case Sensitive =5
		- Total OOV tokens even after lowercasing  =21
		- OOV tokens even after lowercasing, no repetition  =5
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =43
		- OOV tokens, no repetitions, Case Sensitive =14
		- Total OOV tokens even after lowercasing  =42
		- OOV tokens even after lowercasing, no repetition  =13
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =21
		- OOV tokens, no repetitions, Case Sensitive =8
		- Total OOV tokens even after lowercasing  =20
		- OOV tokens even after lowercasing, no repetition  =7
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 576 milliseconds
Constructing a problem for the following text: 
  Bandar Seri Begawan 11-15 (AFP) -  A high-level American official announced today Wednesday in the wake of the meeting between American President Bill Clinton and his Russian counterpart Vladimir...
Annotating mention view..
1 milliseconds elapsed on constructing the TF-IDF representation of the input text...20001115_AFP_ARB.0060.eng
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Adding NER candidates for 20001115_AFP_ARB.0060.eng
Adding SHALLOW_PARSE and subChunk candidates for 20001115_AFP_ARB.0060.eng
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Matched regex entity Russian and American[243-263]{39-42}
Matched regex entity Clinton and Putin[621-638]{106-109}
Matched regex entity Sultanate of Brunei[751-770]{129-132}
Matched regex entity United States and Russia[964-988]{168-172}
Matched regex entity States and Russia[971-988]{169-172}
Matched regex entity Russian and American[1094-1114]{190-193}
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Done constructing the Wikifiable entities
     ----  almost there....
505 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...20001115_AFP_ARB.0060.eng
Inference on the document  -- 20001115_AFP_ARB.0060.eng
3 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
6 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
98 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
11 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
332 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
5 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: Bandar Seri Begawan to : http://en.wikipedia.org/wiki/Bandar_Seri_Begawan
Level:FeatureExtractorCoherenceCorrect Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level:FeatureExtractorCoherenceCorrect Wikification of: Sultanate of Brunei to : http://en.wikipedia.org/wiki/Brunei
Level:FeatureExtractorCoherenceCorrect Wikification of: Iran to : http://en.wikipedia.org/wiki/Iran
Level:FeatureExtractorCoherenceCorrect Wikification of: Bandar Seri Begawan to : http://en.wikipedia.org/wiki/Bandar_Seri_Begawan
Level:FeatureExtractorCoherenceCorrect Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level:FeatureExtractorCoherenceCorrect Wikification of: Sultanate of Brunei to : http://en.wikipedia.org/wiki/Brunei
Level:FeatureExtractorCoherenceCorrect Wikification of: Iran to : http://en.wikipedia.org/wiki/Iran
Could not find WikiMatchData for title The_United
Could not find WikiMatchData for title The_United
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=President_of_the_United_States, pred=WIKI_LINK_RELATION, arg2=Bill_Clinton, score=7.646950435638427, normalizedScore=100.0]For surfaces American President and Bill Clinton
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Russians, pred=populationPlace, arg2=United_States, score=6.731627988815307, normalizedScore=0.18451689614594516]For surfaces Russian and American
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Russian_American, pred=WIKI_LINK_RELATION, arg2=United_States, score=3.8561918735504146, normalizedScore=0.10381949998978927]For surfaces Russian and American
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Russian_Empire, pred=WIKI_LINK_RELATION, arg2=United_States, score=1.9280959367752075, normalizedScore=0.07060031645865454]For surfaces Russian and American
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Russian_language, pred=WIKI_LINK_RELATION, arg2=United_States, score=1.9280959367752075, normalizedScore=0.07060031645865454]For surfaces Russian and American
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Hillary_Rodham_Clinton, pred=WIKI_LINK_RELATION, arg2=Vladimir_Putin, score=1.6755067110061646, normalizedScore=100.0]For surfaces Clinton and Putin
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Russian_language, pred=WIKI_LINK_RELATION, arg2=United_States, score=1.9280959367752075, normalizedScore=100.0]For surfaces Russian and American
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Vladimir Putin[189-203]{30-32} === his Russian counterpart
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Vladimir_Putin due to a longer mention than Putin that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Vladimir_Putin due to a longer mention than Putin that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Vladimir_Putin due to a longer mention than Putin that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Vladimir_Putin due to a longer mention than Putin that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Vladimir_Putin due to a longer mention than Putin that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Vladimir_Putin due to a longer mention than Putin that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Vladimir_Putin due to a longer mention than Putin that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Vladimir_Putin due to a longer mention than Putin that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bill_Clinton due to a longer mention than Clinton that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bill_Clinton due to a longer mention than Clinton that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bill_Clinton due to a longer mention than Clinton that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bill_Clinton due to a longer mention than Clinton that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bill_Clinton due to a longer mention than Clinton that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bill_Clinton due to a longer mention than Clinton that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Asia-Pacific_Economic_Cooperation due to a longer mention than APEC that referred to the same thing
Relational inference took 11ms
CoherenceRelation 189 [arg1=[surface=Putin, solution=Vladimir_Putin], arg2=[surface=Vladimir Putin, solution=Vladimir_Putin], weight=10.0] is captured by ILP inference.
CoherenceRelation 1907 [arg1=[surface=George, solution=George_W._Bush], arg2=[surface=George Bush Junior, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 751 [arg1=[surface=Sultanate, solution=Brunei], arg2=[surface=Sultanate of Brunei, solution=Brunei], weight=10.0] is captured by ILP inference.
CoherenceRelation 1907 [arg1=[surface=Bush Junior, solution=George_W._Bush], arg2=[surface=George Bush Junior, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 2671 [arg1=[surface=Edmond, solution=*null*], arg2=[surface=Edmond Bob, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 148 [arg1=[surface=American President, solution=President_of_the_United_States], arg2=[surface=Bill Clinton, solution=Bill_Clinton], weight=100.0] is captured by ILP inference.
CoherenceRelation 255 [arg1=[surface=Russian, solution=Russian_language], arg2=[surface=American, solution=United_States], weight=0.03530015822932727] is captured by ILP inference.
CoherenceRelation 1907 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George Bush Junior, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 1575 [arg1=[surface=NMD, solution=Missile_defense_systems_of_various_nations], arg2=[surface=NMD, solution=Missile_defense_systems_of_various_nations], weight=10.0] is captured by ILP inference.
CoherenceRelation 1907 [arg1=[surface=George Bush, solution=George_W._Bush], arg2=[surface=George Bush Junior, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 1106 [arg1=[surface=Russian, solution=Russian_language], arg2=[surface=American, solution=United_States], weight=50.0] is captured by ILP inference.
CoherenceRelation 148 [arg1=[surface=Clinton, solution=Bill_Clinton], arg2=[surface=Bill Clinton, solution=Bill_Clinton], weight=10.0] is captured by ILP inference.
CoherenceRelation 189 [arg1=[surface=Putin, solution=Vladimir_Putin], arg2=[surface=Vladimir Putin, solution=Vladimir_Putin], weight=10.0] is captured by ILP inference.
CoherenceRelation 189 [arg1=[surface=Putin, solution=Vladimir_Putin], arg2=[surface=Vladimir Putin, solution=Vladimir_Putin], weight=10.0] is captured by ILP inference.
CoherenceRelation 138 [arg1=[surface=Bill Clinton, solution=Bill_Clinton], arg2=[surface=President Bill Clinton, solution=Bill_Clinton], weight=10.0] is captured by ILP inference.
CoherenceRelation 1230 [arg1=[surface=Russian-American, solution=Russian_American], arg2=[surface=Russian-American, solution=Russian_American], weight=10.0] is captured by ILP inference.
CoherenceRelation 148 [arg1=[surface=Clinton, solution=Bill_Clinton], arg2=[surface=Bill Clinton, solution=Bill_Clinton], weight=10.0] is captured by ILP inference.
CoherenceRelation 2671 [arg1=[surface=Bob, solution=*null*], arg2=[surface=Edmond Bob, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 189 [arg1=[surface=Vladimir, solution=Vladimir_Putin], arg2=[surface=Vladimir Putin, solution=Vladimir_Putin], weight=10.0] is captured by ILP inference.
CoherenceRelation 1575 [arg1=[surface=NMD, solution=Missile_defense_systems_of_various_nations], arg2=[surface=NMD, solution=Missile_defense_systems_of_various_nations], weight=10.0] is captured by ILP inference.
CoherenceRelation 1670 [arg1=[surface=States, solution=United_States], arg2=[surface=The United States, solution=United_States], weight=10.0] is captured by ILP inference.
CoherenceRelation 189 [arg1=[surface=Putin, solution=Vladimir_Putin], arg2=[surface=Vladimir Putin, solution=Vladimir_Putin], weight=10.0] is captured by ILP inference.
CoherenceRelation 189 [arg1=[surface=Putin, solution=Vladimir_Putin], arg2=[surface=Vladimir Putin, solution=Vladimir_Putin], weight=10.0] is captured by ILP inference.
CoherenceRelation 189 [arg1=[surface=Putin, solution=Vladimir_Putin], arg2=[surface=Vladimir Putin, solution=Vladimir_Putin], weight=10.0] is captured by ILP inference.
CoherenceRelation 148 [arg1=[surface=Clinton, solution=Bill_Clinton], arg2=[surface=Bill Clinton, solution=Bill_Clinton], weight=10.0] is captured by ILP inference.
CoherenceRelation 148 [arg1=[surface=Clinton, solution=Bill_Clinton], arg2=[surface=Bill Clinton, solution=Bill_Clinton], weight=10.0] is captured by ILP inference.
CoherenceRelation 148 [arg1=[surface=Clinton, solution=Bill_Clinton], arg2=[surface=Bill Clinton, solution=Bill_Clinton], weight=10.0] is captured by ILP inference.
CoherenceRelation 148 [arg1=[surface=Clinton, solution=Bill_Clinton], arg2=[surface=Bill Clinton, solution=Bill_Clinton], weight=10.0] is captured by ILP inference.
CoherenceRelation 2751 [arg1=[surface=States, solution=United_States], arg2=[surface=The United States, solution=United_States], weight=10.0] is captured by ILP inference.
CoherenceRelation 1907 [arg1=[surface=Junior, solution=George_W._Bush], arg2=[surface=George Bush Junior, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 189 [arg1=[surface=Putin, solution=Vladimir_Putin], arg2=[surface=Vladimir Putin, solution=Vladimir_Putin], weight=10.0] is captured by ILP inference.
CoherenceRelation 189 [arg1=[surface=Putin, solution=Vladimir_Putin], arg2=[surface=Vladimir Putin, solution=Vladimir_Putin], weight=10.0] is captured by ILP inference.
CoherenceRelation 189 [arg1=[surface=Putin, solution=Vladimir_Putin], arg2=[surface=Vladimir Putin, solution=Vladimir_Putin], weight=10.0] is captured by ILP inference.
CoherenceRelation 662 [arg1=[surface=APEC, solution=Asia-Pacific_Economic_Cooperation], arg2=[surface=Asia-Pacific Economic Cooperation, solution=Asia-Pacific_Economic_Cooperation], weight=10.0] is captured by ILP inference.
Discarded 12 hypothesis
Level: Relational Coherence Correct Wikification of: Bandar Seri Begawan to : http://en.wikipedia.org/wiki/Bandar_Seri_Begawan
Level: Relational Coherence Correct Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level: Relational Coherence Correct Wikification of: Sultanate of Brunei to : http://en.wikipedia.org/wiki/Brunei
Level: Relational Coherence Correct Wikification of: Iran to : http://en.wikipedia.org/wiki/Iran
Annotation at test time--811 milliseconds elapsed to annotate the document 20001115_AFP_ARB.0060.eng
Final System Output:Correct Wikification of: Bandar Seri Begawan to : http://en.wikipedia.org/wiki/Bandar_Seri_Begawan
Candidates Entropy: 0.11858020358179253
Final System Output:Correct Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Candidates Entropy: 1.728428981915175
Final System Output:Correct Wikification of: Sultanate of Brunei to : http://en.wikipedia.org/wiki/Brunei
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Iran to : http://en.wikipedia.org/wiki/Iran
Candidates Entropy: 0.23225868961129092
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/20001115_AFP_ARB.0060.eng.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/APW20001127.1346.0419
Empty problem - no reference instances!!!
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/chtb_227.eng
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =213
		- Total unique tokens  =109
		- Total unique tokens ignore case =105
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =5
		- OOV tokens, no repetitions, Case Sensitive =4
		- Total OOV tokens even after lowercasing  =5
		- OOV tokens even after lowercasing, no repetition  =4
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =8
		- OOV tokens, no repetitions, Case Sensitive =7
		- Total OOV tokens even after lowercasing  =7
		- OOV tokens even after lowercasing, no repetition  =6
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =3
		- OOV tokens, no repetitions, Case Sensitive =3
		- Total OOV tokens even after lowercasing  =2
		- OOV tokens even after lowercasing, no repetition  =2
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 211 milliseconds
Constructing a problem for the following text: 
  Xinhua News Agency, Moscow, August 31st, by reporter Rong Xie  Presidents of 3 Baltic Sea countries issued a joint statement on August 31st, pointing out that Russia's withdrawal of troops from t...
Annotating mention view..
0 milliseconds elapsed on constructing the TF-IDF representation of the input text...chtb_227.eng
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Adding NER candidates for chtb_227.eng
Adding SHALLOW_PARSE and subChunk candidates for chtb_227.eng
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Matched regex entity Moscow, August[22-36]{4-7}
Matched regex entity Russian and Baltic Sea[385-407]{65-69}
Matched regex entity International Correspondence Communication News Agency[841-895]{140-145}
Matched regex entity Correspondence Communication News Agency[855-895]{141-145}
Matched regex entity Communication News Agency[870-895]{142-145}
Matched regex entity Russia's Foreign Affairs[934-958]{153-157}
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Done constructing the Wikifiable entities
     ----  almost there....
287 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...chtb_227.eng
Inference on the document  -- chtb_227.eng
1 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
3 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
49 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
5 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
68 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
3 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: International Correspondence Communication News Agency to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Klelov to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: International Correspondence Communication News Agency to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Klelov to : http://en.wikipedia.org/wiki/*null*
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Moscow, pred=WIKI_LINK_RELATION, arg2=August_31, score=2.9165728092193604, normalizedScore=100.0]For surfaces Moscow and August 31st
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Russian_Empire, pred=WIKI_LINK_RELATION, arg2=Baltic_region, score=1.8349860906600952, normalizedScore=100.0]For surfaces Russian and Baltic Sea countries
Relational inference took 5ms
CoherenceRelation 30 [arg1=[surface=Moscow, solution=Moscow], arg2=[surface=August 31st, solution=August_31], weight=100.0] is captured by ILP inference.
CoherenceRelation 397 [arg1=[surface=Russian, solution=Russian_Empire], arg2=[surface=Baltic Sea countries, solution=Baltic_region], weight=50.0] is captured by ILP inference.
CoherenceRelation 2 [arg1=[surface=Agency, solution=Xinhua_News_Agency], arg2=[surface=Xinhua News Agency, solution=Xinhua_News_Agency], weight=10.0] is captured by ILP inference.
Discarded 0 hypothesis
Level: Relational Coherence Correct Wikification of: International Correspondence Communication News Agency to : http://en.wikipedia.org/wiki/*null*
Level: Relational Coherence Correct Wikification of: Klelov to : http://en.wikipedia.org/wiki/*null*
Annotation at test time--424 milliseconds elapsed to annotate the document chtb_227.eng
Final System Output:Correct Wikification of: International Correspondence Communication News Agency to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Klelov to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/chtb_227.eng.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/APW20001002.0615.0146
Empty problem - no reference instances!!!
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/PRI20001122.2000.0320
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =72
		- Total unique tokens  =54
		- Total unique tokens ignore case =53
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =0
		- OOV tokens, no repetitions, Case Sensitive =0
		- Total OOV tokens even after lowercasing  =0
		- OOV tokens even after lowercasing, no repetition  =0
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =5
		- OOV tokens, no repetitions, Case Sensitive =5
		- Total OOV tokens even after lowercasing  =5
		- OOV tokens even after lowercasing, no repetition  =5
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =3
		- OOV tokens, no repetitions, Case Sensitive =3
		- Total OOV tokens even after lowercasing  =3
		- OOV tokens even after lowercasing, no repetition  =3
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 55 milliseconds
Constructing a problem for the following text: 
 The Palestinian faction headed by Yasser Arafat said today that, it will avenge the deaths of four of its members who were killed today by Israeli soldiers. Later in the day, a car bombing in the ...
0 milliseconds elapsed on constructing the TF-IDF representation of the input text...PRI20001122.2000.0320
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Annotating mention view..
Getting the text annotation
Adding NER candidates for PRI20001122.2000.0320
Adding SHALLOW_PARSE and subChunk candidates for PRI20001122.2000.0320
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Matched regex entity Corey Flintoff, NPR[332-351]{64-68}
Matched regex entity Flintoff, NPR[338-351]{65-68}
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Done constructing the Wikifiable entities
     ----  almost there....
108 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...PRI20001122.2000.0320
Inference on the document  -- PRI20001122.2000.0320
0 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
1 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
19 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
2 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
7 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
2 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: Yasser Arafat to : http://en.wikipedia.org/wiki/Yasser_Arafat
Level:FeatureExtractorCoherenceCorrect Wikification of: Corey Flintoff to : http://en.wikipedia.org/wiki/Corey_Flintoff
Level:FeatureExtractorCoherenceCorrect Wikification of: NPR news to : http://en.wikipedia.org/wiki/NPR
Level:FeatureExtractorCoherenceCorrect Wikification of: Yasser Arafat to : http://en.wikipedia.org/wiki/Yasser_Arafat
Level:FeatureExtractorCoherenceCorrect Wikification of: Corey Flintoff to : http://en.wikipedia.org/wiki/Corey_Flintoff
Level:FeatureExtractorCoherenceCorrect Wikification of: NPR news to : http://en.wikipedia.org/wiki/NPR
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Washington; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Washington,_D.C.;
  The confusions set is : Washington,_D.C.(ranker score=2.186543318088264) Vs: Washington(ranker score=2.7476008373988177);
  The context is: ; ------- ; Later in the day, a car bombing in the Northern Israeli town of Hadera, killed two people and injured at least 50. Israeli Prime Minister Ehud Barak said he would retaliate. Corey Flintoff, NPR news, Washington.  
Could not find WikiMatchData for title The_Palestinian
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Prime_Minister_of_Israel, pred=shortDescription, arg2=Ehud_Barak, score=26.659513092041017, normalizedScore=100.0]For surfaces Israeli Prime Minister and Ehud Barak
Relational inference took 2ms
CoherenceRelation 332 [arg1=[surface=Flintoff, solution=Corey_Flintoff], arg2=[surface=Corey Flintoff, solution=Corey_Flintoff], weight=10.0] is captured by ILP inference.
CoherenceRelation 35 [arg1=[surface=Arafat, solution=Yasser_Arafat], arg2=[surface=Yasser Arafat, solution=Yasser_Arafat], weight=10.0] is captured by ILP inference.
CoherenceRelation 296 [arg1=[surface=Ehud, solution=Ehud_Barak], arg2=[surface=Ehud Barak, solution=Ehud_Barak], weight=10.0] is captured by ILP inference.
CoherenceRelation 296 [arg1=[surface=Barak, solution=Ehud_Barak], arg2=[surface=Ehud Barak, solution=Ehud_Barak], weight=10.0] is captured by ILP inference.
CoherenceRelation 296 [arg1=[surface=Israeli Prime Minister, solution=Prime_Minister_of_Israel], arg2=[surface=Ehud Barak, solution=Ehud_Barak], weight=100.0] is captured by ILP inference.
CoherenceRelation 35 [arg1=[surface=Yasser, solution=Yasser_Arafat], arg2=[surface=Yasser Arafat, solution=Yasser_Arafat], weight=10.0] is captured by ILP inference.
CoherenceRelation 332 [arg1=[surface=Corey, solution=Corey_Flintoff], arg2=[surface=Corey Flintoff, solution=Corey_Flintoff], weight=10.0] is captured by ILP inference.
Discarded 0 hypothesis
Level: Relational Coherence Correct Wikification of: Yasser Arafat to : http://en.wikipedia.org/wiki/Yasser_Arafat
Level: Relational Coherence Correct Wikification of: Corey Flintoff to : http://en.wikipedia.org/wiki/Corey_Flintoff
Level: Relational Coherence Correct Wikification of: NPR news to : http://en.wikipedia.org/wiki/NPR
Level: Relational Coherence : Still Incorrect Wikification of: Washington; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Washington,_D.C.;
  The confusions set is : Washington,_D.C.(ranker score=0.20991551547515921) Vs: Washington(ranker score=0.3678821571755877);
  The context is: ; ------- ; Later in the day, a car bombing in the Northern Israeli town of Hadera, killed two people and injured at least 50. Israeli Prime Minister Ehud Barak said he would retaliate. Corey Flintoff, NPR news, Washington.  
Annotation at test time--125 milliseconds elapsed to annotate the document PRI20001122.2000.0320
Final System Output:Correct Wikification of: Yasser Arafat to : http://en.wikipedia.org/wiki/Yasser_Arafat
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Corey Flintoff to : http://en.wikipedia.org/wiki/Corey_Flintoff
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: NPR news to : http://en.wikipedia.org/wiki/NPR
Candidates Entropy: 0.0
Final System Output:: Still Incorrect Wikification of: Washington; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Washington,_D.C.;
  The confusions set is : Washington,_D.C.(ranker score=0.20991551547515921) Vs: Washington(ranker score=0.3678821571755877);
  The context is: ; ------- ; Later in the day, a car bombing in the Northern Israeli town of Hadera, killed two people and injured at least 50. Israeli Prime Minister Ehud Barak said he would retaliate. Corey Flintoff, NPR news, Washington.  
Candidates Entropy: 2.2798478944370073
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/PRI20001122.2000.0320.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/NYT20001124.2050.0257
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =817
		- Total unique tokens  =374
		- Total unique tokens ignore case =353
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =35
		- OOV tokens, no repetitions, Case Sensitive =13
		- Total OOV tokens even after lowercasing  =34
		- OOV tokens even after lowercasing, no repetition  =12
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =48
		- OOV tokens, no repetitions, Case Sensitive =18
		- Total OOV tokens even after lowercasing  =47
		- OOV tokens even after lowercasing, no repetition  =17
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =23
		- OOV tokens, no repetitions, Case Sensitive =16
		- Total OOV tokens even after lowercasing  =21
		- OOV tokens even after lowercasing, no repetition  =14
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 886 milliseconds
Critical warning: word 's is not found in the text 
Critical warning: word 's is not found in the text 
Critical warning: word 's is not found in the text 
Constructing a problem for the following text: 
 ECONOMISTS &LR; &QL; &UR; By MARK LANDLER &LR; &QC; &QL; &UR; c.2000 N.Y. Times News Service &LR; &QC; &QL;    HONG KONG _ For most of this year, Asia's economies have performed a sort of levitati...
Annotating mention view..
1 milliseconds elapsed on constructing the TF-IDF representation of the input text...NYT20001124.2050.0257
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Adding NER candidates for NYT20001124.2050.0257
Adding SHALLOW_PARSE and subChunk candidates for NYT20001124.2050.0257
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Matched regex entity Taiwan, and Indonesia[1089-1110]{221-225}
Matched regex entity Malaysia and South Korea, Robinson[1358-1392]{273-279}
Matched regex entity South Korea, Robinson[1371-1392]{275-279}
Matched regex entity On Tuesday, South Korea[1772-1795]{345-350}
Matched regex entity Tuesday, South Korea[1775-1795]{346-350}
Matched regex entity Malaysia, and Singapore[1955-1978]{376-380}
Matched regex entity Hong Kong General Chamber of Commerce[2673-2710]{501-507}
Matched regex entity Robinson of the IMF[3175-3194]{598-602}
Matched regex entity In October, the IMF[3231-3250]{609-614}
Matched regex entity October, the IMF[3234-3250]{610-614}
Matched regex entity On Friday, Robinson[3363-3382]{636-640}
Matched regex entity Friday, Robinson[3366-3382]{637-640}
Matched regex entity Like Perkin, Robinson[4090-4111]{768-772}
Matched regex entity Perkin, Robinson[4095-4111]{769-772}
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Done constructing the Wikifiable entities
     ----  almost there....
594 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...NYT20001124.2050.0257
Inference on the document  -- NYT20001124.2050.0257
4 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
6 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
152 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
17 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
392 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
4 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: HONG KONG to : http://en.wikipedia.org/wiki/Hong_Kong
Level:FeatureExtractorCoherenceCorrect Wikification of: Asia to : http://en.wikipedia.org/wiki/Asia
Level:FeatureExtractorCoherenceCorrect Wikification of: International Monetary Fund to : http://en.wikipedia.org/wiki/International_Monetary_Fund
Level:FeatureExtractorCoherenceCorrect Wikification of: Philippines to : http://en.wikipedia.org/wiki/Philippines
Level:FeatureExtractorCoherenceCorrect Wikification of: Taiwan to : http://en.wikipedia.org/wiki/Taiwan
Level:FeatureExtractorCoherenceCorrect Wikification of: Indonesia to : http://en.wikipedia.org/wiki/Indonesia
Level:FeatureExtractorCoherenceCorrect Wikification of: Chen Shui-bian to : http://en.wikipedia.org/wiki/Chen_Shui-bian
Level:FeatureExtractorCoherenceCorrect Wikification of: Malaysia to : http://en.wikipedia.org/wiki/Malaysia
Level:FeatureExtractorCoherenceCorrect Wikification of: South Korea to : http://en.wikipedia.org/wiki/South_Korea
Level:FeatureExtractorCoherenceCorrect Wikification of: Singapore to : http://en.wikipedia.org/wiki/Singapore
Level:FeatureExtractorCoherenceCorrect Wikification of: Bloomberg News to : http://en.wikipedia.org/wiki/Bloomberg_Television
Level:FeatureExtractorCoherenceCorrect Wikification of: United States to : http://en.wikipedia.org/wiki/United_States
Level:FeatureExtractorCoherenceCorrect Wikification of: China to : http://en.wikipedia.org/wiki/China
Level:FeatureExtractorCoherenceCorrect Wikification of: Ian Perkin to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Hong Kong General Chamber of Commerce to : http://en.wikipedia.org/wiki/Hong_Kong_General_Chamber_of_Commerce
Level:FeatureExtractorCoherenceCorrect Wikification of: HONG KONG to : http://en.wikipedia.org/wiki/Hong_Kong
Level:FeatureExtractorCoherenceCorrect Wikification of: Asia to : http://en.wikipedia.org/wiki/Asia
Level:FeatureExtractorCoherenceCorrect Wikification of: International Monetary Fund to : http://en.wikipedia.org/wiki/International_Monetary_Fund
Level:FeatureExtractorCoherenceCorrect Wikification of: David Robinson to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherencethis fixes the Wikification (!!!)David Robinson; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/*null*;
  The confusions set is : David_Robinson_(basketball)(ranker score=2.76772914079751) Vs: David_Robinson(ranker score=2.7694002124779677);
  The context is: ; ------- ;  the financial markets. The IMF said a $5 increase in the price of a barrel of oil could slow the growth rates of Asian countries next year.   ``The prospects for growth in 2001 have weakened,'' said David Robinson, assistant director of research at the fund. ``There has also been increased political instability across the world, not least in Asia.''   Several Asian countries _ notably the Philipp
Level:FeatureExtractorCoherenceCorrect Wikification of: Philippines to : http://en.wikipedia.org/wiki/Philippines
Level:FeatureExtractorCoherenceCorrect Wikification of: Taiwan to : http://en.wikipedia.org/wiki/Taiwan
Level:FeatureExtractorCoherenceCorrect Wikification of: Indonesia to : http://en.wikipedia.org/wiki/Indonesia
Level:FeatureExtractorCoherenceCorrect Wikification of: Chen Shui-bian to : http://en.wikipedia.org/wiki/Chen_Shui-bian
Level:FeatureExtractorCoherenceCorrect Wikification of: Malaysia to : http://en.wikipedia.org/wiki/Malaysia
Level:FeatureExtractorCoherenceCorrect Wikification of: South Korea to : http://en.wikipedia.org/wiki/South_Korea
Level:FeatureExtractorCoherenceCorrect Wikification of: Singapore to : http://en.wikipedia.org/wiki/Singapore
Level:FeatureExtractorCoherenceCorrect Wikification of: Bloomberg News to : http://en.wikipedia.org/wiki/Bloomberg_Television
Level:FeatureExtractorCoherenceCorrect Wikification of: United States to : http://en.wikipedia.org/wiki/United_States
Level:FeatureExtractorCoherenceCorrect Wikification of: China to : http://en.wikipedia.org/wiki/China
Level:FeatureExtractorCoherenceCorrect Wikification of: Ian Perkin to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Hong Kong General Chamber of Commerce to : http://en.wikipedia.org/wiki/Hong_Kong_General_Chamber_of_Commerce
Could not find WikiMatchData for title Haphazard
Could not find WikiMatchData for title Economic_Outlook
Could not find WikiMatchData for title Bright_spot
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Taiwan, pred=WIKI_LINK_RELATION, arg2=Indonesia, score=4.075064325332642, normalizedScore=100.0]For surfaces Taiwan and Indonesia
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Malaysia, pred=WIKI_LINK_RELATION, arg2=Singapore, score=10.527038745880127, normalizedScore=100.0]For surfaces Malaysia and Singapore
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:David Robinson[883-897]{184-186} === assistant director of research at the fund
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - Force linking David Robinson[883-897]{184-186} to null
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Joseph Estrada[1195-1209]{240-242} === The Philippines president
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Chen Shui-bian[1242-1256]{249-251} === the president of Taiwan
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting International_Monetary_Fund due to a longer mention than IMF that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting International_Monetary_Fund due to a longer mention than IMF that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting International_Monetary_Fund due to a longer mention than IMF that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting International_Monetary_Fund due to a longer mention than IMF that referred to the same thing
Relational inference took 10ms
CoherenceRelation 1101 [arg1=[surface=Taiwan, solution=Taiwan], arg2=[surface=Indonesia, solution=Indonesia], weight=50.0] is captured by ILP inference.
CoherenceRelation 883 [arg1=[surface=Robinson, solution=*null*], arg2=[surface=David Robinson, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 1969 [arg1=[surface=Malaysia, solution=Malaysia], arg2=[surface=Singapore, solution=Singapore], weight=50.0] is captured by ILP inference.
CoherenceRelation 2638 [arg1=[surface=Perkin, solution=*null*], arg2=[surface=Ian Perkin, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 883 [arg1=[surface=Robinson, solution=*null*], arg2=[surface=David Robinson, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 883 [arg1=[surface=Robinson, solution=*null*], arg2=[surface=David Robinson, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 883 [arg1=[surface=Robinson, solution=*null*], arg2=[surface=David Robinson, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 2638 [arg1=[surface=Perkin, solution=*null*], arg2=[surface=Ian Perkin, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 552 [arg1=[surface=IMF, solution=International_Monetary_Fund], arg2=[surface=International Monetary Fund, solution=International_Monetary_Fund], weight=10.0] is captured by ILP inference.
CoherenceRelation 883 [arg1=[surface=Robinson, solution=*null*], arg2=[surface=David Robinson, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 2638 [arg1=[surface=Ian, solution=*null*], arg2=[surface=Ian Perkin, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 1242 [arg1=[surface=Chen, solution=Chen_Shui-bian], arg2=[surface=Chen Shui-bian, solution=Chen_Shui-bian], weight=10.0] is captured by ILP inference.
CoherenceRelation 552 [arg1=[surface=IMF, solution=International_Monetary_Fund], arg2=[surface=International Monetary Fund, solution=International_Monetary_Fund], weight=10.0] is captured by ILP inference.
CoherenceRelation 1195 [arg1=[surface=Joseph, solution=Joseph_Estrada], arg2=[surface=Joseph Estrada, solution=Joseph_Estrada], weight=10.0] is captured by ILP inference.
CoherenceRelation 552 [arg1=[surface=IMF, solution=International_Monetary_Fund], arg2=[surface=International Monetary Fund, solution=International_Monetary_Fund], weight=10.0] is captured by ILP inference.
CoherenceRelation 2638 [arg1=[surface=Perkin, solution=*null*], arg2=[surface=Ian Perkin, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 883 [arg1=[surface=David, solution=*null*], arg2=[surface=David Robinson, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 883 [arg1=[surface=Robinson, solution=*null*], arg2=[surface=David Robinson, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 883 [arg1=[surface=Robinson, solution=*null*], arg2=[surface=David Robinson, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 1195 [arg1=[surface=Estrada, solution=Joseph_Estrada], arg2=[surface=Joseph Estrada, solution=Joseph_Estrada], weight=10.0] is captured by ILP inference.
CoherenceRelation 883 [arg1=[surface=Robinson, solution=*null*], arg2=[surface=David Robinson, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 552 [arg1=[surface=IMF, solution=International_Monetary_Fund], arg2=[surface=International Monetary Fund, solution=International_Monetary_Fund], weight=10.0] is captured by ILP inference.
Discarded 54 hypothesis
Level: Relational Coherence Correct Wikification of: HONG KONG to : http://en.wikipedia.org/wiki/Hong_Kong
Level: Relational Coherence Correct Wikification of: Asia to : http://en.wikipedia.org/wiki/Asia
Level: Relational Coherence Correct Wikification of: International Monetary Fund to : http://en.wikipedia.org/wiki/International_Monetary_Fund
Level: Relational Coherence Correct Wikification of: David Robinson to : http://en.wikipedia.org/wiki/*null*
Level: Relational Coherence Correct Wikification of: Philippines to : http://en.wikipedia.org/wiki/Philippines
Level: Relational Coherence Correct Wikification of: Taiwan to : http://en.wikipedia.org/wiki/Taiwan
Level: Relational Coherence Correct Wikification of: Indonesia to : http://en.wikipedia.org/wiki/Indonesia
Level: Relational Coherence Correct Wikification of: Chen Shui-bian to : http://en.wikipedia.org/wiki/Chen_Shui-bian
Level: Relational Coherence Correct Wikification of: Malaysia to : http://en.wikipedia.org/wiki/Malaysia
Level: Relational Coherence Correct Wikification of: South Korea to : http://en.wikipedia.org/wiki/South_Korea
Level: Relational Coherence Correct Wikification of: Singapore to : http://en.wikipedia.org/wiki/Singapore
Level: Relational Coherence Correct Wikification of: Bloomberg News to : http://en.wikipedia.org/wiki/Bloomberg_Television
Level: Relational Coherence Correct Wikification of: United States to : http://en.wikipedia.org/wiki/United_States
Level: Relational Coherence Correct Wikification of: China to : http://en.wikipedia.org/wiki/China
Level: Relational Coherence Correct Wikification of: Ian Perkin to : http://en.wikipedia.org/wiki/*null*
Level: Relational Coherence Correct Wikification of: Hong Kong General Chamber of Commerce to : http://en.wikipedia.org/wiki/Hong_Kong_General_Chamber_of_Commerce
Annotation at test time--737 milliseconds elapsed to annotate the document NYT20001124.2050.0257
Final System Output:Correct Wikification of: HONG KONG to : http://en.wikipedia.org/wiki/Hong_Kong
Candidates Entropy: 0.3217199492620594
Final System Output:Correct Wikification of: Asia to : http://en.wikipedia.org/wiki/Asia
Candidates Entropy: 0.33453138508919816
Final System Output:Correct Wikification of: International Monetary Fund to : http://en.wikipedia.org/wiki/International_Monetary_Fund
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: David Robinson to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 1.2381043202448343
Final System Output:Correct Wikification of: Philippines to : http://en.wikipedia.org/wiki/Philippines
Candidates Entropy: 0.045974940236849574
Final System Output:Correct Wikification of: Taiwan to : http://en.wikipedia.org/wiki/Taiwan
Candidates Entropy: 0.027192403329833685
Final System Output:Correct Wikification of: Indonesia to : http://en.wikipedia.org/wiki/Indonesia
Candidates Entropy: 0.0754311821275639
Final System Output:Correct Wikification of: Chen Shui-bian to : http://en.wikipedia.org/wiki/Chen_Shui-bian
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Malaysia to : http://en.wikipedia.org/wiki/Malaysia
Candidates Entropy: 0.1065806389257419
Final System Output:Correct Wikification of: South Korea to : http://en.wikipedia.org/wiki/South_Korea
Candidates Entropy: 0.21562963055172216
Final System Output:Correct Wikification of: Singapore to : http://en.wikipedia.org/wiki/Singapore
Candidates Entropy: 0.03077800324492494
Final System Output:Correct Wikification of: Bloomberg News to : http://en.wikipedia.org/wiki/Bloomberg_Television
Candidates Entropy: 0.362070228000255
Final System Output:Correct Wikification of: United States to : http://en.wikipedia.org/wiki/United_States
Candidates Entropy: 0.34655629348474887
Final System Output:Correct Wikification of: China to : http://en.wikipedia.org/wiki/China
Candidates Entropy: 0.2655641522753628
Final System Output:Correct Wikification of: Ian Perkin to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Hong Kong General Chamber of Commerce to : http://en.wikipedia.org/wiki/Hong_Kong_General_Chamber_of_Commerce
Candidates Entropy: 0.0
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/NYT20001124.2050.0257.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/NYT20001123.1511.0062
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =892
		- Total unique tokens  =453
		- Total unique tokens ignore case =427
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =67
		- OOV tokens, no repetitions, Case Sensitive =16
		- Total OOV tokens even after lowercasing  =67
		- OOV tokens even after lowercasing, no repetition  =16
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =115
		- OOV tokens, no repetitions, Case Sensitive =38
		- Total OOV tokens even after lowercasing  =112
		- OOV tokens even after lowercasing, no repetition  =35
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =55
		- OOV tokens, no repetitions, Case Sensitive =44
		- Total OOV tokens even after lowercasing  =46
		- OOV tokens even after lowercasing, no repetition  =36
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 973 milliseconds
Constructing a problem for the following text: 
 WORLD' &LR; &QL; &UR; By STUART ELLIOTT &LR; &QC; &QL; &UR; c.2000 N.Y. Times News Service &LR; &QC; &QL;    It's time again to ask 20 questions about advertising, marketing and the media.   _ Wil...
Annotating mention view..
1 milliseconds elapsed on constructing the TF-IDF representation of the input text...NYT20001123.1511.0062
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Adding NER candidates for NYT20001123.1511.0062
Adding SHALLOW_PARSE and subChunk candidates for NYT20001123.1511.0062
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Matched regex entity WORLD' &LR[1-11]{0-3}
Matched regex entity The Drew Carey Show'' and ``Spin City''[363-402]{83-93}
Matched regex entity Drew Carey Show'' and ``Spin City''[367-402]{84-93}
Matched regex entity Spin City''[391-402]{90-93}
Matched regex entity Chad, Chad World''[521-539]{120-125}
Matched regex entity Genetically Altered Protein Is Found in Still More Corn''[650-707]{145-155}
Matched regex entity Found in Still More Corn''[681-707]{149-155}
Matched regex entity Now That the Election Is Over, You Can Focus on Some Real News''[1550-1614]{311-326}
Matched regex entity That the Election Is Over, You Can Focus on Some Real News''[1554-1614]{312-326}
Matched regex entity Election Is Over, You Can Focus on Some Real News''[1563-1614]{314-326}
Matched regex entity Over, You Can Focus on Some Real News''[1575-1614]{316-326}
Matched regex entity You Can Focus on Some Real News''[1581-1614]{318-326}
Matched regex entity Can Focus on Some Real News''[1585-1614]{319-326}
Matched regex entity Focus on Some Real News''[1589-1614]{320-326}
Matched regex entity Carnation Coffee-mate[1660-1681]{337-339}
Matched regex entity Vitamin C[2081-2090]{408-410}
Matched regex entity Helen Hunt, Greg Kinnear and James L. Brooks[2143-2187]{424-433}
Matched regex entity Greg Kinnear and James L. Brooks[2155-2187]{427-433}
Matched regex entity Campbell's Cream of Mushroom[2236-2264]{442-447}
Matched regex entity Cream of Mushroom[2247-2264]{444-447}
Matched regex entity Times Square the American Airlines Theater[2404-2446]{480-486}
Matched regex entity Reader's Digest Association[2519-2546]{501-505}
Matched regex entity Reader's Digest[2692-2707]{534-537}
Matched regex entity Empire Blue Cross Blue Shield and the MSN[3075-3116]{606-614}
Matched regex entity Land Rover and Volvo[3278-3298]{642-646}
Matched regex entity John Corbett on ``Sex and the City[3879-3913]{755-763}
Matched regex entity Sex and the City[3897-3913]{759-763}
Matched regex entity Houston Grand Opera[4040-4059]{792-795}
Matched regex entity Grand Opera[4048-4059]{793-795}
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Important warning: the manually defined entity Reader's Digest magazine had 0 disambiguation candidates
Important warning: the manually defined entity MSN network had 0 disambiguation candidates
Important warning: the manually defined entity In Style Entertaining 2000 magazine had 0 disambiguation candidates
Done constructing the Wikifiable entities
     ----  almost there....
235 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...NYT20001123.1511.0062
Inference on the document  -- NYT20001123.1511.0062
2 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
4 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
230 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
13 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
315 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
7 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: ABC to : http://en.wikipedia.org/wiki/American_Broadcasting_Company
Level:FeatureExtractorCoherenceCorrect Wikification of: Sun Microsystems to : http://en.wikipedia.org/wiki/Sun_Microsystems
Level:FeatureExtractorCoherenceCorrect Wikification of: Fidelity Investments to : http://en.wikipedia.org/wiki/Fidelity_Investments
Level:FeatureExtractorCoherenceCorrect Wikification of: PepsiCo to : http://en.wikipedia.org/wiki/PepsiCo
Level:FeatureExtractorCoherenceCorrect Wikification of: Jack Nicholson to : http://en.wikipedia.org/wiki/Jack_Nicholson
Level:FeatureExtractorCoherenceCorrect Wikification of: Helen Hunt to : http://en.wikipedia.org/wiki/Helen_Hunt
Level:FeatureExtractorCoherenceCorrect Wikification of: Greg Kinnear to : http://en.wikipedia.org/wiki/Greg_Kinnear
Level:FeatureExtractorCoherenceCorrect Wikification of: James L. Brooks to : http://en.wikipedia.org/wiki/James_L._Brooks
Level:FeatureExtractorCoherenceCorrect Wikification of: Campbell Soup Co to : http://en.wikipedia.org/wiki/Campbell_Soup_Company
Level:FeatureExtractorCoherenceCorrect Wikification of: Roundabout Theater Company to : http://en.wikipedia.org/wiki/Roundabout_Theatre_Company
Level:FeatureExtractorCoherenceCorrect Wikification of: Times Square to : http://en.wikipedia.org/wiki/Times_Square
Level:FeatureExtractorCoherenceCorrect Wikification of: Levi to : http://en.wikipedia.org/wiki/Levi_Strauss_&_Co.
Level:FeatureExtractorCoherenceCorrect Wikification of: Empire Blue Cross Blue Shield to : http://en.wikipedia.org/wiki/Blue_Cross_Blue_Shield_Association
Level:FeatureExtractorCoherenceCorrect Wikification of: Microsoft to : http://en.wikipedia.org/wiki/Microsoft
Level:FeatureExtractorCoherenceCorrect Wikification of: Land Rover to : http://en.wikipedia.org/wiki/Land_Rover
Level:FeatureExtractorCoherenceCorrect Wikification of: Volvo to : http://en.wikipedia.org/wiki/Volvo
Level:FeatureExtractorCoherenceCorrect Wikification of: Sprint Communications Co to : http://en.wikipedia.org/wiki/Sprint_Nextel
Level:FeatureExtractorCoherenceCorrect Wikification of: Houston Grand Opera to : http://en.wikipedia.org/wiki/Houston_Grand_Opera
Level:FeatureExtractorCoherenceCorrect Wikification of: CBS to : http://en.wikipedia.org/wiki/CBS
Level:FeatureExtractorCoherenceCorrect Wikification of: Brooklyn to : http://en.wikipedia.org/wiki/Brooklyn
Level:FeatureExtractorCoherenceCorrect Wikification of: ABC to : http://en.wikipedia.org/wiki/American_Broadcasting_Company
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Fox Sports; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Fox_Sports_(United_States);
  The confusions set is : Fox_Sports_(United_States)(ranker score=2.526786905571452) Vs: Fox_Sports_(Australia)(ranker score=2.9716599561192707);
  The context is: ; ------- ; he Wall Street Journal noticed that an article on Wednesday carrying the headline ``Genetically Altered Protein Is Found in Still More Corn'' ran adjacent to an advertisement for a golf tournament on Fox Sports sponsored by Sun Microsystems that featured a fanciful photograph of a gigantic ear of corn as big as a Buick?   _ Doesn't a new television commercial for Fidelity Investments, centered on 
Level:FeatureExtractorCoherenceCorrect Wikification of: Sun Microsystems to : http://en.wikipedia.org/wiki/Sun_Microsystems
Level:FeatureExtractorCoherenceCorrect Wikification of: Fidelity Investments to : http://en.wikipedia.org/wiki/Fidelity_Investments
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Ocean Spray Cranberries; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Ocean_Spray_(cooperative);
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; rmarket chain Gristede's rush to take advantage of a recent sale on the ``BIG 150-count box'' of Scotties facial tissues, or did they recall that Scotties has usually come in a 175-count box?   _ Can Ocean Spray Cranberries get a refund on a full-page ad that ran in newspapers on Nov. 8 and carried the headline ``Now That the Election Is Over, You Can Focus on Some Real News''?   _ Was it a coinci
Level:FeatureExtractorCoherenceCorrect Wikification of: PepsiCo to : http://en.wikipedia.org/wiki/PepsiCo
Level:FeatureExtractorCoherenceCorrect Wikification of: Jack Nicholson to : http://en.wikipedia.org/wiki/Jack_Nicholson
Level:FeatureExtractorCoherenceCorrect Wikification of: Helen Hunt to : http://en.wikipedia.org/wiki/Helen_Hunt
Level:FeatureExtractorCoherenceCorrect Wikification of: Greg Kinnear to : http://en.wikipedia.org/wiki/Greg_Kinnear
Level:FeatureExtractorCoherenceCorrect Wikification of: James L. Brooks to : http://en.wikipedia.org/wiki/James_L._Brooks
Level:FeatureExtractorCoherenceCorrect Wikification of: Campbell Soup Co to : http://en.wikipedia.org/wiki/Campbell_Soup_Company
Level:FeatureExtractorCoherenceCorrect Wikification of: Roundabout Theater Company to : http://en.wikipedia.org/wiki/Roundabout_Theatre_Company
Level:FeatureExtractorCoherenceCorrect Wikification of: Times Square to : http://en.wikipedia.org/wiki/Times_Square
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Reader's Digest Association; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Reader's_Digest ; the gold is: http://en.wikipedia.org/wiki/Reader's_Digest_Association;
  The surface form has a single disambiguation candidate : Reader's_Digest(ranker score=3.6258761414526264) ;
  The context is: ; ------- ; t gets''?   _ Now that the Roundabout Theater Company is calling its new facility in Times Square the American Airlines Theater, will the ushers give out peanuts instead of Playbills?   _ Why did the Reader's Digest Association go to the trouble of airbrushing the identifying information from a label on a pair of jeans worn by a man in a photograph featured in an ad for Reader's Digest magazine, b
Level:FeatureExtractorCoherenceCorrect Wikification of: Levi to : http://en.wikipedia.org/wiki/Levi_Strauss_&_Co.
Level:FeatureExtractorCoherenceCorrect Wikification of: Empire Blue Cross Blue Shield to : http://en.wikipedia.org/wiki/Blue_Cross_Blue_Shield_Association
Level:FeatureExtractorCoherenceCorrect Wikification of: Microsoft to : http://en.wikipedia.org/wiki/Microsoft
Level:FeatureExtractorCoherenceCorrect Wikification of: Land Rover to : http://en.wikipedia.org/wiki/Land_Rover
Level:FeatureExtractorCoherenceCorrect Wikification of: Volvo to : http://en.wikipedia.org/wiki/Volvo
Level:FeatureExtractorCoherenceCorrect Wikification of: Sprint Communications Co to : http://en.wikipedia.org/wiki/Sprint_Nextel
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: John Corbett; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/John_Corbett ; the gold is: http://en.wikipedia.org/wiki/John_Corbett_(actor);
  The confusions set is : John_Corbett_(writer)(ranker score=1.052139199446223) Vs: John_Corbett(ranker score=7.706064433541268);
  The context is: ; ------- ; cent offer made by Sprint Communications Co. to give buyers of a Sprint PCS telephone and a calling plan a free ``pre-owned phone''?   _ Was it an inside joke that the name of the character played by John Corbett on ``Sex and the City,'' Aidan Shaw, was almost identical to the name of a longtime star of gay sex films, Aiden Shaw?   _ How many tickets did the Houston Grand Opera sell after mailing 
Level:FeatureExtractorCoherenceCorrect Wikification of: Houston Grand Opera to : http://en.wikipedia.org/wiki/Houston_Grand_Opera
Level:FeatureExtractorCoherenceCorrect Wikification of: CBS to : http://en.wikipedia.org/wiki/CBS
Level:FeatureExtractorCoherenceCorrect Wikification of: Brooklyn to : http://en.wikipedia.org/wiki/Brooklyn
Could not find WikiMatchData for title Real_News
Could not find WikiMatchData for title Folks
Could not find WikiMatchData for title Survivor:_The_Australian_Outback
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Ocean_Spray_(cooperative), pred=products, arg2=Cranberry, score=12.936555385589601, normalizedScore=100.0]For surfaces Ocean Spray and Cranberries
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Greg_Kinnear, pred=WIKI_LINK_RELATION, arg2=James_L._Brooks, score=5.547650337219238, normalizedScore=100.0]For surfaces Greg Kinnear and James L. Brooks
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Campbell_Soup_Company, pred=WIKI_LINK_RELATION, arg2=Cream_of_mushroom_soup, score=4.22623336315155, normalizedScore=100.0]For surfaces Campbell and Cream of Mushroom
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Land_Rover, pred=WIKI_LINK_RELATION, arg2=Volvo, score=4.832008600234985, normalizedScore=100.0]For surfaces Land Rover and Volvo
Could not find WikiMatchData for title John_Corbett_(actor)
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=John_Corbett_(actor), pred=WIKI_LINK_RELATION, arg2=Sex_and_the_City, score=5.54153603553772, normalizedScore=100.0]For surfaces John Corbett and Sex and the City
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Arthur Godfrey[3487-3501]{678-680} === the radio and television personality
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Aiden Shaw[3999-4009]{783-785} === a longtime star of gay sex films
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Aiden Shaw[3999-4009]{783-785} === longtime star of gay sex films
Relational inference took 7ms
CoherenceRelation 2172 [arg1=[surface=Greg Kinnear, solution=Greg_Kinnear], arg2=[surface=James L. Brooks, solution=James_L._Brooks], weight=50.0] is captured by ILP inference.
CoherenceRelation 2143 [arg1=[surface=Hunt, solution=Helen_Hunt], arg2=[surface=Helen Hunt, solution=Helen_Hunt], weight=10.0] is captured by ILP inference.
CoherenceRelation 2172 [arg1=[surface=Brooks, solution=James_L._Brooks], arg2=[surface=James L. Brooks, solution=James_L._Brooks], weight=10.0] is captured by ILP inference.
CoherenceRelation 3999 [arg1=[surface=Shaw, solution=Aiden_Shaw], arg2=[surface=Aiden Shaw, solution=Aiden_Shaw], weight=10.0] is captured by ILP inference.
CoherenceRelation 4308 [arg1=[surface=XXXV, solution=Super_Bowl_XXXV], arg2=[surface=Super Bowl XXXV, solution=Super_Bowl_XXXV], weight=10.0] is captured by ILP inference.
CoherenceRelation 1332 [arg1=[surface=Scotties, solution=Scotties], arg2=[surface=Scotties, solution=Scotties], weight=10.0] is captured by ILP inference.
CoherenceRelation 2155 [arg1=[surface=Greg, solution=Greg_Kinnear], arg2=[surface=Greg Kinnear, solution=Greg_Kinnear], weight=10.0] is captured by ILP inference.
CoherenceRelation 2247 [arg1=[surface=Campbell, solution=Campbell_Soup_Company], arg2=[surface=Cream of Mushroom, solution=Cream_of_mushroom_soup], weight=100.0] is captured by ILP inference.
CoherenceRelation 4040 [arg1=[surface=Grand Opera, solution=Houston_Grand_Opera], arg2=[surface=Houston Grand Opera, solution=Houston_Grand_Opera], weight=10.0] is captured by ILP inference.
CoherenceRelation 4308 [arg1=[surface=Super Bowl, solution=Super_Bowl_XXXV], arg2=[surface=Super Bowl XXXV, solution=Super_Bowl_XXXV], weight=10.0] is captured by ILP inference.
CoherenceRelation 569 [arg1=[surface=Journal, solution=The_Wall_Street_Journal], arg2=[surface=Wall Street Journal, solution=The_Wall_Street_Journal], weight=10.0] is captured by ILP inference.
CoherenceRelation 2143 [arg1=[surface=Helen, solution=Helen_Hunt], arg2=[surface=Helen Hunt, solution=Helen_Hunt], weight=10.0] is captured by ILP inference.
CoherenceRelation 3293 [arg1=[surface=Land Rover, solution=Land_Rover], arg2=[surface=Volvo, solution=Volvo], weight=50.0] is captured by ILP inference.
CoherenceRelation 1447 [arg1=[surface=Ocean Spray, solution=Ocean_Spray_(cooperative)], arg2=[surface=Cranberries, solution=Cranberry], weight=100.0] is captured by ILP inference.
CoherenceRelation 3487 [arg1=[surface=Arthur, solution=Arthur_Godfrey], arg2=[surface=Arthur Godfrey, solution=Arthur_Godfrey], weight=10.0] is captured by ILP inference.
CoherenceRelation 3917 [arg1=[surface=Aidan, solution=*null*], arg2=[surface=Aidan Shaw, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 2127 [arg1=[surface=Nicholson, solution=Jack_Nicholson], arg2=[surface=Jack Nicholson, solution=Jack_Nicholson], weight=10.0] is captured by ILP inference.
CoherenceRelation 2172 [arg1=[surface=James, solution=James_L._Brooks], arg2=[surface=James L. Brooks, solution=James_L._Brooks], weight=10.0] is captured by ILP inference.
CoherenceRelation 3917 [arg1=[surface=Shaw, solution=*null*], arg2=[surface=Aidan Shaw, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 2346 [arg1=[surface=Company, solution=Roundabout_Theatre_Company], arg2=[surface=Roundabout Theater Company, solution=Roundabout_Theatre_Company], weight=10.0] is captured by ILP inference.
CoherenceRelation 2155 [arg1=[surface=Kinnear, solution=Greg_Kinnear], arg2=[surface=Greg Kinnear, solution=Greg_Kinnear], weight=10.0] is captured by ILP inference.
CoherenceRelation 3879 [arg1=[surface=John, solution=John_Corbett_(actor)], arg2=[surface=John Corbett, solution=John_Corbett_(actor)], weight=10.0] is captured by ILP inference.
CoherenceRelation 3897 [arg1=[surface=John Corbett, solution=John_Corbett_(actor)], arg2=[surface=Sex and the City, solution=Sex_and_the_City], weight=50.0] is captured by ILP inference.
CoherenceRelation 3879 [arg1=[surface=Corbett, solution=John_Corbett_(actor)], arg2=[surface=John Corbett, solution=John_Corbett_(actor)], weight=10.0] is captured by ILP inference.
CoherenceRelation 2127 [arg1=[surface=Jack, solution=Jack_Nicholson], arg2=[surface=Jack Nicholson, solution=Jack_Nicholson], weight=10.0] is captured by ILP inference.
CoherenceRelation 3999 [arg1=[surface=Aiden, solution=Aiden_Shaw], arg2=[surface=Aiden Shaw, solution=Aiden_Shaw], weight=10.0] is captured by ILP inference.
CoherenceRelation 2172 [arg1=[surface=L., solution=James_L._Brooks], arg2=[surface=James L. Brooks, solution=James_L._Brooks], weight=10.0] is captured by ILP inference.
CoherenceRelation 3487 [arg1=[surface=Godfrey, solution=Arthur_Godfrey], arg2=[surface=Arthur Godfrey, solution=Arthur_Godfrey], weight=10.0] is captured by ILP inference.
CoherenceRelation 3082 [arg1=[surface=Blue Shield, solution=Blue_Cross_Blue_Shield_Association], arg2=[surface=Blue Cross Blue Shield, solution=Blue_Cross_Blue_Shield_Association], weight=10.0] is captured by ILP inference.
Discarded 7 hypothesis
Level: Relational Coherence Correct Wikification of: ABC to : http://en.wikipedia.org/wiki/American_Broadcasting_Company
Level: Relational Coherence : Still Incorrect Wikification of: Fox Sports; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Fox_Sports_(United_States);
  The confusions set is : Fox_Sports_(United_States)(ranker score=0.31022355235498605) Vs: Fox_Sports_(Australia)(ranker score=0.4840393595342169);
  The context is: ; ------- ; he Wall Street Journal noticed that an article on Wednesday carrying the headline ``Genetically Altered Protein Is Found in Still More Corn'' ran adjacent to an advertisement for a golf tournament on Fox Sports sponsored by Sun Microsystems that featured a fanciful photograph of a gigantic ear of corn as big as a Buick?   _ Doesn't a new television commercial for Fidelity Investments, centered on 
Level: Relational Coherence Correct Wikification of: Sun Microsystems to : http://en.wikipedia.org/wiki/Sun_Microsystems
Level: Relational Coherence Correct Wikification of: Fidelity Investments to : http://en.wikipedia.org/wiki/Fidelity_Investments
Level: Relational Coherence : Still Incorrect Wikification of: Ocean Spray Cranberries; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Ocean_Spray_(cooperative);
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; rmarket chain Gristede's rush to take advantage of a recent sale on the ``BIG 150-count box'' of Scotties facial tissues, or did they recall that Scotties has usually come in a 175-count box?   _ Can Ocean Spray Cranberries get a refund on a full-page ad that ran in newspapers on Nov. 8 and carried the headline ``Now That the Election Is Over, You Can Focus on Some Real News''?   _ Was it a coinci
Level: Relational Coherence Correct Wikification of: PepsiCo to : http://en.wikipedia.org/wiki/PepsiCo
Level: Relational Coherence Correct Wikification of: Jack Nicholson to : http://en.wikipedia.org/wiki/Jack_Nicholson
Level: Relational Coherence Correct Wikification of: Helen Hunt to : http://en.wikipedia.org/wiki/Helen_Hunt
Level: Relational Coherence Correct Wikification of: Greg Kinnear to : http://en.wikipedia.org/wiki/Greg_Kinnear
Level: Relational Coherence Correct Wikification of: James L. Brooks to : http://en.wikipedia.org/wiki/James_L._Brooks
Level: Relational Coherence Correct Wikification of: Campbell Soup Co to : http://en.wikipedia.org/wiki/Campbell_Soup_Company
Level: Relational Coherence Correct Wikification of: Roundabout Theater Company to : http://en.wikipedia.org/wiki/Roundabout_Theatre_Company
Level: Relational Coherence Correct Wikification of: Times Square to : http://en.wikipedia.org/wiki/Times_Square
Level: Relational Coherence : Still Incorrect Wikification of: Reader's Digest Association; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Reader's_Digest ; the gold is: http://en.wikipedia.org/wiki/Reader's_Digest_Association;
  The surface form has a single disambiguation candidate : Reader's_Digest(ranker score=1.0) ;
  The context is: ; ------- ; t gets''?   _ Now that the Roundabout Theater Company is calling its new facility in Times Square the American Airlines Theater, will the ushers give out peanuts instead of Playbills?   _ Why did the Reader's Digest Association go to the trouble of airbrushing the identifying information from a label on a pair of jeans worn by a man in a photograph featured in an ad for Reader's Digest magazine, b
Level: Relational Coherence Correct Wikification of: Levi to : http://en.wikipedia.org/wiki/Levi_Strauss_&_Co.
Level: Relational Coherence Correct Wikification of: Empire Blue Cross Blue Shield to : http://en.wikipedia.org/wiki/Blue_Cross_Blue_Shield_Association
Level: Relational Coherence Correct Wikification of: Microsoft to : http://en.wikipedia.org/wiki/Microsoft
Level: Relational Coherence Correct Wikification of: Land Rover to : http://en.wikipedia.org/wiki/Land_Rover
Level: Relational Coherence Correct Wikification of: Volvo to : http://en.wikipedia.org/wiki/Volvo
Level: Relational Coherence Correct Wikification of: Sprint Communications Co to : http://en.wikipedia.org/wiki/Sprint_Nextel
Level: Relational Coherence Correct Wikification of: John Corbett to : http://en.wikipedia.org/wiki/John_Corbett_(actor)
Level: Relational Coherence this fixes the Wikification (!!!)John Corbett; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/John_Corbett_(actor) ; the gold is: http://en.wikipedia.org/wiki/John_Corbett_(actor);
  The confusions set is : John_Corbett_(writer)(ranker score=0.0012857476227723375) Vs: John_Corbett(ranker score=0.9975134085835885);
  The context is: ; ------- ; cent offer made by Sprint Communications Co. to give buyers of a Sprint PCS telephone and a calling plan a free ``pre-owned phone''?   _ Was it an inside joke that the name of the character played by John Corbett on ``Sex and the City,'' Aidan Shaw, was almost identical to the name of a longtime star of gay sex films, Aiden Shaw?   _ How many tickets did the Houston Grand Opera sell after mailing 
Level: Relational Coherence Correct Wikification of: Houston Grand Opera to : http://en.wikipedia.org/wiki/Houston_Grand_Opera
Level: Relational Coherence Correct Wikification of: CBS to : http://en.wikipedia.org/wiki/CBS
Level: Relational Coherence Correct Wikification of: Brooklyn to : http://en.wikipedia.org/wiki/Brooklyn
Annotation at test time--1017 milliseconds elapsed to annotate the document NYT20001123.1511.0062
Final System Output:Correct Wikification of: ABC to : http://en.wikipedia.org/wiki/American_Broadcasting_Company
Candidates Entropy: 1.237070050304243
Final System Output:: Still Incorrect Wikification of: Fox Sports; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Fox_Sports_(United_States);
  The confusions set is : Fox_Sports_(United_States)(ranker score=0.31022355235498605) Vs: Fox_Sports_(Australia)(ranker score=0.4840393595342169);
  The context is: ; ------- ; he Wall Street Journal noticed that an article on Wednesday carrying the headline ``Genetically Altered Protein Is Found in Still More Corn'' ran adjacent to an advertisement for a golf tournament on Fox Sports sponsored by Sun Microsystems that featured a fanciful photograph of a gigantic ear of corn as big as a Buick?   _ Doesn't a new television commercial for Fidelity Investments, centered on 
Candidates Entropy: 1.3773756019193117
Final System Output:Correct Wikification of: Sun Microsystems to : http://en.wikipedia.org/wiki/Sun_Microsystems
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Fidelity Investments to : http://en.wikipedia.org/wiki/Fidelity_Investments
Candidates Entropy: 0.0
Final System Output:: Still Incorrect Wikification of: Ocean Spray Cranberries; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Ocean_Spray_(cooperative);
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; rmarket chain Gristede's rush to take advantage of a recent sale on the ``BIG 150-count box'' of Scotties facial tissues, or did they recall that Scotties has usually come in a 175-count box?   _ Can Ocean Spray Cranberries get a refund on a full-page ad that ran in newspapers on Nov. 8 and carried the headline ``Now That the Election Is Over, You Can Focus on Some Real News''?   _ Was it a coinci
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: PepsiCo to : http://en.wikipedia.org/wiki/PepsiCo
Candidates Entropy: 0.058565355031761857
Final System Output:Correct Wikification of: Jack Nicholson to : http://en.wikipedia.org/wiki/Jack_Nicholson
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Helen Hunt to : http://en.wikipedia.org/wiki/Helen_Hunt
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Greg Kinnear to : http://en.wikipedia.org/wiki/Greg_Kinnear
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: James L. Brooks to : http://en.wikipedia.org/wiki/James_L._Brooks
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Campbell Soup Co to : http://en.wikipedia.org/wiki/Campbell_Soup_Company
Candidates Entropy: 0.28452577752393887
Final System Output:Correct Wikification of: Roundabout Theater Company to : http://en.wikipedia.org/wiki/Roundabout_Theatre_Company
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Times Square to : http://en.wikipedia.org/wiki/Times_Square
Candidates Entropy: 0.30983393936059583
Final System Output:: Still Incorrect Wikification of: Reader's Digest Association; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Reader's_Digest ; the gold is: http://en.wikipedia.org/wiki/Reader's_Digest_Association;
  The surface form has a single disambiguation candidate : Reader's_Digest(ranker score=1.0) ;
  The context is: ; ------- ; t gets''?   _ Now that the Roundabout Theater Company is calling its new facility in Times Square the American Airlines Theater, will the ushers give out peanuts instead of Playbills?   _ Why did the Reader's Digest Association go to the trouble of airbrushing the identifying information from a label on a pair of jeans worn by a man in a photograph featured in an ad for Reader's Digest magazine, b
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Levi to : http://en.wikipedia.org/wiki/Levi_Strauss_&_Co.
Candidates Entropy: 0.01810480687661389
Final System Output:Correct Wikification of: Empire Blue Cross Blue Shield to : http://en.wikipedia.org/wiki/Blue_Cross_Blue_Shield_Association
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Microsoft to : http://en.wikipedia.org/wiki/Microsoft
Candidates Entropy: 0.31006433558286955
Final System Output:Correct Wikification of: Land Rover to : http://en.wikipedia.org/wiki/Land_Rover
Candidates Entropy: 0.09179790209089655
Final System Output:Correct Wikification of: Volvo to : http://en.wikipedia.org/wiki/Volvo
Candidates Entropy: 0.9881759409042806
Final System Output:Correct Wikification of: Sprint Communications Co to : http://en.wikipedia.org/wiki/Sprint_Nextel
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: John Corbett to : http://en.wikipedia.org/wiki/John_Corbett_(actor)
Candidates Entropy: 0.019117318199309903
Final System Output:Correct Wikification of: Houston Grand Opera to : http://en.wikipedia.org/wiki/Houston_Grand_Opera
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: CBS to : http://en.wikipedia.org/wiki/CBS
Candidates Entropy: 0.1676432887333172
Final System Output:Correct Wikification of: Brooklyn to : http://en.wikipedia.org/wiki/Brooklyn
Candidates Entropy: 1.6412581624077878
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/NYT20001123.1511.0062.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/APW20001203.1456.0329
Empty problem - no reference instances!!!
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/PRI20001201.2000.1828
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =246
		- Total unique tokens  =142
		- Total unique tokens ignore case =136
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =3
		- OOV tokens, no repetitions, Case Sensitive =2
		- Total OOV tokens even after lowercasing  =3
		- OOV tokens even after lowercasing, no repetition  =2
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =6
		- OOV tokens, no repetitions, Case Sensitive =5
		- Total OOV tokens even after lowercasing  =6
		- OOV tokens even after lowercasing, no repetition  =5
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =5
		- OOV tokens, no repetitions, Case Sensitive =4
		- Total OOV tokens even after lowercasing  =5
		- OOV tokens even after lowercasing, no repetition  =4
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 211 milliseconds
Constructing a problem for the following text: 
 From BBC News in London, I am Gregor Cragy for The World. The US Supreme Court has held a hearing to decide whether to intervene in the dispute over the presidential election results. Judith Spenc...
Annotating mention view..
1 milliseconds elapsed on constructing the TF-IDF representation of the input text...PRI20001201.2000.1828
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Adding NER candidates for PRI20001201.2000.1828
Adding SHALLOW_PARSE and subChunk candidates for PRI20001201.2000.1828
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Matched regex entity From BBC News in London, I[1-27]{0-7}
Matched regex entity BBC News in London, I[6-27]{1-7}
Matched regex entity London, I[18-27]{4-7}
Matched regex entity Gregor Cragy for The World[31-57]{8-13}
Matched regex entity Republican George W. Bush and Democrat AL Gore[306-352]{56-64}
Matched regex entity Democrat AL Gore[336-352]{61-64}
Matched regex entity Justice Sandra Day O'Connor[768-795]{142-146}
Matched regex entity Sandra Day O'Connor[776-795]{143-146}
Matched regex entity Day O'Connor[783-795]{144-146}
Matched regex entity O'Connor[787-795]{145-146}
Matched regex entity For The World, I[1077-1093]{204-209}
Matched regex entity The World, I[1081-1093]{205-209}
Matched regex entity World, I[1085-1093]{206-209}
Matched regex entity Judith Spencer in Washington[1097-1125]{210-214}
Matched regex entity Meanwhile, the Florida Supreme Court[1129-1165]{215-221}
Matched regex entity Palm Beach and Miami Dade[1276-1301]{239-244}
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Done constructing the Wikifiable entities
     ----  almost there....
258 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...PRI20001201.2000.1828
Inference on the document  -- PRI20001201.2000.1828
2 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
3 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
49 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
7 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
347 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
4 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: BBC News to : http://en.wikipedia.org/wiki/BBC_News
Level:FeatureExtractorCoherenceCorrect Wikification of: London to : http://en.wikipedia.org/wiki/London
Level:FeatureExtractorCoherenceCorrect Wikification of: US Supreme Court to : http://en.wikipedia.org/wiki/Supreme_Court_of_the_United_States
Level:FeatureExtractorCoherenceCorrect Wikification of: Judith Spencer to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Florida Supreme Court to : http://en.wikipedia.org/wiki/Supreme_Court_of_Florida
Level:FeatureExtractorCoherenceCorrect Wikification of: Sandra Day O'Connor to : http://en.wikipedia.org/wiki/Sandra_Day_O'Connor
Level:FeatureExtractorCoherenceCorrect Wikification of: Washington to : http://en.wikipedia.org/wiki/Washington,_D.C.
Level:FeatureExtractorCoherenceCorrect Wikification of: BBC News to : http://en.wikipedia.org/wiki/BBC_News
Level:FeatureExtractorCoherenceCorrect Wikification of: London to : http://en.wikipedia.org/wiki/London
Level:FeatureExtractorCoherenceCorrect Wikification of: US Supreme Court to : http://en.wikipedia.org/wiki/Supreme_Court_of_the_United_States
Level:FeatureExtractorCoherenceCorrect Wikification of: Judith Spencer to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Ruth Bater Ginsburg; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Ruth_Bader_Ginsburg;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; s underway.   Inside the stately Supreme Court building, lawyers for Republican George W. Bush and Democrat AL Gore argued over the validity of hand re-counts in the crucial state of Florida, just as Ruth Bater Ginsburg pressed Bush's lawyer to explain why the Federal High Court should intervene in the Florida Supreme Court's move to extend the deadline for finishing the re-counts.   When we read 
Level:FeatureExtractorCoherenceCorrect Wikification of: Florida Supreme Court to : http://en.wikipedia.org/wiki/Supreme_Court_of_Florida
Level:FeatureExtractorCoherenceCorrect Wikification of: Sandra Day O'Connor to : http://en.wikipedia.org/wiki/Sandra_Day_O'Connor
Level:FeatureExtractorCoherenceCorrect Wikification of: Washington to : http://en.wikipedia.org/wiki/Washington,_D.C.
Could not find WikiMatchData for title Decide
Could not find WikiMatchData for title United_States_presidential_election,_2012
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=BBC_News, pred=locationCity, arg2=London, score=12.553539037704468, normalizedScore=100.0]For surfaces BBC News and London
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Republican_Party_(United_States), pred=party, arg2=George_W._Bush, score=19.763012552261355, normalizedScore=100.0]For surfaces Republican and George W. Bush
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Democratic_Party_(United_States), pred=party, arg2=Al_Gore, score=11.42337842941284, normalizedScore=100.0]For surfaces Democrat and AL Gore
3 too ambiguous for Supreme Court[270-283]{50-52}, not adding cross cluster candidates.
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Sandra_Day_O'Connor due to a longer mention than O'Connor that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Al_Gore due to a longer mention than Gore that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Al_Gore_presidential_campaign,_2000 due to a longer mention than Gore that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Al_Gore due to a longer mention than Gore that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Al_Gore_and_information_technology due to a longer mention than Gore that referred to the same thing
Relational inference took 11ms
CoherenceRelation 768 [arg1=[surface=Justice, solution=Sandra_Day_O'Connor], arg2=[surface=Justice Sandra Day O'Connor, solution=Sandra_Day_O'Connor], weight=10.0] is captured by ILP inference.
CoherenceRelation 768 [arg1=[surface=Sandra, solution=Sandra_Day_O'Connor], arg2=[surface=Justice Sandra Day O'Connor, solution=Sandra_Day_O'Connor], weight=10.0] is captured by ILP inference.
CoherenceRelation 317 [arg1=[surface=George W., solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 768 [arg1=[surface=Day, solution=Sandra_Day_O'Connor], arg2=[surface=Justice Sandra Day O'Connor, solution=Sandra_Day_O'Connor], weight=10.0] is captured by ILP inference.
CoherenceRelation 1013 [arg1=[surface=US Supreme Court, solution=Supreme_Court_of_the_United_States], arg2=[surface=US Supreme Court, solution=Supreme_Court_of_the_United_States], weight=10.0] is captured by ILP inference.
CoherenceRelation 185 [arg1=[surface=Judith, solution=*null*], arg2=[surface=Judith Spencer, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 317 [arg1=[surface=W., solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 1013 [arg1=[surface=State Supreme Court, solution=Supreme_Court_of_the_United_States], arg2=[surface=US Supreme Court, solution=Supreme_Court_of_the_United_States], weight=10.0] is captured by ILP inference.
CoherenceRelation 1013 [arg1=[surface=Supreme Court, solution=Supreme_Court_of_the_United_States], arg2=[surface=US Supreme Court, solution=Supreme_Court_of_the_United_States], weight=10.0] is captured by ILP inference.
CoherenceRelation 1013 [arg1=[surface=Florida Supreme Court, solution=Supreme_Court_of_the_United_States], arg2=[surface=US Supreme Court, solution=Supreme_Court_of_the_United_States], weight=10.0] is captured by ILP inference.
CoherenceRelation 31 [arg1=[surface=Gregor, solution=*null*], arg2=[surface=Gregor Cragy, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 317 [arg1=[surface=Republican, solution=Republican_Party_(United_States)], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=50.0] is captured by ILP inference.
CoherenceRelation 768 [arg1=[surface=Sandra Day, solution=Sandra_Day_O'Connor], arg2=[surface=Justice Sandra Day O'Connor, solution=Sandra_Day_O'Connor], weight=10.0] is captured by ILP inference.
CoherenceRelation 1013 [arg1=[surface=Florida Supreme Court, solution=Supreme_Court_of_the_United_States], arg2=[surface=US Supreme Court, solution=Supreme_Court_of_the_United_States], weight=10.0] is captured by ILP inference.
CoherenceRelation 1097 [arg1=[surface=Judith Spencer, solution=*null*], arg2=[surface=Judith Spencer, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 1097 [arg1=[surface=Spencer, solution=*null*], arg2=[surface=Judith Spencer, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 317 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 437 [arg1=[surface=Ginsburg, solution=*null*], arg2=[surface=Ruth Bater Ginsburg, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 48 [arg1=[surface=The World, solution=The_World_(radio_program)], arg2=[surface=The World, solution=The_World_(radio_program)], weight=10.0] is captured by ILP inference.
CoherenceRelation 18 [arg1=[surface=BBC News, solution=BBC_News], arg2=[surface=London, solution=London], weight=100.0] is captured by ILP inference.
CoherenceRelation 1097 [arg1=[surface=Judith, solution=*null*], arg2=[surface=Judith Spencer, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 437 [arg1=[surface=Ruth, solution=*null*], arg2=[surface=Ruth Bater Ginsburg, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 768 [arg1=[surface=Day O'Connor, solution=Sandra_Day_O'Connor], arg2=[surface=Justice Sandra Day O'Connor, solution=Sandra_Day_O'Connor], weight=10.0] is captured by ILP inference.
CoherenceRelation 1204 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 1204 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 437 [arg1=[surface=Bater, solution=*null*], arg2=[surface=Ruth Bater Ginsburg, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 317 [arg1=[surface=W. Bush, solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 185 [arg1=[surface=Spencer, solution=*null*], arg2=[surface=Judith Spencer, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 317 [arg1=[surface=George, solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 768 [arg1=[surface=Sandra Day O'Connor, solution=Sandra_Day_O'Connor], arg2=[surface=Justice Sandra Day O'Connor, solution=Sandra_Day_O'Connor], weight=10.0] is captured by ILP inference.
CoherenceRelation 1013 [arg1=[surface=Supreme Court, solution=Supreme_Court_of_the_United_States], arg2=[surface=US Supreme Court, solution=Supreme_Court_of_the_United_States], weight=10.0] is captured by ILP inference.
CoherenceRelation 1013 [arg1=[surface=Supreme Court, solution=Supreme_Court_of_the_United_States], arg2=[surface=US Supreme Court, solution=Supreme_Court_of_the_United_States], weight=10.0] is captured by ILP inference.
CoherenceRelation 345 [arg1=[surface=Democrat, solution=Democratic_Party_(United_States)], arg2=[surface=AL Gore, solution=Al_Gore], weight=100.0] is captured by ILP inference.
CoherenceRelation 768 [arg1=[surface=O'Connor, solution=Sandra_Day_O'Connor], arg2=[surface=Justice Sandra Day O'Connor, solution=Sandra_Day_O'Connor], weight=10.0] is captured by ILP inference.
CoherenceRelation 317 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
Discarded 51 hypothesis
Level: Relational Coherence Correct Wikification of: BBC News to : http://en.wikipedia.org/wiki/BBC_News
Level: Relational Coherence Correct Wikification of: London to : http://en.wikipedia.org/wiki/London
Level: Relational Coherence Correct Wikification of: US Supreme Court to : http://en.wikipedia.org/wiki/Supreme_Court_of_the_United_States
Level: Relational Coherence Correct Wikification of: Judith Spencer to : http://en.wikipedia.org/wiki/*null*
Level: Relational Coherence : Still Incorrect Wikification of: Ruth Bater Ginsburg; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Ruth_Bader_Ginsburg;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; s underway.   Inside the stately Supreme Court building, lawyers for Republican George W. Bush and Democrat AL Gore argued over the validity of hand re-counts in the crucial state of Florida, just as Ruth Bater Ginsburg pressed Bush's lawyer to explain why the Federal High Court should intervene in the Florida Supreme Court's move to extend the deadline for finishing the re-counts.   When we read 
Level: Relational Coherence : this introduces a Wikification error(!!!): Florida Supreme Court; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Supreme_Court_of_the_United_States ; the gold is: http://en.wikipedia.org/wiki/Supreme_Court_of_Florida;
  The confusions set is : Demographics_of_the_Supreme_Court_of_the_United_States(ranker score=0.003074413475343058) Vs: Supreme_Court_of_the_United_States(ranker score=0.9969255865246569);
  The context is: ; ------- ; rat AL Gore argued over the validity of hand re-counts in the crucial state of Florida, just as Ruth Bater Ginsburg pressed Bush's lawyer to explain why the Federal High Court should intervene in the Florida Supreme Court's move to extend the deadline for finishing the re-counts.   When we read a State court decision, we should read it in the light most favorable to the integrity of the State Supr
Level: Relational Coherence Correct Wikification of: Sandra Day O'Connor to : http://en.wikipedia.org/wiki/Sandra_Day_O'Connor
Level: Relational Coherence Correct Wikification of: Washington to : http://en.wikipedia.org/wiki/Washington,_D.C.
Annotation at test time--664 milliseconds elapsed to annotate the document PRI20001201.2000.1828
Final System Output:Correct Wikification of: BBC News to : http://en.wikipedia.org/wiki/BBC_News
Candidates Entropy: 0.3769638776903254
Final System Output:Correct Wikification of: London to : http://en.wikipedia.org/wiki/London
Candidates Entropy: 0.7064289589912017
Final System Output:Correct Wikification of: US Supreme Court to : http://en.wikipedia.org/wiki/Supreme_Court_of_the_United_States
Candidates Entropy: 0.02085406127298369
Final System Output:Correct Wikification of: Judith Spencer to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Final System Output:: Still Incorrect Wikification of: Ruth Bater Ginsburg; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Ruth_Bader_Ginsburg;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; s underway.   Inside the stately Supreme Court building, lawyers for Republican George W. Bush and Democrat AL Gore argued over the validity of hand re-counts in the crucial state of Florida, just as Ruth Bater Ginsburg pressed Bush's lawyer to explain why the Federal High Court should intervene in the Florida Supreme Court's move to extend the deadline for finishing the re-counts.   When we read 
Candidates Entropy: 0.0
Final System Output:: Still Incorrect Wikification of: Florida Supreme Court; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Supreme_Court_of_the_United_States ; the gold is: http://en.wikipedia.org/wiki/Supreme_Court_of_Florida;
  The confusions set is : Demographics_of_the_Supreme_Court_of_the_United_States(ranker score=0.003074413475343058) Vs: Supreme_Court_of_the_United_States(ranker score=0.9969255865246569);
  The context is: ; ------- ; rat AL Gore argued over the validity of hand re-counts in the crucial state of Florida, just as Ruth Bater Ginsburg pressed Bush's lawyer to explain why the Federal High Court should intervene in the Florida Supreme Court's move to extend the deadline for finishing the re-counts.   When we read a State court decision, we should read it in the light most favorable to the integrity of the State Supr
Candidates Entropy: 0.02085406127298369
Final System Output:Correct Wikification of: Sandra Day O'Connor to : http://en.wikipedia.org/wiki/Sandra_Day_O'Connor
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Washington to : http://en.wikipedia.org/wiki/Washington,_D.C.
Candidates Entropy: 1.2006131984180057
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/PRI20001201.2000.1828.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/20001115_AFP_ARB.0210.eng
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =37
		- Total unique tokens  =32
		- Total unique tokens ignore case =31
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =4
		- OOV tokens, no repetitions, Case Sensitive =2
		- Total OOV tokens even after lowercasing  =4
		- OOV tokens even after lowercasing, no repetition  =2
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =5
		- OOV tokens, no repetitions, Case Sensitive =3
		- Total OOV tokens even after lowercasing  =5
		- OOV tokens even after lowercasing, no repetition  =3
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =0
		- OOV tokens, no repetitions, Case Sensitive =0
		- Total OOV tokens even after lowercasing  =0
		- OOV tokens even after lowercasing, no repetition  =0
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 37 milliseconds
Constructing a problem for the following text: 
  Tallahassee (United States) 11-15 (AFP) -  The Supreme Court in Florida today Wednesday refused the application by the state's authorities to stop the new hand count of votes in some counties. 

0 milliseconds elapsed on constructing the TF-IDF representation of the input text...20001115_AFP_ARB.0210.eng
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Adding NER candidates for 20001115_AFP_ARB.0210.eng
Adding SHALLOW_PARSE and subChunk candidates for 20001115_AFP_ARB.0210.eng
Annotating mention view..
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Matched regex entity The Supreme Court in Florida[45-73]{10-15}
Matched regex entity Supreme Court in Florida[49-73]{11-15}
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Done constructing the Wikifiable entities
     ----  almost there....
49 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...20001115_AFP_ARB.0210.eng
Inference on the document  -- 20001115_AFP_ARB.0210.eng
0 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
1 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
14 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
2 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
13 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
0 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: Tallahassee to : http://en.wikipedia.org/wiki/Tallahassee,_Florida
Level:FeatureExtractorCoherenceCorrect Wikification of: United States to : http://en.wikipedia.org/wiki/United_States
Level:FeatureExtractorCoherenceCorrect Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level:FeatureExtractorCoherenceCorrect Wikification of: Florida to : http://en.wikipedia.org/wiki/Florida
Level:FeatureExtractorCoherenceCorrect Wikification of: Tallahassee to : http://en.wikipedia.org/wiki/Tallahassee,_Florida
Level:FeatureExtractorCoherenceCorrect Wikification of: United States to : http://en.wikipedia.org/wiki/United_States
Level:FeatureExtractorCoherence: this introduces a Wikification error(!!!): AFP; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Agence_France-Presse;
  The confusions set is : Apple_Filing_Protocol(ranker score=0.8134147466975288) Vs: Agence_France-Presse(ranker score=1.4726571507496415);
  The context is: ; ------- ;   Tallahassee (United States) 11-15 (AFP) -  The Supreme Court in Florida today Wednesday refused the application by the state's authorities to stop the new hand count of votes in some counties. 
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Supreme Court; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Supreme_Court_of_the_United_States ; the gold is: http://en.wikipedia.org/wiki/Supreme_Court_of_Florida;
  The confusions set is : Supreme_Court_of_Israel(ranker score=1.073437216678868) Vs: Supreme_Court_of_the_United_States(ranker score=4.815466107997583);
  The context is: ; ------- ;   Tallahassee (United States) 11-15 (AFP) -  The Supreme Court in Florida today Wednesday refused the application by the state's authorities to stop the new hand count of votes in some counties. 
Level:FeatureExtractorCoherenceCorrect Wikification of: Florida to : http://en.wikipedia.org/wiki/Florida
Relational inference took 1ms
Discarded 0 hypothesis
Level: Relational Coherence Correct Wikification of: Tallahassee to : http://en.wikipedia.org/wiki/Tallahassee,_Florida
Level: Relational Coherence Correct Wikification of: United States to : http://en.wikipedia.org/wiki/United_States
Level: Relational Coherence : Still Incorrect Wikification of: AFP; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Agence_France-Presse;
  The confusions set is : Apple_Filing_Protocol(ranker score=0.1821817498782073) Vs: Agence_France-Presse(ranker score=0.35221691392227444);
  The context is: ; ------- ;   Tallahassee (United States) 11-15 (AFP) -  The Supreme Court in Florida today Wednesday refused the application by the state's authorities to stop the new hand count of votes in some counties. 
Level: Relational Coherence : Still Incorrect Wikification of: Supreme Court; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Supreme_Court_of_the_United_States ; the gold is: http://en.wikipedia.org/wiki/Supreme_Court_of_Florida;
  The confusions set is : Supreme_Court_of_Israel(ranker score=0.023156998669154744) Vs: Supreme_Court_of_the_United_States(ranker score=0.9768430013308452);
  The context is: ; ------- ;   Tallahassee (United States) 11-15 (AFP) -  The Supreme Court in Florida today Wednesday refused the application by the state's authorities to stop the new hand count of votes in some counties. 
Level: Relational Coherence Correct Wikification of: Florida to : http://en.wikipedia.org/wiki/Florida
Annotation at test time--184 milliseconds elapsed to annotate the document 20001115_AFP_ARB.0210.eng
Final System Output:Correct Wikification of: Tallahassee to : http://en.wikipedia.org/wiki/Tallahassee,_Florida
Candidates Entropy: 0.22311617051394053
Final System Output:Correct Wikification of: United States to : http://en.wikipedia.org/wiki/United_States
Candidates Entropy: 0.04007053705984323
Final System Output:: Still Incorrect Wikification of: AFP; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Agence_France-Presse;
  The confusions set is : Apple_Filing_Protocol(ranker score=0.1821817498782073) Vs: Agence_France-Presse(ranker score=0.35221691392227444);
  The context is: ; ------- ;   Tallahassee (United States) 11-15 (AFP) -  The Supreme Court in Florida today Wednesday refused the application by the state's authorities to stop the new hand count of votes in some counties. 
Candidates Entropy: 1.7683351578198119
Final System Output:: Still Incorrect Wikification of: Supreme Court; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Supreme_Court_of_the_United_States ; the gold is: http://en.wikipedia.org/wiki/Supreme_Court_of_Florida;
  The confusions set is : Supreme_Court_of_Israel(ranker score=0.023156998669154744) Vs: Supreme_Court_of_the_United_States(ranker score=0.9768430013308452);
  The context is: ; ------- ;   Tallahassee (United States) 11-15 (AFP) -  The Supreme Court in Florida today Wednesday refused the application by the state's authorities to stop the new hand count of votes in some counties. 
Candidates Entropy: 0.11008349255434147
Final System Output:Correct Wikification of: Florida to : http://en.wikipedia.org/wiki/Florida
Candidates Entropy: 0.03765762751777533
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/20001115_AFP_ARB.0210.eng.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/APW20001207.2118.0838
Empty problem - no reference instances!!!
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/NYT20001002.1754.0290
Empty problem - no reference instances!!!
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/APW20001211.0507.0196
Empty problem - no reference instances!!!
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/VOA20001129.2000.0364
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =735
		- Total unique tokens  =282
		- Total unique tokens ignore case =266
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =11
		- OOV tokens, no repetitions, Case Sensitive =7
		- Total OOV tokens even after lowercasing  =11
		- OOV tokens even after lowercasing, no repetition  =7
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =11
		- OOV tokens, no repetitions, Case Sensitive =7
		- Total OOV tokens even after lowercasing  =11
		- OOV tokens even after lowercasing, no repetition  =7
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =11
		- OOV tokens, no repetitions, Case Sensitive =7
		- Total OOV tokens even after lowercasing  =11
		- OOV tokens even after lowercasing, no repetition  =7
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 720 milliseconds
Constructing a problem for the following text: 
 Welcome to this hour of VOA News Now. I'm Erin Brumett in Washington. The incredibly close Florida vote count for President is in the state courts and heading for the US Supreme Court at the end o...
Annotating mention view..
1 milliseconds elapsed on constructing the TF-IDF representation of the input text...VOA20001129.2000.0364
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Adding NER candidates for VOA20001129.2000.0364
Adding SHALLOW_PARSE and subChunk candidates for VOA20001129.2000.0364
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Matched regex entity I'm Erin Brumett in Washington[39-69]{9-15}
Matched regex entity Erin Brumett in Washington[43-69]{11-15}
Matched regex entity Joe O'Grossman[345-359]{68-70}
Matched regex entity O'Grossman[349-359]{69-70}
Matched regex entity Baltimore's Johns Hopkins University[400-436]{77-82}
Matched regex entity Well, I[586-593]{110-113}
Matched regex entity Lawrence Tribe, the Harvard Law School Professor[770-818]{152-160}
Matched regex entity And the Bush[918-930]{183-186}
Matched regex entity And the Gore[1298-1310]{261-264}
Matched regex entity No, I[1579-1584]{316-319}
Matched regex entity Well, I[2120-2127]{432-435}
Matched regex entity Joe O'Grossman[3425-3439]{695-697}
Matched regex entity O'Grossman[3429-3439]{696-697}
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Done constructing the Wikifiable entities
     ----  almost there....
449 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...VOA20001129.2000.0364
Inference on the document  -- VOA20001129.2000.0364
4 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
7 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
121 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
13 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
396 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
7 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: Supreme Court to : http://en.wikipedia.org/wiki/Supreme_Court_of_the_United_States
Level:FeatureExtractorCoherenceCorrect Wikification of: Baltimore to : http://en.wikipedia.org/wiki/Baltimore
Level:FeatureExtractorCoherenceCorrect Wikification of: Johns Hopkins University to : http://en.wikipedia.org/wiki/Johns_Hopkins_University
Level:FeatureExtractorCoherenceCorrect Wikification of: Lawrence Tribe to : http://en.wikipedia.org/wiki/Laurence_Tribe
Level:FeatureExtractorCoherenceCorrect Wikification of: Gore to : http://en.wikipedia.org/wiki/Al_Gore
Level:FeatureExtractorCoherenceCorrect Wikification of: Congress to : http://en.wikipedia.org/wiki/United_States_Congress
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Washington; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Washington,_D.C.;
  The confusions set is : Washington,_D.C.(ranker score=3.789160322850348) Vs: Washington(ranker score=4.211720739066406);
  The context is: ; ------- ;  Welcome to this hour of VOA News Now. I'm Erin Brumett in Washington. The incredibly close Florida vote count for President is in the state courts and heading for the US Supreme Court at the end of the week. That's virtually unprecedented, as the Federal Cou
Level:FeatureExtractorCoherenceCorrect Wikification of: Supreme Court to : http://en.wikipedia.org/wiki/Supreme_Court_of_the_United_States
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Joe O'Grossman; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Joel_Grossman;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; ts and heading for the US Supreme Court at the end of the week. That's virtually unprecedented, as the Federal Courts have tended to stay out of elections, which are the responsibility of the states. Joe O'Grossman is a professor of constitutional law at Baltimore's Johns Hopkins University. He says that in this instance the Supreme Court probably felt the circumstances were such that they had no 
Level:FeatureExtractorCoherenceCorrect Wikification of: Baltimore to : http://en.wikipedia.org/wiki/Baltimore
Level:FeatureExtractorCoherenceCorrect Wikification of: Johns Hopkins University to : http://en.wikipedia.org/wiki/Johns_Hopkins_University
Level:FeatureExtractorCoherenceCorrect Wikification of: Lawrence Tribe to : http://en.wikipedia.org/wiki/Laurence_Tribe
Level:FeatureExtractorCoherence: this introduces a Wikification error(!!!): Gore; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Al_Gore;
  The confusions set is : Gore,_New_Zealand(ranker score=1.7629594803140676) Vs: Al_Gore(ranker score=3.6383705776018496);
  The context is: ; ------- ; ike it was such a important issue that it would be kind of unseemly for them to try to reject it out of hand. In fact, I think that Lawrence Tribe, the Harvard Law School Professor who is arguing for Gore tomorrow, is going to ask the court to hold the case, moot and dismiss it. And the Bush campaign has brought the case, but recognizes that the particular issues that they brought to the court las
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: legislature; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Florida_Legislature;
  The confusions set is : State_legislature_(United_States)(ranker score=4.587202158624076) Vs: Legislature(ranker score=4.898441987757678);
  The context is: ; ------- ; in the sense, take the entire issue, even - not just the specific questions that it was asked last week and try to resolve the question. For example, if the court says it is clearly the fact that the legislature of the state of Florida can determine for itself who its electors will be, that will pretty much end the case, because that's what the legislature already plans to do. And that doesn't mea
Level:FeatureExtractorCoherenceCorrect Wikification of: Congress to : http://en.wikipedia.org/wiki/United_States_Congress
Could not find WikiMatchData for title Unprecedented
Could not find WikiMatchData for title Courts_of_Florida
Could not find WikiMatchData for title Decide
Could not find WikiMatchData for title Decide
Could not find WikiMatchData for title The_Johns
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Laurence_Tribe, pred=workplaces, arg2=Harvard_Law_School, score=11.434549427032472, normalizedScore=100.0]For surfaces Lawrence Tribe and Harvard Law School
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Vice_President_of_the_United_States, pred=title, arg2=Al_Gore, score=14.234070825576781, normalizedScore=100.0]For surfaces Vice President and Gore
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Republican_Party_(United_States), pred=party, arg2=George_W._Bush, score=19.763012552261355, normalizedScore=100.0]For surfaces Republican and George W Bush
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Lawrence Tribe[770-784]{152-154} === the Harvard Law School Professor who is arguing for Gore tomorrow
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush due to a longer mention than Bush that referred to the same thing
Relational inference took 26ms
CoherenceRelation 412 [arg1=[surface=University, solution=Johns_Hopkins_University], arg2=[surface=Johns Hopkins University, solution=Johns_Hopkins_University], weight=10.0] is captured by ILP inference.
CoherenceRelation 345 [arg1=[surface=O'Grossman, solution=*null*], arg2=[surface=Joe O'Grossman, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 168 [arg1=[surface=Supreme Court, solution=Supreme_Court_of_the_United_States], arg2=[surface=US Supreme Court, solution=Supreme_Court_of_the_United_States], weight=10.0] is captured by ILP inference.
CoherenceRelation 3592 [arg1=[surface=Vice President, solution=Vice_President_of_the_United_States], arg2=[surface=Gore, solution=Al_Gore], weight=100.0] is captured by ILP inference.
CoherenceRelation 790 [arg1=[surface=School, solution=Harvard_Law_School], arg2=[surface=Harvard Law School, solution=Harvard_Law_School], weight=10.0] is captured by ILP inference.
CoherenceRelation 345 [arg1=[surface=Joe O'Grossman, solution=*null*], arg2=[surface=Joe O'Grossman, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 770 [arg1=[surface=Lawrence, solution=Laurence_Tribe], arg2=[surface=Lawrence Tribe, solution=Laurence_Tribe], weight=10.0] is captured by ILP inference.
CoherenceRelation 3592 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 3592 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 3664 [arg1=[surface=Republican, solution=Republican_Party_(United_States)], arg2=[surface=George W Bush, solution=George_W._Bush], weight=100.0] is captured by ILP inference.
CoherenceRelation 168 [arg1=[surface=Supreme Court, solution=Supreme_Court_of_the_United_States], arg2=[surface=US Supreme Court, solution=Supreme_Court_of_the_United_States], weight=10.0] is captured by ILP inference.
CoherenceRelation 3664 [arg1=[surface=George, solution=George_W._Bush], arg2=[surface=George W Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 43 [arg1=[surface=Erin, solution=*null*], arg2=[surface=Erin Brumett, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 3664 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George W Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 3371 [arg1=[surface=University, solution=Johns_Hopkins_University], arg2=[surface=Johns Hopkins University, solution=Johns_Hopkins_University], weight=10.0] is captured by ILP inference.
CoherenceRelation 770 [arg1=[surface=Tribe, solution=Laurence_Tribe], arg2=[surface=Lawrence Tribe, solution=Laurence_Tribe], weight=10.0] is captured by ILP inference.
CoherenceRelation 3237 [arg1=[surface=Congress, solution=United_States_Congress], arg2=[surface=Congress, solution=United_States_Congress], weight=10.0] is captured by ILP inference.
CoherenceRelation 248 [arg1=[surface=Federal, solution=United_States_federal_courts], arg2=[surface=Federal Courts, solution=United_States_federal_courts], weight=10.0] is captured by ILP inference.
CoherenceRelation 3664 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George W Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 1437 [arg1=[surface=Republicans, solution=Republican_Party_(United_States)], arg2=[surface=Republicans, solution=Republican_Party_(United_States)], weight=10.0] is captured by ILP inference.
CoherenceRelation 3664 [arg1=[surface=George W, solution=George_W._Bush], arg2=[surface=George W Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 3592 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 790 [arg1=[surface=Lawrence Tribe, solution=Laurence_Tribe], arg2=[surface=Harvard Law School, solution=Harvard_Law_School], weight=100.0] is captured by ILP inference.
CoherenceRelation 3664 [arg1=[surface=W Bush, solution=George_W._Bush], arg2=[surface=George W Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 168 [arg1=[surface=Supreme Court, solution=Supreme_Court_of_the_United_States], arg2=[surface=US Supreme Court, solution=Supreme_Court_of_the_United_States], weight=10.0] is captured by ILP inference.
CoherenceRelation 3664 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George W Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 3425 [arg1=[surface=O'Grossman, solution=*null*], arg2=[surface=Joe O'Grossman, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 168 [arg1=[surface=Supreme Court, solution=Supreme_Court_of_the_United_States], arg2=[surface=US Supreme Court, solution=Supreme_Court_of_the_United_States], weight=10.0] is captured by ILP inference.
CoherenceRelation 168 [arg1=[surface=Supreme Court, solution=Supreme_Court_of_the_United_States], arg2=[surface=US Supreme Court, solution=Supreme_Court_of_the_United_States], weight=10.0] is captured by ILP inference.
CoherenceRelation 3425 [arg1=[surface=Joe, solution=*null*], arg2=[surface=Joe O'Grossman, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 168 [arg1=[surface=Supreme Court, solution=Supreme_Court_of_the_United_States], arg2=[surface=US Supreme Court, solution=Supreme_Court_of_the_United_States], weight=10.0] is captured by ILP inference.
CoherenceRelation 168 [arg1=[surface=Supreme Court, solution=Supreme_Court_of_the_United_States], arg2=[surface=US Supreme Court, solution=Supreme_Court_of_the_United_States], weight=10.0] is captured by ILP inference.
CoherenceRelation 345 [arg1=[surface=Joe, solution=*null*], arg2=[surface=Joe O'Grossman, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 3664 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George W Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
Discarded 98 hypothesis
Level: Relational Coherence : Still Incorrect Wikification of: Washington; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Washington,_D.C.;
  The confusions set is : Washington,_D.C.(ranker score=0.3171743411639663) Vs: Washington(ranker score=0.48396471977849714);
  The context is: ; ------- ;  Welcome to this hour of VOA News Now. I'm Erin Brumett in Washington. The incredibly close Florida vote count for President is in the state courts and heading for the US Supreme Court at the end of the week. That's virtually unprecedented, as the Federal Cou
Level: Relational Coherence Correct Wikification of: Supreme Court to : http://en.wikipedia.org/wiki/Supreme_Court_of_the_United_States
Level: Relational Coherence : Still Incorrect Wikification of: Joe O'Grossman; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Joel_Grossman;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; ts and heading for the US Supreme Court at the end of the week. That's virtually unprecedented, as the Federal Courts have tended to stay out of elections, which are the responsibility of the states. Joe O'Grossman is a professor of constitutional law at Baltimore's Johns Hopkins University. He says that in this instance the Supreme Court probably felt the circumstances were such that they had no 
Level: Relational Coherence Correct Wikification of: Baltimore to : http://en.wikipedia.org/wiki/Baltimore
Level: Relational Coherence Correct Wikification of: Johns Hopkins University to : http://en.wikipedia.org/wiki/Johns_Hopkins_University
Level: Relational Coherence Correct Wikification of: Lawrence Tribe to : http://en.wikipedia.org/wiki/Laurence_Tribe
Level: Relational Coherence Correct Wikification of: Gore to : http://en.wikipedia.org/wiki/Al_Gore
Level: Relational Coherence this fixes the Wikification (!!!)Gore; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Al_Gore ; the gold is: http://en.wikipedia.org/wiki/Al_Gore;
  The confusions set is : Gore,_New_Zealand(ranker score=0.005463785192293558) Vs: Al_Gore(ranker score=0.9764809222467294);
  The context is: ; ------- ; ike it was such a important issue that it would be kind of unseemly for them to try to reject it out of hand. In fact, I think that Lawrence Tribe, the Harvard Law School Professor who is arguing for Gore tomorrow, is going to ask the court to hold the case, moot and dismiss it. And the Bush campaign has brought the case, but recognizes that the particular issues that they brought to the court las
Level: Relational Coherence : Still Incorrect Wikification of: legislature; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Florida_Legislature;
  The confusions set is : State_legislature_(United_States)(ranker score=0.3893516386449194) Vs: Legislature(ranker score=0.5315103760622584);
  The context is: ; ------- ; in the sense, take the entire issue, even - not just the specific questions that it was asked last week and try to resolve the question. For example, if the court says it is clearly the fact that the legislature of the state of Florida can determine for itself who its electors will be, that will pretty much end the case, because that's what the legislature already plans to do. And that doesn't mea
Level: Relational Coherence Correct Wikification of: Congress to : http://en.wikipedia.org/wiki/United_States_Congress
Annotation at test time--918 milliseconds elapsed to annotate the document VOA20001129.2000.0364
Final System Output:: Still Incorrect Wikification of: Washington; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Washington,_D.C.;
  The confusions set is : Washington,_D.C.(ranker score=0.3171743411639663) Vs: Washington(ranker score=0.48396471977849714);
  The context is: ; ------- ;  Welcome to this hour of VOA News Now. I'm Erin Brumett in Washington. The incredibly close Florida vote count for President is in the state courts and heading for the US Supreme Court at the end of the week. That's virtually unprecedented, as the Federal Cou
Candidates Entropy: 1.5148113366709186
Final System Output:Correct Wikification of: Supreme Court to : http://en.wikipedia.org/wiki/Supreme_Court_of_the_United_States
Candidates Entropy: 0.07606853070173471
Final System Output:: Still Incorrect Wikification of: Joe O'Grossman; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Joel_Grossman;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; ts and heading for the US Supreme Court at the end of the week. That's virtually unprecedented, as the Federal Courts have tended to stay out of elections, which are the responsibility of the states. Joe O'Grossman is a professor of constitutional law at Baltimore's Johns Hopkins University. He says that in this instance the Supreme Court probably felt the circumstances were such that they had no 
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Baltimore to : http://en.wikipedia.org/wiki/Baltimore
Candidates Entropy: 0.007581624212885629
Final System Output:Correct Wikification of: Johns Hopkins University to : http://en.wikipedia.org/wiki/Johns_Hopkins_University
Candidates Entropy: 0.11216670636159615
Final System Output:Correct Wikification of: Lawrence Tribe to : http://en.wikipedia.org/wiki/Laurence_Tribe
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Gore to : http://en.wikipedia.org/wiki/Al_Gore
Candidates Entropy: 0.17154940911099062
Final System Output:: Still Incorrect Wikification of: legislature; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Florida_Legislature;
  The confusions set is : State_legislature_(United_States)(ranker score=0.3893516386449194) Vs: Legislature(ranker score=0.5315103760622584);
  The context is: ; ------- ; in the sense, take the entire issue, even - not just the specific questions that it was asked last week and try to resolve the question. For example, if the court says it is clearly the fact that the legislature of the state of Florida can determine for itself who its electors will be, that will pretty much end the case, because that's what the legislature already plans to do. And that doesn't mea
Candidates Entropy: 1.1281037429773604
Final System Output:Correct Wikification of: Congress to : http://en.wikipedia.org/wiki/United_States_Congress
Candidates Entropy: 0.5385493958086384
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/VOA20001129.2000.0364.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/NYT20001109.1946.0315
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =959
		- Total unique tokens  =400
		- Total unique tokens ignore case =377
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =60
		- OOV tokens, no repetitions, Case Sensitive =19
		- Total OOV tokens even after lowercasing  =59
		- OOV tokens even after lowercasing, no repetition  =18
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =73
		- OOV tokens, no repetitions, Case Sensitive =28
		- Total OOV tokens even after lowercasing  =71
		- OOV tokens even after lowercasing, no repetition  =26
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =36
		- OOV tokens, no repetitions, Case Sensitive =30
		- Total OOV tokens even after lowercasing  =31
		- OOV tokens even after lowercasing, no repetition  =25
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 1045 milliseconds
Critical warning: word hared is not found in the text 
Critical warning: word 's is not found in the text 
Critical warning: word hared is not found in the text 
Critical warning: word 's is not found in the text 
Critical warning: word hared is not found in the text 
Critical warning: word 's is not found in the text 
Constructing a problem for the following text: 
 &UR; By JAMES DAO &LR; &QC; &QL; &UR; c.2000 N.Y. Times News Service &LR; &QC; &QL;    WASHINGTON _ Ralph Nader may not be feeling any regrets about his Green Party presidential campaign, but some...
Annotating mention view..
2 milliseconds elapsed on constructing the TF-IDF representation of the input text...NYT20001109.1946.0315
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Adding NER candidates for NYT20001109.1946.0315
Adding SHALLOW_PARSE and subChunk candidates for NYT20001109.1946.0315
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Matched regex entity Instead, I'm[683-695]{152-156}
Matched regex entity And in Oregon[2061-2074]{446-449}
Matched regex entity Nader in Portland[2277-2294]{490-493}
Matched regex entity Barbara Lange, the Everglades[3931-3960]{821-826}
Matched regex entity Lange, the Everglades[3939-3960]{822-826}
Matched regex entity Nader at the University of Florida in Gainesville[4276-4325]{887-895}
Matched regex entity University of Florida in Gainesville[4289-4325]{890-895}
Matched regex entity Florida in Gainesville[4303-4325]{892-895}
Matched regex entity Nader on Tuesday[4493-4509]{931-934}
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Done constructing the Wikifiable entities
     ----  almost there....
569 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...NYT20001109.1946.0315
Inference on the document  -- NYT20001109.1946.0315
4 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
8 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
129 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
14 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
514 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
7 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: Ralph Nader to : http://en.wikipedia.org/wiki/Ralph_Nader
Level:FeatureExtractorCoherenceCorrect Wikification of: America to : http://en.wikipedia.org/wiki/United_States
Level:FeatureExtractorCoherenceCorrect Wikification of: White House to : http://en.wikipedia.org/wiki/White_House
Level:FeatureExtractorCoherenceCorrect Wikification of: Florida to : http://en.wikipedia.org/wiki/Florida
Level:FeatureExtractorCoherenceCorrect Wikification of: John Ruth to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Oregon to : http://en.wikipedia.org/wiki/Oregon
Level:FeatureExtractorCoherenceCorrect Wikification of: Julie Quastler to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Barbara Lange to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Sierra Club to : http://en.wikipedia.org/wiki/Sierra_Club
Level:FeatureExtractorCoherenceCorrect Wikification of: Patricia Newell to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: University of Florida to : http://en.wikipedia.org/wiki/University_of_Florida
Level:FeatureExtractorCoherenceCorrect Wikification of: Gainesville to : http://en.wikipedia.org/wiki/Gainesville,_Florida
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: WASHINGTON; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Washington,_D.C.;
  The confusions set is : Washington,_D.C.(ranker score=4.131873356346566) Vs: Washington(ranker score=4.219441243217619);
  The context is: ; ------- ;  &UR; By JAMES DAO &LR; &QC; &QL; &UR; c.2000 N.Y. Times News Service &LR; &QC; &QL;    WASHINGTON _ Ralph Nader may not be feeling any regrets about his Green Party presidential campaign, but some visitors to the chat room on Nader2000.org, Nader's official campaign website, sounded as 
Level:FeatureExtractorCoherenceCorrect Wikification of: Ralph Nader to : http://en.wikipedia.org/wiki/Ralph_Nader
Level:FeatureExtractorCoherenceCorrect Wikification of: America to : http://en.wikipedia.org/wiki/United_States
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Noni; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Morinda_citrifolia ; the gold is: http://en.wikipedia.org/wiki/*null*;
  The surface form has a single disambiguation candidate : Morinda_citrifolia(ranker score=2.3556864740335266) ;
  The context is: ; ------- ; our country and planet. I am no longer a member of the Green Party. Instead, I'm a member of the green movement _ a movement without Ralph Nader.''   Or this one, also posted Thursday morning, from ``Noni'':   ``I saw an interview with Ralph Nader today and he seemed to be enjoying what has happened! I've never seen him smile so broadly. I regret my support. Nader, you're a well-intending man and 
Level:FeatureExtractorCoherenceCorrect Wikification of: White House to : http://en.wikipedia.org/wiki/White_House
Level:FeatureExtractorCoherenceCorrect Wikification of: Florida to : http://en.wikipedia.org/wiki/Florida
Level:FeatureExtractorCoherenceCorrect Wikification of: John Ruth to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Oregon to : http://en.wikipedia.org/wiki/Oregon
Level:FeatureExtractorCoherenceCorrect Wikification of: Julie Quastler to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Portland; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Portland;
  The confusions set is : Portland,_Maine(ranker score=2.0071230639540945) Vs: Portland,_Oregon(ranker score=3.197087685719874);
  The context is: ; ------- ; at was still too close to call Thursday afternoon, Nader won about 5 percent of the vote _ enough to cause some Nader voters to feel morning-after qualms.   Julie Quastler, 28, who voted for Nader in Portland, said on Wednesday that she was feeling ``a little alarmed and disappointed'' that Bush seemed on the brink of winning the presidency _ suggesting that she did not accept Nader's assertion th
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Dorothy Byrne; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Dorothy_Byrne ; the gold is: http://en.wikipedia.org/wiki/*null*;
  The surface form has a single disambiguation candidate : Dorothy_Byrne(ranker score=3.4618386611045415) ;
  The context is: ; ------- ; ader2000 site signed GO LOOK ELSEWHERE FOR SCAPEGOATS.   ``We fought the good fight for what we believed in. This does not make us villains.''   Such sentiments seemed particularly strong in Florida. Dorothy Byrne, a state coordinator for the Florida Green Party, said she had been inundated with angry phone calls and e-mails from Democrats, but has yet to receive one regretful note from a Nader vo
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Green Party; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Green_Party_of_the_United_States ; the gold is: http://en.wikipedia.org/wiki/Green_Party_of_Florida;
  The confusions set is : Green_party(ranker score=4.096494227676979) Vs: Green_Party_of_the_United_States(ranker score=5.67047956895149);
  The context is: ; ------- ; TS.   ``We fought the good fight for what we believed in. This does not make us villains.''   Such sentiments seemed particularly strong in Florida. Dorothy Byrne, a state coordinator for the Florida Green Party, said she had been inundated with angry phone calls and e-mails from Democrats, but has yet to receive one regretful note from a Nader voter.   ``I can see positives for the Greens with ei
Level:FeatureExtractorCoherenceCorrect Wikification of: Barbara Lange to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: Sierra Club to : http://en.wikipedia.org/wiki/Sierra_Club
Level:FeatureExtractorCoherenceCorrect Wikification of: Patricia Newell to : http://en.wikipedia.org/wiki/*null*
Level:FeatureExtractorCoherenceCorrect Wikification of: University of Florida to : http://en.wikipedia.org/wiki/University_of_Florida
Level:FeatureExtractorCoherenceCorrect Wikification of: Gainesville to : http://en.wikipedia.org/wiki/Gainesville,_Florida
Could not find WikiMatchData for title Green_Party
Could not find WikiMatchData for title Ownership,_Unity_and_Responsibility_Party
Could not find WikiMatchData for title Qualm
Could not find WikiMatchData for title Green_Party
Could not find WikiMatchData for title Green_Party
Could not find WikiMatchData for title Scapegoating
Could not find WikiMatchData for title Green_Party_of_Florida
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=Governor, pred=WIKI_LINK_RELATION, arg2=George_W._Bush, score=3.990677833557129, normalizedScore=100.0]For surfaces Gov. and George W. Bush
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Gore[1564-1568]{342-343} === the most likely major-party alternative for Nader 's supporters
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Nader[2137-2142]{462-463} === a state that was still too close to call Thursday afternoon
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Quastler[2833-2841]{602-603} === the development director for a nonprofit cafe
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Dorothy Byrne[3463-3476]{723-725} === a state coordinator for the Florida Green Party
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - Force linking Dorothy Byrne[3463-3476]{723-725} to null
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Barbara Lange[3931-3944]{821-823} === the Everglades chairwoman for the Florida chapter of the Sierra Club
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Patricia Newell[4242-4257]{881-883} === an organizer for Nader at the University of Florida in Gainesville
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bush_family due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bush_family due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bush_family due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush_military_service_controversy due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush_presidential_campaign,_2000 due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bush_family due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Presidency_of_George_W._Bush due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bush_family due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bush_family due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Bush_family due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Ralph_Nader due to a longer mention than Nader that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Ralph_Nader due to a longer mention than Nader that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Ralph_Nader due to a longer mention than Nader that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Ralph_Nader due to a longer mention than Nader that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Ralph_Nader due to a longer mention than Nader that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Ralph_Nader due to a longer mention than Nader that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Ralph_Nader due to a longer mention than Nader that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Ralph_Nader due to a longer mention than Nader that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Ralph_Nader due to a longer mention than Nader that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Ralph_Nader due to a longer mention than Nader that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Ralph_Nader due to a longer mention than Nader that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Ralph_Nader due to a longer mention than Nader that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Ralph_Nader due to a longer mention than Nader that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Ralph_Nader due to a longer mention than Nader that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Ralph_Nader due to a longer mention than Nader that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Ralph_Nader due to a longer mention than Nader that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Ralph_Nader due to a longer mention than Nader that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Ralph_Nader due to a longer mention than Nader that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Ralph_Nader due to a longer mention than Nader that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Al_Gore due to a longer mention than Gore that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Al_Gore due to a longer mention than Gore that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Al_Gore due to a longer mention than Gore that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Al_Gore due to a longer mention than Gore that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Al_Gore due to a longer mention than Gore that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Al_Gore due to a longer mention than Gore that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Al_Gore due to a longer mention than Gore that referred to the same thing
Relational inference took 36ms
CoherenceRelation 101 [arg1=[surface=Nader, solution=Ralph_Nader], arg2=[surface=Ralph Nader, solution=Ralph_Nader], weight=10.0] is captured by ILP inference.
CoherenceRelation 1363 [arg1=[surface=Vice, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 1324 [arg1=[surface=Gov., solution=Governor], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=100.0] is captured by ILP inference.
CoherenceRelation 1324 [arg1=[surface=G.W. Bush, solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 670 [arg1=[surface=Green Party, solution=Green_Party_of_the_United_States], arg2=[surface=Green Party, solution=Green_Party_of_the_United_States], weight=10.0] is captured by ILP inference.
CoherenceRelation 1324 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 851 [arg1=[surface=Ralph, solution=Ralph_Nader], arg2=[surface=Ralph Nader, solution=Ralph_Nader], weight=10.0] is captured by ILP inference.
CoherenceRelation 1363 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 101 [arg1=[surface=Nader, solution=Ralph_Nader], arg2=[surface=Ralph Nader, solution=Ralph_Nader], weight=10.0] is captured by ILP inference.
CoherenceRelation 101 [arg1=[surface=Nader, solution=Ralph_Nader], arg2=[surface=Ralph Nader, solution=Ralph_Nader], weight=10.0] is captured by ILP inference.
CoherenceRelation 3463 [arg1=[surface=Byrne, solution=*null*], arg2=[surface=Dorothy Byrne, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 101 [arg1=[surface=Nader, solution=Ralph_Nader], arg2=[surface=Ralph Nader, solution=Ralph_Nader], weight=10.0] is captured by ILP inference.
CoherenceRelation 1363 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 1324 [arg1=[surface=W. Bush, solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 4456 [arg1=[surface=Democrats, solution=*null*], arg2=[surface=Democrats, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 748 [arg1=[surface=Nader, solution=Ralph_Nader], arg2=[surface=Ralph Nader, solution=Ralph_Nader], weight=10.0] is captured by ILP inference.
CoherenceRelation 101 [arg1=[surface=Nader, solution=Ralph_Nader], arg2=[surface=Ralph Nader, solution=Ralph_Nader], weight=10.0] is captured by ILP inference.
CoherenceRelation 101 [arg1=[surface=Nader, solution=Ralph_Nader], arg2=[surface=Ralph Nader, solution=Ralph_Nader], weight=10.0] is captured by ILP inference.
CoherenceRelation 3950 [arg1=[surface=Everglades, solution=Everglades], arg2=[surface=Everglades, solution=Everglades], weight=10.0] is captured by ILP inference.
CoherenceRelation 3463 [arg1=[surface=Dorothy, solution=*null*], arg2=[surface=Dorothy Byrne, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 1363 [arg1=[surface=Al Gore, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 101 [arg1=[surface=Nader, solution=Ralph_Nader], arg2=[surface=Ralph Nader, solution=Ralph_Nader], weight=10.0] is captured by ILP inference.
CoherenceRelation 1636 [arg1=[surface=John, solution=*null*], arg2=[surface=John Ruth, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 101 [arg1=[surface=Ralph Nader, solution=Ralph_Nader], arg2=[surface=Ralph Nader, solution=Ralph_Nader], weight=10.0] is captured by ILP inference.
CoherenceRelation 101 [arg1=[surface=Ralph Nader, solution=Ralph_Nader], arg2=[surface=Ralph Nader, solution=Ralph_Nader], weight=10.0] is captured by ILP inference.
CoherenceRelation 1363 [arg1=[surface=Vice President, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 748 [arg1=[surface=Ralph, solution=Ralph_Nader], arg2=[surface=Ralph Nader, solution=Ralph_Nader], weight=10.0] is captured by ILP inference.
CoherenceRelation 2243 [arg1=[surface=Quastler, solution=*null*], arg2=[surface=Julie Quastler, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 1324 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 1324 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 1885 [arg1=[surface=G.W., solution=George_W._Bush], arg2=[surface=G.W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 101 [arg1=[surface=Nader, solution=Ralph_Nader], arg2=[surface=Ralph Nader, solution=Ralph_Nader], weight=10.0] is captured by ILP inference.
CoherenceRelation 101 [arg1=[surface=Nader, solution=Ralph_Nader], arg2=[surface=Ralph Nader, solution=Ralph_Nader], weight=10.0] is captured by ILP inference.
CoherenceRelation 1636 [arg1=[surface=Ruth, solution=*null*], arg2=[surface=John Ruth, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 101 [arg1=[surface=Nader, solution=Ralph_Nader], arg2=[surface=Ralph Nader, solution=Ralph_Nader], weight=10.0] is captured by ILP inference.
CoherenceRelation 1324 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 101 [arg1=[surface=Nader, solution=Ralph_Nader], arg2=[surface=Ralph Nader, solution=Ralph_Nader], weight=10.0] is captured by ILP inference.
CoherenceRelation 101 [arg1=[surface=Ralph Nader, solution=Ralph_Nader], arg2=[surface=Ralph Nader, solution=Ralph_Nader], weight=10.0] is captured by ILP inference.
CoherenceRelation 851 [arg1=[surface=Nader, solution=Ralph_Nader], arg2=[surface=Ralph Nader, solution=Ralph_Nader], weight=10.0] is captured by ILP inference.
CoherenceRelation 101 [arg1=[surface=Nader, solution=Ralph_Nader], arg2=[surface=Ralph Nader, solution=Ralph_Nader], weight=10.0] is captured by ILP inference.
CoherenceRelation 3262 [arg1=[surface=Nader2000, solution=*null*], arg2=[surface=Nader2000, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 101 [arg1=[surface=Nader, solution=Ralph_Nader], arg2=[surface=Ralph Nader, solution=Ralph_Nader], weight=10.0] is captured by ILP inference.
CoherenceRelation 1324 [arg1=[surface=George, solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 1363 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 670 [arg1=[surface=Green Party, solution=Green_Party_of_the_United_States], arg2=[surface=Green Party, solution=Green_Party_of_the_United_States], weight=10.0] is captured by ILP inference.
CoherenceRelation 670 [arg1=[surface=Florida Green Party, solution=Green_Party_of_the_United_States], arg2=[surface=Green Party, solution=Green_Party_of_the_United_States], weight=10.0] is captured by ILP inference.
CoherenceRelation 1324 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 1324 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 101 [arg1=[surface=Ralph, solution=Ralph_Nader], arg2=[surface=Ralph Nader, solution=Ralph_Nader], weight=10.0] is captured by ILP inference.
CoherenceRelation 1324 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 1363 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 491 [arg1=[surface=Nader, solution=Ralph_Nader], arg2=[surface=Ralph Nader, solution=Ralph_Nader], weight=10.0] is captured by ILP inference.
CoherenceRelation 1324 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 1885 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=G.W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 2243 [arg1=[surface=Julie, solution=*null*], arg2=[surface=Julie Quastler, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 101 [arg1=[surface=Nader, solution=Ralph_Nader], arg2=[surface=Ralph Nader, solution=Ralph_Nader], weight=10.0] is captured by ILP inference.
CoherenceRelation 101 [arg1=[surface=Nader, solution=Ralph_Nader], arg2=[surface=Ralph Nader, solution=Ralph_Nader], weight=10.0] is captured by ILP inference.
CoherenceRelation 491 [arg1=[surface=Ralph, solution=Ralph_Nader], arg2=[surface=Ralph Nader, solution=Ralph_Nader], weight=10.0] is captured by ILP inference.
CoherenceRelation 101 [arg1=[surface=Nader, solution=Ralph_Nader], arg2=[surface=Ralph Nader, solution=Ralph_Nader], weight=10.0] is captured by ILP inference.
CoherenceRelation 101 [arg1=[surface=Nader, solution=Ralph_Nader], arg2=[surface=Ralph Nader, solution=Ralph_Nader], weight=10.0] is captured by ILP inference.
CoherenceRelation 1363 [arg1=[surface=President, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 101 [arg1=[surface=Nader, solution=Ralph_Nader], arg2=[surface=Ralph Nader, solution=Ralph_Nader], weight=10.0] is captured by ILP inference.
CoherenceRelation 1324 [arg1=[surface=W., solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 4289 [arg1=[surface=University of Florida, solution=University_of_Florida], arg2=[surface=University of Florida in Gainesville, solution=University_of_Florida], weight=10.0] is captured by ILP inference.
CoherenceRelation 1363 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 1324 [arg1=[surface=George W., solution=George_W._Bush], arg2=[surface=George W. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 1363 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 101 [arg1=[surface=Ralph, solution=Ralph_Nader], arg2=[surface=Ralph Nader, solution=Ralph_Nader], weight=10.0] is captured by ILP inference.
CoherenceRelation 101 [arg1=[surface=Nader, solution=Ralph_Nader], arg2=[surface=Ralph Nader, solution=Ralph_Nader], weight=10.0] is captured by ILP inference.
CoherenceRelation 1363 [arg1=[surface=Gore, solution=Al_Gore], arg2=[surface=Vice President Al Gore, solution=Al_Gore], weight=10.0] is captured by ILP inference.
CoherenceRelation 101 [arg1=[surface=Nader, solution=Ralph_Nader], arg2=[surface=Ralph Nader, solution=Ralph_Nader], weight=10.0] is captured by ILP inference.
CoherenceRelation 670 [arg1=[surface=Green Party, solution=Green_Party_of_the_United_States], arg2=[surface=Green Party, solution=Green_Party_of_the_United_States], weight=10.0] is captured by ILP inference.
Discarded 152 hypothesis
Level: Relational Coherence : Still Incorrect Wikification of: WASHINGTON; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Washington,_D.C.;
  The confusions set is : Washington,_D.C.(ranker score=0.40916807958234996) Vs: Washington(ranker score=0.4466136534915243);
  The context is: ; ------- ;  &UR; By JAMES DAO &LR; &QC; &QL; &UR; c.2000 N.Y. Times News Service &LR; &QC; &QL;    WASHINGTON _ Ralph Nader may not be feeling any regrets about his Green Party presidential campaign, but some visitors to the chat room on Nader2000.org, Nader's official campaign website, sounded as 
Level: Relational Coherence Correct Wikification of: Ralph Nader to : http://en.wikipedia.org/wiki/Ralph_Nader
Level: Relational Coherence Correct Wikification of: America to : http://en.wikipedia.org/wiki/United_States
Level: Relational Coherence : Still Incorrect Wikification of: Noni; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Morinda_citrifolia ; the gold is: http://en.wikipedia.org/wiki/*null*;
  The surface form has a single disambiguation candidate : Morinda_citrifolia(ranker score=1.0) ;
  The context is: ; ------- ; our country and planet. I am no longer a member of the Green Party. Instead, I'm a member of the green movement _ a movement without Ralph Nader.''   Or this one, also posted Thursday morning, from ``Noni'':   ``I saw an interview with Ralph Nader today and he seemed to be enjoying what has happened! I've never seen him smile so broadly. I regret my support. Nader, you're a well-intending man and 
Level: Relational Coherence Correct Wikification of: White House to : http://en.wikipedia.org/wiki/White_House
Level: Relational Coherence Correct Wikification of: Florida to : http://en.wikipedia.org/wiki/Florida
Level: Relational Coherence Correct Wikification of: John Ruth to : http://en.wikipedia.org/wiki/*null*
Level: Relational Coherence Correct Wikification of: Oregon to : http://en.wikipedia.org/wiki/Oregon
Level: Relational Coherence Correct Wikification of: Julie Quastler to : http://en.wikipedia.org/wiki/*null*
Level: Relational Coherence : Still Incorrect Wikification of: Portland; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Portland;
  The confusions set is : Portland,_Maine(ranker score=0.14786321185515872) Vs: Portland,_Oregon(ranker score=0.4860211900767419);
  The context is: ; ------- ; at was still too close to call Thursday afternoon, Nader won about 5 percent of the vote _ enough to cause some Nader voters to feel morning-after qualms.   Julie Quastler, 28, who voted for Nader in Portland, said on Wednesday that she was feeling ``a little alarmed and disappointed'' that Bush seemed on the brink of winning the presidency _ suggesting that she did not accept Nader's assertion th
Level: Relational Coherence Correct Wikification of: Dorothy Byrne to : http://en.wikipedia.org/wiki/*null*
Level: Relational Coherence this fixes the Wikification (!!!)Dorothy Byrne; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/*null*;
  The surface form has a single disambiguation candidate : Dorothy_Byrne(ranker score=1.0) ;
  The context is: ; ------- ; ader2000 site signed GO LOOK ELSEWHERE FOR SCAPEGOATS.   ``We fought the good fight for what we believed in. This does not make us villains.''   Such sentiments seemed particularly strong in Florida. Dorothy Byrne, a state coordinator for the Florida Green Party, said she had been inundated with angry phone calls and e-mails from Democrats, but has yet to receive one regretful note from a Nader vo
Level: Relational Coherence : Still Incorrect Wikification of: Green Party; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Green_Party_of_the_United_States ; the gold is: http://en.wikipedia.org/wiki/Green_Party_of_Florida;
  The confusions set is : Green_party(ranker score=0.1572876565005756) Vs: Green_Party_of_the_United_States(ranker score=0.7590454653048402);
  The context is: ; ------- ; TS.   ``We fought the good fight for what we believed in. This does not make us villains.''   Such sentiments seemed particularly strong in Florida. Dorothy Byrne, a state coordinator for the Florida Green Party, said she had been inundated with angry phone calls and e-mails from Democrats, but has yet to receive one regretful note from a Nader voter.   ``I can see positives for the Greens with ei
Level: Relational Coherence Correct Wikification of: Barbara Lange to : http://en.wikipedia.org/wiki/*null*
Level: Relational Coherence Correct Wikification of: Sierra Club to : http://en.wikipedia.org/wiki/Sierra_Club
Level: Relational Coherence Correct Wikification of: Patricia Newell to : http://en.wikipedia.org/wiki/*null*
Level: Relational Coherence Correct Wikification of: University of Florida to : http://en.wikipedia.org/wiki/University_of_Florida
Level: Relational Coherence Correct Wikification of: Gainesville to : http://en.wikipedia.org/wiki/Gainesville,_Florida
Annotation at test time--1053 milliseconds elapsed to annotate the document NYT20001109.1946.0315
Final System Output:: Still Incorrect Wikification of: WASHINGTON; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Washington,_D.C.;
  The confusions set is : Washington,_D.C.(ranker score=0.40916807958234996) Vs: Washington(ranker score=0.4466136534915243);
  The context is: ; ------- ;  &UR; By JAMES DAO &LR; &QC; &QL; &UR; c.2000 N.Y. Times News Service &LR; &QC; &QL;    WASHINGTON _ Ralph Nader may not be feeling any regrets about his Green Party presidential campaign, but some visitors to the chat room on Nader2000.org, Nader's official campaign website, sounded as 
Candidates Entropy: 1.3982954470329716
Final System Output:Correct Wikification of: Ralph Nader to : http://en.wikipedia.org/wiki/Ralph_Nader
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: America to : http://en.wikipedia.org/wiki/United_States
Candidates Entropy: 0.6199139355978944
Final System Output:: Still Incorrect Wikification of: NIL [NER, MISC]Entity:Noni; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Morinda_citrifolia ; the gold is: http://en.wikipedia.org/wiki/*null*;
  The surface form has a single disambiguation candidate : Morinda_citrifolia(ranker score=1.0) ;
  The context is: ; ------- ; our country and planet. I am no longer a member of the Green Party. Instead, I'm a member of the green movement _ a movement without Ralph Nader.''   Or this one, also posted Thursday morning, from ``Noni'':   ``I saw an interview with Ralph Nader today and he seemed to be enjoying what has happened! I've never seen him smile so broadly. I regret my support. Nader, you're a well-intending man and 
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: White House to : http://en.wikipedia.org/wiki/White_House
Candidates Entropy: 0.3033897340099622
Final System Output:Correct Wikification of: Florida to : http://en.wikipedia.org/wiki/Florida
Candidates Entropy: 0.2744794838150578
Final System Output:Correct Wikification of: John Ruth to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Oregon to : http://en.wikipedia.org/wiki/Oregon
Candidates Entropy: 0.3428663762065302
Final System Output:Correct Wikification of: Julie Quastler to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Final System Output:: Still Incorrect Wikification of: Portland; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Portland;
  The confusions set is : Portland,_Maine(ranker score=0.14786321185515872) Vs: Portland,_Oregon(ranker score=0.4860211900767419);
  The context is: ; ------- ; at was still too close to call Thursday afternoon, Nader won about 5 percent of the vote _ enough to cause some Nader voters to feel morning-after qualms.   Julie Quastler, 28, who voted for Nader in Portland, said on Wednesday that she was feeling ``a little alarmed and disappointed'' that Bush seemed on the brink of winning the presidency _ suggesting that she did not accept Nader's assertion th
Candidates Entropy: 2.025224549362715
Final System Output:Correct Wikification of: Dorothy Byrne to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Final System Output:: Still Incorrect Wikification of: Green Party; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Green_Party_of_the_United_States ; the gold is: http://en.wikipedia.org/wiki/Green_Party_of_Florida;
  The confusions set is : Green_party(ranker score=0.1572876565005756) Vs: Green_Party_of_the_United_States(ranker score=0.7590454653048402);
  The context is: ; ------- ; TS.   ``We fought the good fight for what we believed in. This does not make us villains.''   Such sentiments seemed particularly strong in Florida. Dorothy Byrne, a state coordinator for the Florida Green Party, said she had been inundated with angry phone calls and e-mails from Democrats, but has yet to receive one regretful note from a Nader voter.   ``I can see positives for the Greens with ei
Candidates Entropy: 0.8915836635490735
Final System Output:Correct Wikification of: Barbara Lange to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Sierra Club to : http://en.wikipedia.org/wiki/Sierra_Club
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Patricia Newell to : http://en.wikipedia.org/wiki/*null*
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: University of Florida to : http://en.wikipedia.org/wiki/University_of_Florida
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Gainesville to : http://en.wikipedia.org/wiki/Gainesville,_Florida
Candidates Entropy: 0.49307681846840673
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/NYT20001109.1946.0315.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/20001115_AFP_ARB.0065.eng
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =384
		- Total unique tokens  =195
		- Total unique tokens ignore case =194
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =18
		- OOV tokens, no repetitions, Case Sensitive =7
		- Total OOV tokens even after lowercasing  =18
		- OOV tokens even after lowercasing, no repetition  =7
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =28
		- OOV tokens, no repetitions, Case Sensitive =11
		- Total OOV tokens even after lowercasing  =28
		- OOV tokens even after lowercasing, no repetition  =11
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =7
		- OOV tokens, no repetitions, Case Sensitive =6
		- Total OOV tokens even after lowercasing  =7
		- OOV tokens even after lowercasing, no repetition  =6
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 347 milliseconds
Constructing a problem for the following text: 
  Camp Zeist (Holland) 11-15 (AFP) -  Today Wednesday, the judges in charge of looking into the Lockerbie case in Camp Zeist (Holland) were faced with an awkward problem: how to deal with a witness...
Annotating mention view..
1 milliseconds elapsed on constructing the TF-IDF representation of the input text...20001115_AFP_ARB.0065.eng
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Adding NER candidates for 20001115_AFP_ARB.0065.eng
Adding SHALLOW_PARSE and subChunk candidates for 20001115_AFP_ARB.0065.eng
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Matched regex entity Amsterdam, Copenhagen and Stockholm[870-905]{162-167}
Matched regex entity Copenhagen and Stockholm[881-905]{164-167}
Matched regex entity Based on Scottish[1037-1054]{190-193}
Matched regex entity Libyans, Alameen Khalifa Fahima and Abdulbasit[1816-1862]{344-351}
Matched regex entity Alameen Khalifa Fahima and Abdulbasit[1825-1862]{346-351}
Matched regex entity Khalifa Fahima and Abdulbasit[1833-1862]{347-351}
Matched regex entity Fahima and Abdulbasit[1841-1862]{348-351}
Matched regex entity Lockerbie on December[1990-2011]{375-378}
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Done constructing the Wikifiable entities
     ----  almost there....
290 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...20001115_AFP_ARB.0065.eng
Inference on the document  -- 20001115_AFP_ARB.0065.eng
1 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
4 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
100 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
9 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
338 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
5 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: Holland to : http://en.wikipedia.org/wiki/Holland
Level:FeatureExtractorCoherenceCorrect Wikification of: AFP to : http://en.wikipedia.org/wiki/Agence_France-Presse
Level:FeatureExtractorCoherenceCorrect Wikification of: Soviet Union to : http://en.wikipedia.org/wiki/Soviet_Union
Level:FeatureExtractorCoherenceCorrect Wikification of: Sweden to : http://en.wikipedia.org/wiki/Sweden
Level:FeatureExtractorCoherenceCorrect Wikification of: Amsterdam to : http://en.wikipedia.org/wiki/Amsterdam
Level:FeatureExtractorCoherenceCorrect Wikification of: Copenhagen to : http://en.wikipedia.org/wiki/Copenhagen
Level:FeatureExtractorCoherenceCorrect Wikification of: Stockholm to : http://en.wikipedia.org/wiki/Stockholm
Level:FeatureExtractorCoherenceCorrect Wikification of: Malta to : http://en.wikipedia.org/wiki/Malta
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Camp Zeist; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Scottish_Court_in_the_Netherlands ; the gold is: http://en.wikipedia.org/wiki/Zeist;
  The confusions set is : Zeist(ranker score=2.284250086110598) Vs: Scottish_Court_in_the_Netherlands(ranker score=4.985751028147863);
  The context is: ; ------- ;   Camp Zeist (Holland) 11-15 (AFP) -  Today Wednesday, the judges in charge of looking into the Lockerbie case in Camp Zeist (Holland) were faced with an awkward problem: how to deal with a witness who 
Level:FeatureExtractorCoherence: this introduces a Wikification error(!!!): Holland; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Holland;
  The confusions set is : Netherlands(ranker score=2.7812335573879663) Vs: Holland(ranker score=4.222032405038838);
  The context is: ; ------- ;   Camp Zeist (Holland) 11-15 (AFP) -  Today Wednesday, the judges in charge of looking into the Lockerbie case in Camp Zeist (Holland) were faced with an awkward problem: how to deal with a witness who is refusing 
Level:FeatureExtractorCoherence: this introduces a Wikification error(!!!): AFP; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Agence_France-Presse;
  The confusions set is : Apple_Filing_Protocol(ranker score=0.8134636979981003) Vs: Agence_France-Presse(ranker score=1.4914354089743482);
  The context is: ; ------- ;   Camp Zeist (Holland) 11-15 (AFP) -  Today Wednesday, the judges in charge of looking into the Lockerbie case in Camp Zeist (Holland) were faced with an awkward problem: how to deal with a witness who is refusing to answer questi
Level:FeatureExtractorCoherenceCorrect Wikification of: Soviet Union to : http://en.wikipedia.org/wiki/Soviet_Union
Level:FeatureExtractorCoherenceCorrect Wikification of: Sweden to : http://en.wikipedia.org/wiki/Sweden
Level:FeatureExtractorCoherenceCorrect Wikification of: Amsterdam to : http://en.wikipedia.org/wiki/Amsterdam
Level:FeatureExtractorCoherenceCorrect Wikification of: Copenhagen to : http://en.wikipedia.org/wiki/Copenhagen
Level:FeatureExtractorCoherenceCorrect Wikification of: Stockholm to : http://en.wikipedia.org/wiki/Stockholm
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Alameen Khalifa Fahima; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Lamin_Khalifah_Fhimah;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; t president, Ronald Sutherland, who adjourned the session for a short while in an attempt to find a solution to this dilemma, said "this raises an important question of principle."   The two Libyans, Alameen Khalifa Fahima and Abdulbasit al-Maqrahi, are suspected of sending a bomb from Malta which was used to explode the Pan Am plane over the Scottish village of Lockerbie on December 21, 1988 kill
Level:FeatureExtractorCoherence: Still Incorrect Wikification of: Abdulbasit al-Maqrahi; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Abdelbaset_al-Megrahi;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; and, who adjourned the session for a short while in an attempt to find a solution to this dilemma, said "this raises an important question of principle."   The two Libyans, Alameen Khalifa Fahima and Abdulbasit al-Maqrahi, are suspected of sending a bomb from Malta which was used to explode the Pan Am plane over the Scottish village of Lockerbie on December 21, 1988 killing 270 people. 
Level:FeatureExtractorCoherenceCorrect Wikification of: Malta to : http://en.wikipedia.org/wiki/Malta
Could not find WikiMatchData for title 18_Months
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Ronald Sutherland[1638-1655]{309-311} === The court president
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Alameen Khalifa Fahima[1825-1847]{346-349} === The two Libyans
Relational inference took 5ms
CoherenceRelation 499 [arg1=[surface=Keen, solution=Richard_Keen], arg2=[surface=Richard Keen, solution=Richard_Keen], weight=10.0] is captured by ILP inference.
CoherenceRelation 1319 [arg1=[surface=Talib, solution=Abu_Talib_ibn_‘Abd_al-Muttalib], arg2=[surface=Abu Talib, solution=Abu_Talib_ibn_‘Abd_al-Muttalib], weight=10.0] is captured by ILP inference.
CoherenceRelation 785 [arg1=[surface=Talib, solution=Abu_Talib_ibn_‘Abd_al-Muttalib], arg2=[surface=Abu Talib, solution=Abu_Talib_ibn_‘Abd_al-Muttalib], weight=10.0] is captured by ILP inference.
CoherenceRelation 1319 [arg1=[surface=Abu Talib, solution=Abu_Talib_ibn_‘Abd_al-Muttalib], arg2=[surface=Abu Talib, solution=Abu_Talib_ibn_‘Abd_al-Muttalib], weight=10.0] is captured by ILP inference.
CoherenceRelation 1319 [arg1=[surface=Abu, solution=Abu_Talib_ibn_‘Abd_al-Muttalib], arg2=[surface=Abu Talib, solution=Abu_Talib_ibn_‘Abd_al-Muttalib], weight=10.0] is captured by ILP inference.
CoherenceRelation 1638 [arg1=[surface=Sutherland, solution=*null*], arg2=[surface=Ronald Sutherland, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 785 [arg1=[surface=Abu, solution=Abu_Talib_ibn_‘Abd_al-Muttalib], arg2=[surface=Abu Talib, solution=Abu_Talib_ibn_‘Abd_al-Muttalib], weight=10.0] is captured by ILP inference.
CoherenceRelation 664 [arg1=[surface=Abu, solution=Abu_Talib_ibn_‘Abd_al-Muttalib], arg2=[surface=Abu Talib, solution=Abu_Talib_ibn_‘Abd_al-Muttalib], weight=10.0] is captured by ILP inference.
CoherenceRelation 1638 [arg1=[surface=Ronald, solution=*null*], arg2=[surface=Ronald Sutherland, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 1319 [arg1=[surface=Abu Talib, solution=Abu_Talib_ibn_‘Abd_al-Muttalib], arg2=[surface=Abu Talib, solution=Abu_Talib_ibn_‘Abd_al-Muttalib], weight=10.0] is captured by ILP inference.
CoherenceRelation 1319 [arg1=[surface=Abu Talib, solution=Abu_Talib_ibn_‘Abd_al-Muttalib], arg2=[surface=Abu Talib, solution=Abu_Talib_ibn_‘Abd_al-Muttalib], weight=10.0] is captured by ILP inference.
CoherenceRelation 1319 [arg1=[surface=Mahmood Abu Talib, solution=Abu_Talib_ibn_‘Abd_al-Muttalib], arg2=[surface=Abu Talib, solution=Abu_Talib_ibn_‘Abd_al-Muttalib], weight=10.0] is captured by ILP inference.
CoherenceRelation 499 [arg1=[surface=Richard, solution=Richard_Keen], arg2=[surface=Richard Keen, solution=Richard_Keen], weight=10.0] is captured by ILP inference.
CoherenceRelation 1087 [arg1=[surface=Abu, solution=Abu_Talib_ibn_‘Abd_al-Muttalib], arg2=[surface=Abu Talib, solution=Abu_Talib_ibn_‘Abd_al-Muttalib], weight=10.0] is captured by ILP inference.
CoherenceRelation 1481 [arg1=[surface=Talib, solution=Abu_Talib_ibn_‘Abd_al-Muttalib], arg2=[surface=Abu Talib, solution=Abu_Talib_ibn_‘Abd_al-Muttalib], weight=10.0] is captured by ILP inference.
CoherenceRelation 1087 [arg1=[surface=Talib, solution=Abu_Talib_ibn_‘Abd_al-Muttalib], arg2=[surface=Abu Talib, solution=Abu_Talib_ibn_‘Abd_al-Muttalib], weight=10.0] is captured by ILP inference.
CoherenceRelation 1481 [arg1=[surface=Abu, solution=Abu_Talib_ibn_‘Abd_al-Muttalib], arg2=[surface=Abu Talib, solution=Abu_Talib_ibn_‘Abd_al-Muttalib], weight=10.0] is captured by ILP inference.
CoherenceRelation 1852 [arg1=[surface=Abdulbasit, solution=*null*], arg2=[surface=Abdulbasit al-Maqrahi, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 1319 [arg1=[surface=Abu Talib, solution=Abu_Talib_ibn_‘Abd_al-Muttalib], arg2=[surface=Abu Talib, solution=Abu_Talib_ibn_‘Abd_al-Muttalib], weight=10.0] is captured by ILP inference.
CoherenceRelation 664 [arg1=[surface=Talib, solution=Abu_Talib_ibn_‘Abd_al-Muttalib], arg2=[surface=Abu Talib, solution=Abu_Talib_ibn_‘Abd_al-Muttalib], weight=10.0] is captured by ILP inference.
CoherenceRelation 1825 [arg1=[surface=Khalifa, solution=*null*], arg2=[surface=Alameen Khalifa Fahima, solution=*null*], weight=10.0] is captured by ILP inference.
Discarded 0 hypothesis
Level: Relational Coherence : Still Incorrect Wikification of: Camp Zeist; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Scottish_Court_in_the_Netherlands ; the gold is: http://en.wikipedia.org/wiki/Zeist;
  The confusions set is : Zeist(ranker score=0.06288484697510213) Vs: Scottish_Court_in_the_Netherlands(ranker score=0.9371151530248979);
  The context is: ; ------- ;   Camp Zeist (Holland) 11-15 (AFP) -  Today Wednesday, the judges in charge of looking into the Lockerbie case in Camp Zeist (Holland) were faced with an awkward problem: how to deal with a witness who 
Level: Relational Coherence : Still Incorrect Wikification of: Holland; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Holland;
  The confusions set is : Netherlands(ranker score=0.15769189251901064) Vs: Holland(ranker score=0.6661014121953877);
  The context is: ; ------- ;   Camp Zeist (Holland) 11-15 (AFP) -  Today Wednesday, the judges in charge of looking into the Lockerbie case in Camp Zeist (Holland) were faced with an awkward problem: how to deal with a witness who is refusing 
Level: Relational Coherence : Still Incorrect Wikification of: AFP; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Agence_France-Presse;
  The confusions set is : Apple_Filing_Protocol(ranker score=0.18626558768061127) Vs: Agence_France-Presse(ranker score=0.36692051968287004);
  The context is: ; ------- ;   Camp Zeist (Holland) 11-15 (AFP) -  Today Wednesday, the judges in charge of looking into the Lockerbie case in Camp Zeist (Holland) were faced with an awkward problem: how to deal with a witness who is refusing to answer questi
Level: Relational Coherence Correct Wikification of: Soviet Union to : http://en.wikipedia.org/wiki/Soviet_Union
Level: Relational Coherence Correct Wikification of: Sweden to : http://en.wikipedia.org/wiki/Sweden
Level: Relational Coherence Correct Wikification of: Amsterdam to : http://en.wikipedia.org/wiki/Amsterdam
Level: Relational Coherence Correct Wikification of: Copenhagen to : http://en.wikipedia.org/wiki/Copenhagen
Level: Relational Coherence Correct Wikification of: Stockholm to : http://en.wikipedia.org/wiki/Stockholm
Level: Relational Coherence : Still Incorrect Wikification of: Alameen Khalifa Fahima; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Lamin_Khalifah_Fhimah;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; t president, Ronald Sutherland, who adjourned the session for a short while in an attempt to find a solution to this dilemma, said "this raises an important question of principle."   The two Libyans, Alameen Khalifa Fahima and Abdulbasit al-Maqrahi, are suspected of sending a bomb from Malta which was used to explode the Pan Am plane over the Scottish village of Lockerbie on December 21, 1988 kill
Level: Relational Coherence : Still Incorrect Wikification of: Abdulbasit al-Maqrahi; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Abdelbaset_al-Megrahi;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; and, who adjourned the session for a short while in an attempt to find a solution to this dilemma, said "this raises an important question of principle."   The two Libyans, Alameen Khalifa Fahima and Abdulbasit al-Maqrahi, are suspected of sending a bomb from Malta which was used to explode the Pan Am plane over the Scottish village of Lockerbie on December 21, 1988 killing 270 people. 
Level: Relational Coherence Correct Wikification of: Malta to : http://en.wikipedia.org/wiki/Malta
Annotation at test time--582 milliseconds elapsed to annotate the document 20001115_AFP_ARB.0065.eng
Final System Output:: Still Incorrect Wikification of: Camp Zeist; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/Scottish_Court_in_the_Netherlands ; the gold is: http://en.wikipedia.org/wiki/Zeist;
  The confusions set is : Zeist(ranker score=0.06288484697510213) Vs: Scottish_Court_in_the_Netherlands(ranker score=0.9371151530248979);
  The context is: ; ------- ;   Camp Zeist (Holland) 11-15 (AFP) -  Today Wednesday, the judges in charge of looking into the Lockerbie case in Camp Zeist (Holland) were faced with an awkward problem: how to deal with a witness who 
Candidates Entropy: 0.23483258220039044
Final System Output:: Still Incorrect Wikification of: Holland; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Holland;
  The confusions set is : Netherlands(ranker score=0.15769189251901064) Vs: Holland(ranker score=0.6661014121953877);
  The context is: ; ------- ;   Camp Zeist (Holland) 11-15 (AFP) -  Today Wednesday, the judges in charge of looking into the Lockerbie case in Camp Zeist (Holland) were faced with an awkward problem: how to deal with a witness who is refusing 
Candidates Entropy: 1.3771301727964649
Final System Output:: Still Incorrect Wikification of: AFP; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Agence_France-Presse;
  The confusions set is : Apple_Filing_Protocol(ranker score=0.18626558768061127) Vs: Agence_France-Presse(ranker score=0.36692051968287004);
  The context is: ; ------- ;   Camp Zeist (Holland) 11-15 (AFP) -  Today Wednesday, the judges in charge of looking into the Lockerbie case in Camp Zeist (Holland) were faced with an awkward problem: how to deal with a witness who is refusing to answer questi
Candidates Entropy: 1.7551723481437729
Final System Output:Correct Wikification of: Soviet Union to : http://en.wikipedia.org/wiki/Soviet_Union
Candidates Entropy: 0.7828677380441077
Final System Output:Correct Wikification of: Sweden to : http://en.wikipedia.org/wiki/Sweden
Candidates Entropy: 1.0068973045047296
Final System Output:Correct Wikification of: Amsterdam to : http://en.wikipedia.org/wiki/Amsterdam
Candidates Entropy: 0.6246824106884441
Final System Output:Correct Wikification of: Copenhagen to : http://en.wikipedia.org/wiki/Copenhagen
Candidates Entropy: 0.15376588788488194
Final System Output:Correct Wikification of: Stockholm to : http://en.wikipedia.org/wiki/Stockholm
Candidates Entropy: 0.2579254875546767
Final System Output:: Still Incorrect Wikification of: Alameen Khalifa Fahima; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Lamin_Khalifah_Fhimah;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; t president, Ronald Sutherland, who adjourned the session for a short while in an attempt to find a solution to this dilemma, said "this raises an important question of principle."   The two Libyans, Alameen Khalifa Fahima and Abdulbasit al-Maqrahi, are suspected of sending a bomb from Malta which was used to explode the Pan Am plane over the Scottish village of Lockerbie on December 21, 1988 kill
Candidates Entropy: 0.0
Final System Output:: Still Incorrect Wikification of: Abdulbasit al-Maqrahi; ------- ;
  the prediction is: http://en.wikipedia.org/wiki/*null* ; the gold is: http://en.wikipedia.org/wiki/Abdelbaset_al-Megrahi;
 The surface form has no candidate disambiguations....;
  The context is: ; ------- ; and, who adjourned the session for a short while in an attempt to find a solution to this dilemma, said "this raises an important question of principle."   The two Libyans, Alameen Khalifa Fahima and Abdulbasit al-Maqrahi, are suspected of sending a bomb from Malta which was used to explode the Pan Am plane over the Scottish village of Lockerbie on December 21, 1988 killing 270 people. 
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: Malta to : http://en.wikipedia.org/wiki/Malta
Candidates Entropy: 1.0226663217604357
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/20001115_AFP_ARB.0065.eng.tagged.full.xml
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/APW20001219.1316.0416
Empty problem - no reference instances!!!
Processing the reference problem : /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/data/WikificationACL2011Data/ACE2004_Coref_Turking/Dev/ProblemsNoTranscripts/VOA20001220.2000.0060
character encoding = UTF8
Annotating the data with expressive features...
Brown clusters OOV statistics:
Data statistics:
		- Total tokens with repetitions =166
		- Total unique tokens  =104
		- Total unique tokens ignore case =101
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brown-english-wikitext.case-intact.txt-c1000-freq10-v3.txt(covers 1288301 unique tokens)
		- Total OOV tokens, Case Sensitive =1
		- OOV tokens, no repetitions, Case Sensitive =1
		- Total OOV tokens even after lowercasing  =1
		- OOV tokens even after lowercasing, no repetition  =1
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/brownBllipClusters(covers 95262 unique tokens)
		- Total OOV tokens, Case Sensitive =5
		- OOV tokens, no repetitions, Case Sensitive =4
		- Total OOV tokens even after lowercasing  =3
		- OOV tokens even after lowercasing, no repetition  =3
	* OOV statistics for the resource: data/NER_Data//BrownHierarchicalWordClusters/rcv1.clean.tokenized-c1000-p1.paths.txt(covers 85963 unique tokens)
		- Total OOV tokens, Case Sensitive =6
		- OOV tokens, no repetitions, Case Sensitive =5
		- Total OOV tokens even after lowercasing  =4
		- OOV tokens even after lowercasing, no repetition  =4
Annotating the data with gazetteers
Annotating the data with context-aggregation features (if necessary)
Done Annotating the data with expressive features...
Annontating data with the models tagger, the inference algoritm is: GREEDY
Extracting features for level 2 inference
Done - Extracting features for level 2 inference
Done Annontating data with the models tagger, the inference algoritm is: GREEDY
Inference time: 151 milliseconds
Constructing a problem for the following text: 
 I am David Coler, VOA News. President Elect George W Bush made more cabinet appointments Wednesday. He named Al Koha Chairman Paul O' Neil as Treasury Secretary and former California Food and Agri...
1 milliseconds elapsed on constructing the TF-IDF representation of the input text...VOA20001220.2000.0060
Getting the wikifiable mentions candidates
Getting the Wikifiable entitites
Getting the text annotation
Adding NER candidates for VOA20001220.2000.0060
Adding SHALLOW_PARSE and subChunk candidates for VOA20001220.2000.0060
Annotating mention view..
Done - Getting the text annotation
Adding manually specified mentions
Regex matching...
Matched regex entity David Coler, VOA News[6-27]{2-7}
Matched regex entity Al Koha Chairman Paul O' Neil[110-139]{21-27}
Matched regex entity Koha Chairman Paul O' Neil[113-139]{22-27}
Matched regex entity Chairman Paul O' Neil[118-139]{23-27}
Matched regex entity Paul O' Neil[127-139]{24-27}
Matched regex entity O' Neil[132-139]{25-27}
Matched regex entity California Food and Agriculture Secretary, Anne Venemon[173-228]{32-40}
Matched regex entity Agriculture Secretary, Anne Venemon[193-228]{35-40}
Matched regex entity Secretary of Agriculture[232-256]{41-44}
Matched regex entity Don Evans[314-323]{57-59}
Matched regex entity Secretary of Commerce[327-348]{60-63}
Matched regex entity Secretary of Housing and Urban Development[688-730]{127-133}
Matched regex entity Housing and Urban Development[701-730]{129-133}
Matched regex entity Governor of Texas[876-893]{162-165}
Finished adding regex large chunk matching
Extracting the candidate disambiguations for the mentions
Done constructing the Wikifiable entities
     ----  almost there....
180 milliseconds elapsed on constructing potentially wikifiable entitites in the input text...VOA20001220.2000.0060
Inference on the document  -- VOA20001220.2000.0060
1 milliseconds elapsed extracting features for the level: FeatureExtractorTitlesMatch
3 milliseconds elapsed ranking the candidates at level...FeatureExtractorTitlesMatch
47 milliseconds elapsed extracting features for the level: FeatureExtractorLexical
5 milliseconds elapsed ranking the candidates at level...FeatureExtractorLexical
36 milliseconds elapsed extracting features for the level: FeatureExtractorCoherence
3 milliseconds elapsed ranking the candidates at level...FeatureExtractorCoherence
Level:FeatureExtractorCoherenceCorrect Wikification of: VOA News to : http://en.wikipedia.org/wiki/Voice_of_America
Level:FeatureExtractorCoherenceCorrect Wikification of: America to : http://en.wikipedia.org/wiki/United_States
Level:FeatureExtractorCoherenceCorrect Wikification of: Texas to : http://en.wikipedia.org/wiki/Texas
Level:FeatureExtractorCoherenceCorrect Wikification of: VOA News to : http://en.wikipedia.org/wiki/Voice_of_America
Level:FeatureExtractorCoherenceCorrect Wikification of: America to : http://en.wikipedia.org/wiki/United_States
Level:FeatureExtractorCoherenceCorrect Wikification of: Texas to : http://en.wikipedia.org/wiki/Texas
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.relation.RelationalAnalysis] - Accepting relation Triple [arg1=List_of_Governors_of_Florida, pred=title, arg2=Jeb_Bush, score=11.616999244689941, normalizedScore=100.0]For surfaces Florida Governor and Jeb Bush
[DEBUG][edu.illinois.cs.cogcomp.wikifier.inference.relation.NominalMentionAnalysis] - NOMCOREF DETECTED:Don Evans[314-323]{57-59} === an oil business associate
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Neil_Bush due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Neil_Bush due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting George_W._Bush due to a longer mention than Bush that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Donald_Evans due to a longer mention than Evans that referred to the same thing
[INFO][edu.illinois.cs.cogcomp.wikifier.inference.coref.CorefElection] - Promoting Paul_O'Neil due to a longer mention than Neil that referred to the same thing
Relational inference took 4ms
CoherenceRelation 45 [arg1=[surface=George W, solution=George_W._Bush], arg2=[surface=George W Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 127 [arg1=[surface=Neil, solution=Paul_O'Neil], arg2=[surface=Paul O' Neil, solution=Paul_O'Neil], weight=10.0] is captured by ILP inference.
CoherenceRelation 832 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=Mr. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 314 [arg1=[surface=Evans, solution=Donald_Evans], arg2=[surface=Don Evans, solution=Donald_Evans], weight=10.0] is captured by ILP inference.
CoherenceRelation 6 [arg1=[surface=David, solution=*null*], arg2=[surface=David Coler, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 127 [arg1=[surface=O', solution=Paul_O'Neil], arg2=[surface=Paul O' Neil, solution=Paul_O'Neil], weight=10.0] is captured by ILP inference.
CoherenceRelation 216 [arg1=[surface=Anne, solution=*null*], arg2=[surface=Anne Venemon, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 832 [arg1=[surface=Mr., solution=George_W._Bush], arg2=[surface=Mr. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 127 [arg1=[surface=Paul, solution=Paul_O'Neil], arg2=[surface=Paul O' Neil, solution=Paul_O'Neil], weight=10.0] is captured by ILP inference.
CoherenceRelation 45 [arg1=[surface=Mr. Bush, solution=George_W._Bush], arg2=[surface=George W Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 45 [arg1=[surface=W Bush, solution=George_W._Bush], arg2=[surface=George W Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 672 [arg1=[surface=Mel, solution=Mel_Martinez], arg2=[surface=Mel Martinez, solution=Mel_Martinez], weight=10.0] is captured by ILP inference.
CoherenceRelation 45 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George W Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 45 [arg1=[surface=Jeb Bush, solution=George_W._Bush], arg2=[surface=George W Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 45 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George W Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 127 [arg1=[surface=O' Neil, solution=Paul_O'Neil], arg2=[surface=Paul O' Neil, solution=Paul_O'Neil], weight=10.0] is captured by ILP inference.
CoherenceRelation 672 [arg1=[surface=Martinez, solution=Mel_Martinez], arg2=[surface=Mel Martinez, solution=Mel_Martinez], weight=10.0] is captured by ILP inference.
CoherenceRelation 45 [arg1=[surface=Mr. Bush, solution=George_W._Bush], arg2=[surface=George W Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 631 [arg1=[surface=Mr., solution=George_W._Bush], arg2=[surface=Mr. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 672 [arg1=[surface=Martinez, solution=Mel_Martinez], arg2=[surface=Mel Martinez, solution=Mel_Martinez], weight=10.0] is captured by ILP inference.
CoherenceRelation 631 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=Mr. Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 232 [arg1=[surface=Secretary, solution=United_States_Secretary_of_Agriculture], arg2=[surface=Secretary of Agriculture, solution=United_States_Secretary_of_Agriculture], weight=10.0] is captured by ILP inference.
CoherenceRelation 45 [arg1=[surface=Bush, solution=George_W._Bush], arg2=[surface=George W Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
CoherenceRelation 876 [arg1=[surface=Governor, solution=List_of_Governors_of_Texas], arg2=[surface=Governor of Texas, solution=List_of_Governors_of_Texas], weight=10.0] is captured by ILP inference.
CoherenceRelation 110 [arg1=[surface=Koha, solution=*null*], arg2=[surface=Al Koha, solution=*null*], weight=10.0] is captured by ILP inference.
CoherenceRelation 45 [arg1=[surface=George, solution=George_W._Bush], arg2=[surface=George W Bush, solution=George_W._Bush], weight=10.0] is captured by ILP inference.
Discarded 3 hypothesis
Level: Relational Coherence Correct Wikification of: VOA News to : http://en.wikipedia.org/wiki/Voice_of_America
Level: Relational Coherence Correct Wikification of: America to : http://en.wikipedia.org/wiki/United_States
Level: Relational Coherence Correct Wikification of: Texas to : http://en.wikipedia.org/wiki/Texas
Annotation at test time--329 milliseconds elapsed to annotate the document VOA20001220.2000.0060
Final System Output:Correct Wikification of: VOA News to : http://en.wikipedia.org/wiki/Voice_of_America
Candidates Entropy: 0.0
Final System Output:Correct Wikification of: America to : http://en.wikipedia.org/wiki/United_States
Candidates Entropy: 0.9530372332306349
Final System Output:Correct Wikification of: Texas to : http://en.wikipedia.org/wiki/Texas
Candidates Entropy: 0.16347747834471904
Saving the full wikification output to /scratch2/azehady/nlp/Wikifier2013/Wikifier2013/run_scripts/Output/ACE2004_TestDataResult_ReferenceAssitant_Full/VOA20001220.2000.0060.tagged.full.xml
************  Performance by inference level: ****************
-----------------------------------------------------------------------------------
Performance after stage FeatureExtractorTitlesMatch
------------- Before the linker: 
------------------------------------------------------------------- 
Per position performance:
	 ---->With respect to top 1 predictions:
			Precision: NaN
			Recall (per position on all entitites): NaN
			F1 Per entity = NaN
			Accuracy (per position on all entitites): NaN
	 ---->With respect to top 2 predictions:
			Precision: NaN
			Recall (per position on all entitites): NaN
			F1 Per entity = NaN
			Accuracy (per position on all entitites): NaN
	 ---->With respect to top 3 predictions:
			Precision: NaN
			Recall (per position on all entitites): NaN
			F1 Per entity = NaN
			Accuracy (per position on all entitites): NaN
	 ---->With respect to top 4 predictions:
			Precision: NaN
			Recall (per position on all entitites): NaN
			F1 Per entity = NaN
			Accuracy (per position on all entitites): NaN
	 ---->With respect to top 5 predictions:
			Precision: NaN
			Recall (per position on all entitites): NaN
			F1 Per entity = NaN
			Accuracy (per position on all entitites): NaN
------------------------------------------------------------------- 
Bag of Concepts(BOC) performace:
Precision (on all surface forms): NaN
Recall (on all surface forms): NaN
F1(on all surface forms):  NaN
Precision (only on problem instances): NaN
Recall (only on problem instances): NaN
F1 (only on problem instances): NaN
------------------------------------------------------------------- 
Linker stats:
------------------------------------------------------------------- 
FORCED ranker accuracy on the solvable entities:NaN
Linker performance: NaN
Linker performance if we link every surface form: NaN
-------   interesting linkability statistics -----------
------------- After the linker: 
------------------------------------------------------------------- 
Per position performance:
	 ---->With respect to top 1 predictions:
			Precision: NaN
			Recall (per position on all entitites): NaN
			F1 Per entity = NaN
			Accuracy (per position on all entitites): NaN
	 ---->With respect to top 2 predictions:
			Precision: NaN
			Recall (per position on all entitites): NaN
			F1 Per entity = NaN
			Accuracy (per position on all entitites): NaN
	 ---->With respect to top 3 predictions:
			Precision: NaN
			Recall (per position on all entitites): NaN
			F1 Per entity = NaN
			Accuracy (per position on all entitites): NaN
	 ---->With respect to top 4 predictions:
			Precision: NaN
			Recall (per position on all entitites): NaN
			F1 Per entity = NaN
			Accuracy (per position on all entitites): NaN
	 ---->With respect to top 5 predictions:
			Precision: NaN
			Recall (per position on all entitites): NaN
			F1 Per entity = NaN
			Accuracy (per position on all entitites): NaN
------------------------------------------------------------------- 
Bag of Concepts(BOC) performace:
Precision (on all surface forms): NaN
Recall (on all surface forms): NaN
F1(on all surface forms):  NaN
Precision (only on problem instances): NaN
Recall (only on problem instances): NaN
F1 (only on problem instances): NaN
------------------------------------------------------------------- 
Linker stats:
------------------------------------------------------------------- 
FORCED ranker accuracy on the solvable entities:NaN
Linker performance: NaN
Linker performance if we link every surface form: NaN
-------   interesting linkability statistics -----------
-----------------------------------------------------------------------------------
-----------------------------------------------------------------------------------
Performance after stage FeatureExtractorLexical
------------- Before the linker: 
------------------------------------------------------------------- 
Per position performance:
	 ---->With respect to top 1 predictions:
			Precision: NaN
			Recall (per position on all entitites): NaN
			F1 Per entity = NaN
			Accuracy (per position on all entitites): NaN
	 ---->With respect to top 2 predictions:
			Precision: NaN
			Recall (per position on all entitites): NaN
			F1 Per entity = NaN
			Accuracy (per position on all entitites): NaN
	 ---->With respect to top 3 predictions:
			Precision: NaN
			Recall (per position on all entitites): NaN
			F1 Per entity = NaN
			Accuracy (per position on all entitites): NaN
	 ---->With respect to top 4 predictions:
			Precision: NaN
			Recall (per position on all entitites): NaN
			F1 Per entity = NaN
			Accuracy (per position on all entitites): NaN
	 ---->With respect to top 5 predictions:
			Precision: NaN
			Recall (per position on all entitites): NaN
			F1 Per entity = NaN
			Accuracy (per position on all entitites): NaN
------------------------------------------------------------------- 
Bag of Concepts(BOC) performace:
Precision (on all surface forms): NaN
Recall (on all surface forms): NaN
F1(on all surface forms):  NaN
Precision (only on problem instances): NaN
Recall (only on problem instances): NaN
F1 (only on problem instances): NaN
------------------------------------------------------------------- 
Linker stats:
------------------------------------------------------------------- 
FORCED ranker accuracy on the solvable entities:NaN
Linker performance: NaN
Linker performance if we link every surface form: NaN
-------   interesting linkability statistics -----------
------------- After the linker: 
------------------------------------------------------------------- 
Per position performance:
	 ---->With respect to top 1 predictions:
			Precision: NaN
			Recall (per position on all entitites): NaN
			F1 Per entity = NaN
			Accuracy (per position on all entitites): NaN
	 ---->With respect to top 2 predictions:
			Precision: NaN
			Recall (per position on all entitites): NaN
			F1 Per entity = NaN
			Accuracy (per position on all entitites): NaN
	 ---->With respect to top 3 predictions:
			Precision: NaN
			Recall (per position on all entitites): NaN
			F1 Per entity = NaN
			Accuracy (per position on all entitites): NaN
	 ---->With respect to top 4 predictions:
			Precision: NaN
			Recall (per position on all entitites): NaN
			F1 Per entity = NaN
			Accuracy (per position on all entitites): NaN
	 ---->With respect to top 5 predictions:
			Precision: NaN
			Recall (per position on all entitites): NaN
			F1 Per entity = NaN
			Accuracy (per position on all entitites): NaN
------------------------------------------------------------------- 
Bag of Concepts(BOC) performace:
Precision (on all surface forms): NaN
Recall (on all surface forms): NaN
F1(on all surface forms):  NaN
Precision (only on problem instances): NaN
Recall (only on problem instances): NaN
F1 (only on problem instances): NaN
------------------------------------------------------------------- 
Linker stats:
------------------------------------------------------------------- 
FORCED ranker accuracy on the solvable entities:NaN
Linker performance: NaN
Linker performance if we link every surface form: NaN
-------   interesting linkability statistics -----------
-----------------------------------------------------------------------------------
-----------------------------------------------------------------------------------
Performance after stage FeatureExtractorCoherence
------------- Before the linker: 
------------------------------------------------------------------- 
Per position performance:
	 ---->With respect to top 1 predictions:
			Precision: 0.8299595141700404
			Recall (per position on all entitites): 0.8167330677290837
			F1 Per entity = 0.823293172690763
			Accuracy (per position on all entitites): 0.7953020134228188
	 ---->With respect to top 2 predictions:
			Precision: 0.5198135198135199
			Recall (per position on all entitites): 0.5247058823529411
			F1 Per entity = 0.522248243559719
			Accuracy (per position on all entitites): 0.53125
	 ---->With respect to top 3 predictions:
			Precision: 0.3771043771043771
			Recall (per position on all entitites): 0.38421955403087477
			F1 Per entity = 0.3806287170773152
			Accuracy (per position on all entitites): 0.39689922480620154
	 ---->With respect to top 4 predictions:
			Precision: 0.3771043771043771
			Recall (per position on all entitites): 0.38421955403087477
			F1 Per entity = 0.3806287170773152
			Accuracy (per position on all entitites): 0.39689922480620154
	 ---->With respect to top 5 predictions:
			Precision: 0.3771043771043771
			Recall (per position on all entitites): 0.38421955403087477
			F1 Per entity = 0.3806287170773152
			Accuracy (per position on all entitites): 0.39689922480620154
------------------------------------------------------------------- 
Bag of Concepts(BOC) performace:
Precision (on all surface forms): 0.8770491803278688
Recall (on all surface forms): 0.8492063492063492
F1(on all surface forms):  0.8629032258064516
Precision (only on problem instances): 0.8436213991769548
Recall (only on problem instances): 0.8134920634920635
F1 (only on problem instances): 0.8282828282828283
------------------------------------------------------------------- 
Linker stats:
------------------------------------------------------------------- 
FORCED ranker accuracy on the solvable entities:0.9403669724770642
Linker performance: 0.8590604026845637
Linker performance if we link every surface form: 0.6879194630872483
-------   interesting linkability statistics -----------
------------- After the linker: 
------------------------------------------------------------------- 
Per position performance:
	 ---->With respect to top 1 predictions:
			Precision: 0.8904109589041096
			Recall (per position on all entitites): 0.7768924302788844
			F1 Per entity = 0.8297872340425532
			Accuracy (per position on all entitites): 0.7785234899328859
	 ---->With respect to top 2 predictions:
			Precision: 0.546916890080429
			Recall (per position on all entitites): 0.5074626865671642
			F1 Per entity = 0.5264516129032258
			Accuracy (per position on all entitites): 0.5331858407079646
	 ---->With respect to top 3 predictions:
			Precision: 0.4019607843137255
			Recall (per position on all entitites): 0.3817504655493482
			F1 Per entity = 0.39159503342884433
			Accuracy (per position on all entitites): 0.41086587436332767
	 ---->With respect to top 4 predictions:
			Precision: 0.4019607843137255
			Recall (per position on all entitites): 0.3817504655493482
			F1 Per entity = 0.39159503342884433
			Accuracy (per position on all entitites): 0.41086587436332767
	 ---->With respect to top 5 predictions:
			Precision: 0.4019607843137255
			Recall (per position on all entitites): 0.3817504655493482
			F1 Per entity = 0.39159503342884433
			Accuracy (per position on all entitites): 0.41086587436332767
------------------------------------------------------------------- 
Bag of Concepts(BOC) performace:
Precision (on all surface forms): 0.9234234234234234
Recall (on all surface forms): 0.8134920634920635
F1(on all surface forms):  0.8649789029535866
Precision (only on problem instances): 0.8986175115207373
Recall (only on problem instances): 0.7738095238095238
F1 (only on problem instances): 0.8315565031982942
------------------------------------------------------------------- 
Linker stats:
------------------------------------------------------------------- 
FORCED ranker accuracy on the solvable entities:0.9403669724770642
Linker performance: 0.8557046979865772
Linker performance if we link every surface form: 0.6879194630872483
-------   interesting linkability statistics -----------
-----------------------------------------------------------------------------------
************  Final Performance  **************
------------------------------------------------------------------- 
Per position performance:
	 ---->With respect to top 1 predictions:
			Precision: 0.9054054054054054
			Recall (per position on all entitites): 0.8007968127490039
			F1 Per entity = 0.8498942917547567
			Accuracy (per position on all entitites): 0.8154362416107382
	 ---->With respect to top 2 predictions:
			Precision: 0.5452127659574468
			Recall (per position on all entitites): 0.5086848635235732
			F1 Per entity = 0.5263157894736842
			Accuracy (per position on all entitites): 0.5464601769911505
	 ---->With respect to top 3 predictions:
			Precision: 0.40234375
			Recall (per position on all entitites): 0.3828996282527881
			F1 Per entity = 0.3923809523809524
			Accuracy (per position on all entitites): 0.4217687074829932
	 ---->With respect to top 4 predictions:
			Precision: 0.32445141065830724
			Recall (per position on all entitites): 0.31221719457013575
			F1 Per entity = 0.318216756341276
			Accuracy (per position on all entitites): 0.3487394957983193
	 ---->With respect to top 5 predictions:
			Precision: 0.27344782034346105
			Recall (per position on all entitites): 0.26504481434058896
			F1 Per entity = 0.26918075422626786
			Accuracy (per position on all entitites): 0.29891956782713086
------------------------------------------------------------------- 
Bag of Concepts(BOC) performace:
Precision (on all surface forms): 0.9330357142857143
Recall (on all surface forms): 0.8293650793650794
F1(on all surface forms):  0.8781512605042017
Precision (only on problem instances): 0.9269406392694064
Recall (only on problem instances): 0.8055555555555556
F1 (only on problem instances): 0.861995753715499
------------------------------------------------------------------- 
Linker stats:
------------------------------------------------------------------- 
FORCED ranker accuracy on the solvable entities:0.9311926605504587
Linker performance: 0.8825503355704698
Linker performance if we link every surface form: 0.7046979865771812
-------   interesting linkability statistics -----------
************  Running time breakdown  **************
- Time constructing the disambiguation candidates 12212
- Feature extraction times:
	FeatureExtractorTitlesMatch - 107
	FeatureExtractorLexical - 23792
	FeatureExtractorCoherence - 8818
- Ranking time: 677
- Linking time: 238
Total Inference time: 119970 milliseconds
